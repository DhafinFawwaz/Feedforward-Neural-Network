{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "cbf762c7c5709d70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:37:01.239768Z",
     "start_time": "2025-03-28T16:37:01.235363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.FFNNClassifier import FFNNClassifier\n",
    "\n",
    "from lib.MLPLib import MLPLIB\n",
    "from lib.Utils import model_comparison, model_scratch_output\n"
   ],
   "id": "801534e44fcbe2c0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:37:01.251265Z",
     "start_time": "2025-03-28T16:37:01.247735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_encode(y, num_classes=10):\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    one_hot = np.zeros((len(y), num_classes), dtype=int)\n",
    "    one_hot[np.arange(len(y)), y] = 1\n",
    "    return one_hot"
   ],
   "id": "696c483c9ba4e7cb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:37:06.260006Z",
     "start_time": "2025-03-28T16:37:01.263512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# Type conversion\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "y_test_one_hot = one_hot_encode(y_test)"
   ],
   "id": "28a4bd5cdff5847f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:37:06.281654Z",
     "start_time": "2025-03-28T16:37:06.276512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "DEFAULT PARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "lower_bound=5.39294405e-05\n",
    "upper_bound=1\n",
    "mean=5.39294405e-05\n",
    "std=.44\n",
    "seed=69\n",
    "hidden_layer_sizes=[128,64,32]\n",
    "max_iter=15\n",
    "init_method=\"normal\"\n",
    "learning_rate_init=0.01\n",
    "batch_size=50\n",
    "activation_mlplib=\"logistic\"\n",
    "activation_ffnn=\"sigmoid\"\n"
   ],
   "id": "690823e3c6017152",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pengaruh depth (banyak layer) dan width (banyak neuron per layer)",
   "id": "bdbb694a07f20a30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:37:06.317293Z",
     "start_time": "2025-03-28T16:37:06.312235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration for depth variation (keeping width constant)\n",
    "depth_configs = [\n",
    "    [10, 10],  # 2 layers\n",
    "    [10, 10, 10],  # 3 layers\n",
    "    [10, 10, 10, 10]  # 4 layers\n",
    "]\n",
    "\n",
    "# Configuration for width variation (keeping depth constant)\n",
    "width_configs = [\n",
    "    [5],  # narrow layer\n",
    "    [15],  # medium layer\n",
    "    [30]  # wide layer\n",
    "]"
   ],
   "id": "d4b5a127ebeacf8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:37:37.578714Z",
     "start_time": "2025-03-28T16:37:06.326435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Experiment for depth variations (keeping width fixed)\n",
    "print(\"Depth Variations Experiment:\")\n",
    "for depth_config in depth_configs:\n",
    "    print(f\"\\nTesting depth configuration: {depth_config}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(depth_config) + ['softmax']\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "59dfa7da3d6601c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth Variations Experiment:\n",
      "\n",
      "Testing depth configuration: [10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.6517142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.6517142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing depth configuration: [10, 10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.4722142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.4722142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing depth configuration: [10, 10, 10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.24035714285714285\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.24035714285714285\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:38:09.960667Z",
     "start_time": "2025-03-28T16:37:37.591318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Width Variations Experiment:\")\n",
    "for width in width_configs:\n",
    "    print(f\"\\nTesting width configuration: {width}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=width,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=width,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(width) + ['softmax']\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "ce96bdb39bc445",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing width configuration: [5]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7432142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.7432142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing width configuration: [15]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8022142857142858\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8022142857142858\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing width configuration: [30]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8432857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8432857142857143\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pengaruh fungsi aktivasi hidden layer",
   "id": "613282673cb7adca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:38:09.976828Z",
     "start_time": "2025-03-28T16:38:09.972677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activation_configs = [\n",
    "    ('linear','identity'),\n",
    "    ('relu','relu'),\n",
    "    ('sigmoid','logistic'),\n",
    "    ('tanh','tanh')\n",
    "]\n",
    "\n",
    "bonus_activation_configs = [\n",
    "    'softsign',\n",
    "    'softplus'\n",
    "]"
   ],
   "id": "34b1a12acf7ac72",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:41:24.374944Z",
     "start_time": "2025-03-28T16:38:09.993690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Width Variations Experiment:\")\n",
    "for act_custom, act_sklearn in activation_configs:\n",
    "    print(f\"\\nTesting activation configuration: {act_custom}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=act_sklearn,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[act_custom] * len(hidden_layer_sizes) + ['softmax']\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "e7a0630da20efc9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing activation configuration: linear\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8857857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8857857142857143\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: relu\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7580714285714286\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.7580714285714286\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: sigmoid\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: tanh\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8095\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8095\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:42:07.546766Z",
     "start_time": "2025-03-28T16:41:24.410706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for act_custom in bonus_activation_configs:\n",
    "    print(f\"\\nTesting activation configuration: {act_custom}\")\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[act_custom] * len(hidden_layer_sizes) + ['softmax']\n",
    "    )\n",
    "\n",
    "    model_scratch_output(custom_mlp, X_train_scaled, y_train_one_hot, X_test_scaled, y_test_one_hot)"
   ],
   "id": "b8078fd0146278d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing activation configuration: softsign\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[ 0.34849682,  0.20366047,  0.14421766, ..., -0.11011714,\n",
      "         0.85692686, -0.20459601],\n",
      "       [ 0.43855953,  0.09489525,  0.03395932, ..., -0.07869318,\n",
      "         0.03085322, -0.7965541 ],\n",
      "       [-0.20512688,  0.14743526, -0.8297421 , ..., -0.05077973,\n",
      "        -0.49387592,  0.17818075],\n",
      "       ...,\n",
      "       [-0.6334432 , -0.34678155,  0.25855687, ..., -0.48119783,\n",
      "        -0.21261859, -0.14547339],\n",
      "       [ 0.5134772 , -0.6923477 ,  0.23591197, ...,  0.42926645,\n",
      "         0.39576954, -0.33404246],\n",
      "       [ 0.28817222, -0.24174216, -0.67546964, ..., -0.4206143 ,\n",
      "        -0.25590882, -0.3167226 ]], shape=(784, 128), dtype=float32), array([[ 0.26231116,  0.22627188,  0.23337834, ...,  0.32387826,\n",
      "        -0.35762906,  0.15279643],\n",
      "       [-0.30226976,  0.03051095,  0.4826649 , ..., -0.04104296,\n",
      "        -0.5140538 ,  0.8041288 ],\n",
      "       [-1.0443975 ,  0.4134605 ,  0.00576117, ...,  0.5646582 ,\n",
      "         0.11251439,  0.22100815],\n",
      "       ...,\n",
      "       [ 0.31304032, -0.5955745 , -0.34466562, ...,  0.09856506,\n",
      "         0.2330836 , -0.5352124 ],\n",
      "       [-0.714128  , -0.402061  ,  0.22256942, ..., -0.5886116 ,\n",
      "         0.04714872,  0.05962033],\n",
      "       [ 0.3953012 ,  0.37696984,  0.7386325 , ...,  0.3396097 ,\n",
      "         0.20317905,  0.1846546 ]], shape=(128, 64), dtype=float32), array([[-0.01097698, -0.39204717,  0.34126866, ..., -0.44136396,\n",
      "        -0.01914397,  0.48577234],\n",
      "       [-0.45033967,  0.44150946,  1.0973333 , ...,  0.04489783,\n",
      "        -0.28581965, -0.00131663],\n",
      "       [-0.29405773,  0.27663243, -0.02633004, ..., -0.36102077,\n",
      "        -0.23088397, -0.43987444],\n",
      "       ...,\n",
      "       [-0.07007778, -0.29170156,  0.05018962, ...,  0.03995779,\n",
      "        -0.70015496,  0.08813964],\n",
      "       [ 0.62896496, -0.104601  ,  0.3416828 , ...,  0.20473415,\n",
      "         1.0052451 , -0.077696  ],\n",
      "       [-0.40165582, -0.27237108,  0.5740399 , ...,  0.02129571,\n",
      "        -0.11922266, -0.07703016]], shape=(64, 32), dtype=float32), array([[ 0.7204127 ,  0.7099716 ,  0.69225806, -0.6109203 , -0.27613434,\n",
      "         0.40112773,  0.47902328, -0.55767184, -0.6259416 , -0.1573319 ],\n",
      "       [ 0.9170403 , -0.38125572,  0.22972363, -0.3299394 , -0.59638184,\n",
      "        -0.69619614,  0.7651346 , -0.37037918, -0.0203748 , -0.47461554],\n",
      "       [ 0.83770406, -0.99861836,  0.2715536 ,  0.58497053,  0.48787874,\n",
      "         0.5642876 ,  0.33043402,  0.0450808 , -0.66402847, -0.2971542 ],\n",
      "       [ 0.1197493 ,  0.1907032 ,  0.72373027,  0.41557842, -0.991384  ,\n",
      "         0.50318867, -0.58786845, -1.0777855 ,  0.77291507, -1.1044562 ],\n",
      "       [ 0.2827247 ,  0.2907327 ,  0.94386435,  0.7179124 , -0.64072365,\n",
      "        -0.12279825, -0.4846252 ,  0.80836   , -0.07239278, -0.18898241],\n",
      "       [ 0.58971167, -0.67847794,  0.4483067 ,  1.153679  , -0.820612  ,\n",
      "         0.55143875, -0.202845  ,  0.32297128,  0.49067575,  0.34987888],\n",
      "       [-0.09280388,  0.3492394 ,  0.904619  ,  0.290804  , -0.23271953,\n",
      "         0.12079979, -0.3649038 ,  0.3439376 ,  0.30045256,  0.6159471 ],\n",
      "       [-0.5354497 , -0.26516852, -0.27697515, -0.8514674 ,  0.6712096 ,\n",
      "        -0.18421718, -0.5342671 , -0.646691  , -0.08797527, -0.7688181 ],\n",
      "       [ 0.5668009 , -0.20420077, -0.39120963,  0.5754258 , -0.18239327,\n",
      "        -0.16648374, -0.31866306,  1.1457775 , -0.26645812,  0.17452592],\n",
      "       [ 0.24921803,  0.14576587, -0.50916237,  0.06602102, -0.4467171 ,\n",
      "         0.5543709 ,  0.67179394, -0.41606414,  0.04705325, -0.12727802],\n",
      "       [ 0.04826403,  0.26530164,  0.781513  , -1.1369802 ,  0.20986941,\n",
      "        -0.9059248 ,  0.25102717, -0.4265922 ,  0.3835998 ,  0.42520526],\n",
      "       [-0.52382386, -0.30472362,  0.09557163, -0.45449767, -0.04246317,\n",
      "         0.39942583, -0.01698017, -0.36510253, -0.39326105, -0.60464144],\n",
      "       [-0.3850442 ,  0.4824293 ,  0.31405854,  0.19889323,  0.4759223 ,\n",
      "        -1.0478141 ,  0.6489551 ,  0.34936678, -0.925907  ,  0.6276769 ],\n",
      "       [-0.91379994, -0.22309966, -0.16849779,  0.81454957,  0.23518014,\n",
      "         0.10596516, -0.7416873 ,  0.28009805, -0.3829065 , -0.03763701],\n",
      "       [-0.24763964, -0.29722586,  0.36308882,  0.8860922 ,  0.12226193,\n",
      "         0.47546384, -0.01922692, -0.1523951 , -0.05291554, -0.2079673 ],\n",
      "       [-1.483457  , -0.04348015,  0.54778653, -0.2155732 ,  0.44437858,\n",
      "        -0.7403645 ,  0.86409473, -0.84253085,  0.16756593, -0.09903429],\n",
      "       [ 0.29531106,  0.5942569 , -0.8009987 , -0.20736799, -0.14429502,\n",
      "         0.14975129,  0.23702855, -0.32908502, -0.20407826,  0.09282242],\n",
      "       [-0.83703566,  0.13055521, -0.08705625, -1.1279304 ,  0.44131947,\n",
      "         0.6495838 , -0.03987997,  0.23644815,  0.20671166,  0.09117576],\n",
      "       [ 0.6448284 ,  0.8197347 ,  0.1739718 ,  0.2718735 , -0.41101384,\n",
      "         0.5439576 ,  0.95456505, -0.28252754, -0.09568114, -0.9123923 ],\n",
      "       [ 0.34086248,  0.5755959 ,  0.11127857,  0.05859969,  0.61362624,\n",
      "        -0.8526508 , -0.00527131,  0.76980203, -0.24926631,  0.30326664],\n",
      "       [ 0.1277646 , -0.6877366 , -0.57429105,  0.35579032,  0.04529991,\n",
      "         0.17108971, -0.07515186, -0.40237787,  0.2135834 ,  0.47240144],\n",
      "       [-0.8800322 ,  0.7484577 ,  0.6265876 ,  0.1055163 ,  0.4162778 ,\n",
      "         0.25211826, -0.08330514, -0.5420597 , -0.26711088, -0.5796081 ],\n",
      "       [ 0.23622194,  0.38853624, -0.37822375,  0.7115558 , -0.6243243 ,\n",
      "        -1.3252033 ,  0.02135982,  0.76002175,  0.02737786, -0.6571119 ],\n",
      "       [-0.35177925,  1.0424314 , -0.4518832 , -0.58684206, -0.0633937 ,\n",
      "         0.07116549, -0.70361584,  0.14227147,  0.5006534 ,  0.26803416],\n",
      "       [-0.17366143,  0.6949363 , -0.36704567, -0.8878293 , -0.39850032,\n",
      "        -0.0125149 , -0.12362846,  0.557051  , -0.93291587, -0.4505507 ],\n",
      "       [ 1.2563694 , -0.28107965, -0.2827237 , -0.9006139 ,  0.5401524 ,\n",
      "        -0.3898525 ,  0.80899787, -0.10066852, -0.8509776 ,  0.4827818 ],\n",
      "       [-0.088278  , -0.7226324 ,  0.5763182 , -0.57898456, -0.229248  ,\n",
      "        -0.09635891,  0.33073595,  0.54626995,  0.4034258 , -0.19533426],\n",
      "       [-0.53901434,  0.5742987 , -0.6313185 ,  0.64762175, -0.09365759,\n",
      "        -0.5258117 ,  0.344772  ,  0.09973102, -0.12827821,  0.794588  ],\n",
      "       [ 0.17852451, -0.22931182,  0.11215305, -0.4395629 ,  0.22604047,\n",
      "        -0.79445165,  0.03639711, -0.8455266 , -0.15694278, -0.7006492 ],\n",
      "       [-0.10984758, -0.07025682,  0.53138477,  0.10594755,  0.34747115,\n",
      "        -0.46252462,  0.5969733 , -0.34052768,  0.705917  , -0.79314363],\n",
      "       [-0.39587143,  0.6760719 ,  0.6192406 ,  0.4888085 , -0.9901978 ,\n",
      "        -0.37328103, -1.514959  , -0.20117919,  0.3509496 , -0.43621555],\n",
      "       [-0.51432526,  0.00227906, -0.00676178,  0.3264588 , -0.9080701 ,\n",
      "         0.07512802,  0.8013514 ,  0.07614506, -0.5196732 , -0.5350921 ]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[ 3.94492447e-01, -2.68388569e-01,  5.13341188e-01,\n",
      "        -3.00914466e-01, -7.00361729e-01,  1.39981136e-01,\n",
      "         5.29237926e-01,  4.33071226e-01,  4.38125372e-01,\n",
      "         3.27909648e-01, -1.34062201e-01, -2.24144787e-01,\n",
      "        -4.42302078e-01,  5.21468461e-01, -5.79003215e-01,\n",
      "        -4.67626303e-02, -1.91827968e-01, -8.91853690e-01,\n",
      "        -7.51000524e-01,  1.25623032e-01,  4.13721710e-01,\n",
      "        -4.63612437e-01,  2.96183139e-01, -4.72440898e-01,\n",
      "        -8.38857591e-01, -5.12665331e-01,  9.24483314e-02,\n",
      "        -9.50426579e-01,  9.65727307e-03,  1.47182748e-01,\n",
      "        -4.36681837e-01,  7.29103386e-01,  1.69297144e-01,\n",
      "        -3.39709610e-01, -5.58925748e-01, -9.89288032e-01,\n",
      "        -2.75809944e-01, -1.17612943e-01,  5.78496158e-01,\n",
      "        -7.79117793e-02, -4.92569096e-02, -6.30719244e-01,\n",
      "        -5.52588142e-02,  9.54769959e-04,  3.43548097e-02,\n",
      "         3.08365345e-01, -6.81464195e-01, -6.57052994e-01,\n",
      "         4.37798709e-01,  1.86958238e-01,  6.09728098e-01,\n",
      "        -1.12525070e+00,  7.40925595e-02, -5.50561488e-01,\n",
      "        -2.89281011e-01,  4.71602261e-01, -3.70885760e-01,\n",
      "         8.19538713e-01,  7.11581230e-01, -8.09975922e-01,\n",
      "        -2.76097417e-01, -1.42280839e-03,  7.69419312e-01,\n",
      "        -3.03679556e-01, -3.71441548e-03, -7.66071737e-01,\n",
      "        -9.18572307e-01,  3.32261860e-01, -3.32445055e-01,\n",
      "        -1.00659914e-01, -4.02111039e-02, -6.82542846e-02,\n",
      "         6.53434932e-01, -1.43058911e-01,  3.56220543e-01,\n",
      "         6.47645652e-01,  3.97290796e-01, -4.95959520e-01,\n",
      "         2.58716196e-01, -3.98846805e-01,  6.50611937e-01,\n",
      "         6.90776885e-01,  1.39335677e-01,  8.19832206e-01,\n",
      "         7.99369693e-01,  6.58770859e-01,  3.41742784e-01,\n",
      "        -1.40575528e-01, -7.14725494e-01,  1.08324796e-01,\n",
      "         5.94543032e-02,  4.45702642e-01, -1.21275030e-01,\n",
      "         4.10327464e-01,  9.49784458e-01,  3.54100734e-01,\n",
      "         2.96718460e-02,  3.07525117e-02, -6.86832547e-01,\n",
      "        -1.28142715e-01, -1.67352498e-01,  2.41211846e-01,\n",
      "         1.25670359e-01, -2.48657495e-01, -2.86309253e-02,\n",
      "        -1.93881154e-01,  4.19597596e-01, -7.43409693e-02,\n",
      "         7.01713264e-01, -2.43993804e-01, -5.89550674e-01,\n",
      "        -1.02329135e+00, -4.06341195e-01,  4.59501773e-01,\n",
      "         8.30461979e-01,  3.99443746e-01, -2.20399141e-01,\n",
      "         1.15382262e-01, -9.99832511e-01,  9.93705615e-02,\n",
      "        -8.52853775e-01, -5.85266292e-01,  1.34050339e-01,\n",
      "        -9.40899923e-02,  6.22380197e-01, -1.24202333e-01,\n",
      "        -7.49958336e-01,  4.60065961e-01]], dtype=float32), array([[ 0.57229245, -0.4921641 , -0.02047594, -0.11161993, -0.14837055,\n",
      "         0.67375875, -0.16336799, -0.11275502, -0.68413556, -0.45838147,\n",
      "        -0.19903079, -0.50133336,  0.5108807 , -0.15276337,  0.09734812,\n",
      "         0.40165958,  0.3345365 , -0.07078214,  0.1345577 ,  0.39173922,\n",
      "        -0.5185641 , -0.23932557,  0.8959845 , -0.26165777, -0.11799584,\n",
      "        -0.3322507 ,  0.1984471 , -0.25416863, -0.3084513 , -0.4509186 ,\n",
      "         0.04308396, -0.8567555 ,  0.25783396,  0.6958684 ,  0.13590874,\n",
      "        -0.34085736,  0.4041951 ,  0.27035877, -0.374453  , -0.29089427,\n",
      "         0.3782791 ,  0.26549035,  0.62670785,  0.35680193, -0.31367528,\n",
      "         0.24909583, -0.60611004,  0.36518577,  0.27569142, -0.50282395,\n",
      "         0.6430617 ,  0.28042766,  0.4477292 ,  0.7115216 , -0.30274227,\n",
      "        -0.6049151 , -0.13252312,  0.3566628 ,  0.3981432 , -0.10195444,\n",
      "         0.17771171, -0.00163098,  0.46093804, -0.44854707]],\n",
      "      dtype=float32), array([[-0.67529637,  0.14935479,  0.9539334 ,  0.80657315,  0.05500464,\n",
      "         0.16428562,  0.49200463, -0.07846101,  0.09219555, -0.10993982,\n",
      "         0.7921933 ,  0.09185998,  0.08743745,  1.0153522 ,  0.42775092,\n",
      "         0.14131035, -0.55989796, -1.0037374 , -0.4519436 , -0.4843997 ,\n",
      "         0.38699013,  0.04907554, -0.62295645,  0.23897855,  0.05980467,\n",
      "        -0.0927083 ,  0.2675723 ,  0.53416723, -0.8177954 ,  0.74935466,\n",
      "         0.5718863 , -0.2565842 ]], dtype=float32), array([[-0.47766176, -0.5079046 ,  0.15333942, -0.55035883, -0.27512988,\n",
      "         0.7785856 , -0.09687501,  0.3779984 ,  0.24427278, -0.47351688]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 9 1]\n",
      "Prediction Probability:\n",
      " [[1.33431092e-06 1.07835873e-03 1.49960853e-02 ... 5.61885681e-05\n",
      "  9.75956321e-01 3.98957217e-03]\n",
      " [4.46932245e-06 1.75458030e-04 4.19499956e-05 ... 1.37302547e-03\n",
      "  1.86689699e-03 6.61709979e-02]\n",
      " [2.62662908e-03 2.15866603e-02 7.21748732e-03 ... 1.48233585e-03\n",
      "  7.10108578e-02 3.42200436e-02]\n",
      " ...\n",
      " [1.02461036e-03 1.14386678e-01 7.50571370e-01 ... 2.27898220e-03\n",
      "  1.15592904e-01 5.23065450e-04]\n",
      " [5.81721179e-05 2.13948879e-04 3.72437171e-05 ... 4.72946167e-01\n",
      "  2.87145085e-04 5.22811949e-01]\n",
      " [2.98266878e-06 9.90340889e-01 4.89238882e-03 ... 1.84297969e-04\n",
      "  3.70660750e-03 8.56325714e-05]]\n",
      "Loss:\n",
      " [np.float64(1.7462277629741472), np.float64(1.0167035364979977), np.float64(0.8207294853839009), np.float64(0.7150969054440373), np.float64(0.644987641286893), np.float64(0.5938691025455589), np.float64(0.5544488577655062), np.float64(0.5227499853430485), np.float64(0.49640787828423344), np.float64(0.47396729994348225), np.float64(0.4544989210709601), np.float64(0.4372607014766049), np.float64(0.421835251327764), np.float64(0.4079676841574533), np.float64(0.39544551550415463)]\n",
      "Accuracy:\n",
      " 0.8529285714285715\n",
      "\n",
      "Testing activation configuration: softplus\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:105: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log(1 + np.exp(x))\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:276: RuntimeWarning: invalid value encountered in matmul\n",
      "  a_k = b_k + (h_k_min_1 @ w_k) # numpy will automatically broadcast b_k (row will be copied to match the result from dot) so that this is addable\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:100: RuntimeWarning: invalid value encountered in subtract\n",
      "  exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:130: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x)) # sigmoid(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]],\n",
      "      shape=(784, 128), dtype=float32), array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]],\n",
      "      shape=(128, 64), dtype=float32), array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]], shape=(64, 32), dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)]\n",
      "Biases:\n",
      " [array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "      dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "      dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan]], dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)]\n",
      "Prediction:\n",
      " [0 0 0 ... 0 0 0]\n",
      "Prediction Probability:\n",
      " [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Loss:\n",
      " [np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Accuracy:\n",
      " 0.09592857142857143\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pengaruh learning rate",
   "id": "f403053e9c150dd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:42:07.578676Z",
     "start_time": "2025-03-28T16:42:07.574312Z"
    }
   },
   "cell_type": "code",
   "source": "learning_rates = [0.1, 0.06, 0.006, 0.0009]",
   "id": "d67ad2a321d25bbf",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:45:38.536197Z",
     "start_time": "2025-03-28T16:42:07.591719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Width Variations Experiment:\")\n",
    "for rate in learning_rates:\n",
    "    print(f\"\\nTesting activation configuration: {rate}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax']\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "b21ff3b736552045",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing activation configuration: 0.1\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.06\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.006\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.0009\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Perbandingan Weight",
   "id": "ddcb9cda56cd61b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:45:38.578512Z",
     "start_time": "2025-03-28T16:45:38.573677Z"
    }
   },
   "cell_type": "code",
   "source": "weight_configs =  ['normal', 'zero', 'uniform']",
   "id": "34d5132af2f90c41",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:48:03.479069Z",
     "start_time": "2025-03-28T16:45:38.605931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Width Variations Experiment:\")\n",
    "for weight_config in weight_configs:\n",
    "    print(f\"\\nTesting weight configuration: {weight_config}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax']\n",
    "    )\n",
    "\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "d5c0d65e76b4a222",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing weight configuration: normal\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing weight configuration: zero\n",
      "[SKLearn MLPClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[Comparison Result]\n",
      "[[2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " ...\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]] != [[3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " ...\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]]\n",
      "❌ Weight is not equal\n",
      "[4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883903e-06 4.5883903e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883903e-06 4.5883903e-06 4.5883903e-06 4.5883903e-06\n",
      " 4.5883908e-06 4.5883908e-06 4.5883908e-06 4.5883908e-06] != [[7.2032235e-06 7.2032235e-06 7.2032235e-06 7.2032235e-06 7.2032235e-06\n",
      "  7.2032235e-06 7.2032180e-06 7.2032180e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032180e-06 7.2032180e-06 7.2032180e-06 7.2032180e-06\n",
      "  7.2032212e-06 7.2032212e-06 7.2032212e-06 7.2032212e-06]]\n",
      "❌ Bias is not equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing weight configuration: uniform\n",
      "[SKLearn MLPClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:97: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
