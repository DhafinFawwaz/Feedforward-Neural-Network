{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf762c7c5709d70",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801534e44fcbe2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:00.513568Z",
     "start_time": "2025-03-29T06:05:58.320609Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.FFNNClassifier import FFNNClassifier\n",
    "\n",
    "from lib.MLPLib import MLPLIB\n",
    "from lib.Utils import model_comparison, model_scratch_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696c483c9ba4e7cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:00.532337Z",
     "start_time": "2025-03-29T06:06:00.528314Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes=10):\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    one_hot = np.zeros((len(y), num_classes), dtype=int)\n",
    "    one_hot[np.arange(len(y)), y] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a4bd5cdff5847f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:04.889499Z",
     "start_time": "2025-03-29T06:06:00.541768Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# Type conversion\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "y_test_one_hot = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690823e3c6017152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:05.061698Z",
     "start_time": "2025-03-29T06:06:05.057706Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DEFAULT PARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "lower_bound=5.39294405e-05\n",
    "upper_bound=1\n",
    "mean=5.39294405e-05\n",
    "std=.44\n",
    "seed=69\n",
    "hidden_layer_sizes=[128,64,32]\n",
    "max_iter=15\n",
    "init_method=\"normal\"\n",
    "learning_rate_init=0.01\n",
    "batch_size=50\n",
    "activation_mlplib=\"logistic\"\n",
    "activation_ffnn=\"sigmoid\"\n",
    "l1=0.1\n",
    "l2=0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb694a07f20a30",
   "metadata": {},
   "source": [
    "# Pengaruh depth (banyak layer) dan width (banyak neuron per layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b5a127ebeacf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:05.078669Z",
     "start_time": "2025-03-29T06:06:05.075029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration for depth variation (keeping width constant)\n",
    "depth_configs = [\n",
    "    [10, 10],  # 2 layers\n",
    "    [10, 10, 10],  # 3 layers\n",
    "    [10, 10, 10, 10]  # 4 layers\n",
    "]\n",
    "\n",
    "# Configuration for width variation (keeping depth constant)\n",
    "width_configs = [\n",
    "    [5],  # narrow layer\n",
    "    [15],  # medium layer\n",
    "    [30]  # wide layer\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dfa7da3d6601c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:44.095232Z",
     "start_time": "2025-03-29T06:06:05.142738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth Variations Experiment:\n",
      "\n",
      "Testing depth configuration: [10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.6517142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.6517142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing depth configuration: [10, 10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.4722142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.4722142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing depth configuration: [10, 10, 10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.24035714285714285\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.24035714285714285\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment for depth variations (keeping width fixed)\n",
    "print(\"Depth Variations Experiment:\")\n",
    "for depth_config in depth_configs:\n",
    "    print(f\"\\nTesting depth configuration: {depth_config}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(depth_config) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce96bdb39bc445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:07:28.042275Z",
     "start_time": "2025-03-29T06:06:44.115539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing width configuration: [5]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7432142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.7432142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing width configuration: [15]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8022142857142858\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8022142857142858\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing width configuration: [30]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8432857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8432857142857143\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Width Variations Experiment:\")\n",
    "for width in width_configs:\n",
    "    print(f\"\\nTesting width configuration: {width}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=width,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=width,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(width) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613282673cb7adca",
   "metadata": {},
   "source": [
    "# Pengaruh fungsi aktivasi hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b1a12acf7ac72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:07:28.059674Z",
     "start_time": "2025-03-29T06:07:28.055703Z"
    }
   },
   "outputs": [],
   "source": [
    "activation_configs = [\n",
    "    ('linear','identity'),\n",
    "    ('relu','relu'),\n",
    "    ('sigmoid','logistic'),\n",
    "    ('tanh','tanh')\n",
    "]\n",
    "\n",
    "bonus_activation_configs = [\n",
    "    'softsign',\n",
    "    'softplus'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a0630da20efc9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:12:52.431154Z",
     "start_time": "2025-03-29T06:07:28.082268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Function Variations Experiment:\n",
      "\n",
      "Testing activation configuration: linear\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8857857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8857857142857143\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: relu\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7580714285714286\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.7580714285714286\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: sigmoid\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: tanh\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8095\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8095\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Activation Function Variations Experiment:\")\n",
    "for act_custom, act_sklearn in activation_configs:\n",
    "    print(f\"\\nTesting activation configuration: {act_custom}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=act_sklearn,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[act_custom] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8078fd0146278d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:14:03.739050Z",
     "start_time": "2025-03-29T06:12:52.489458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing activation configuration: softsign\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[ 0.34849682,  0.20366047,  0.14421766, ..., -0.11011714,\n",
      "         0.85692686, -0.20459601],\n",
      "       [ 0.43855953,  0.09489525,  0.03395932, ..., -0.07869318,\n",
      "         0.03085322, -0.7965541 ],\n",
      "       [-0.20512688,  0.14743526, -0.8297421 , ..., -0.05077973,\n",
      "        -0.49387592,  0.17818075],\n",
      "       ...,\n",
      "       [-0.6334432 , -0.34678155,  0.25855687, ..., -0.48119783,\n",
      "        -0.21261859, -0.14547339],\n",
      "       [ 0.5134772 , -0.6923477 ,  0.23591197, ...,  0.42926645,\n",
      "         0.39576954, -0.33404246],\n",
      "       [ 0.28817222, -0.24174216, -0.67546964, ..., -0.4206143 ,\n",
      "        -0.25590882, -0.3167226 ]], shape=(784, 128), dtype=float32), array([[ 0.26231116,  0.22627188,  0.23337834, ...,  0.32387826,\n",
      "        -0.35762906,  0.15279643],\n",
      "       [-0.30226976,  0.03051095,  0.4826649 , ..., -0.04104296,\n",
      "        -0.5140538 ,  0.8041288 ],\n",
      "       [-1.0443975 ,  0.4134605 ,  0.00576117, ...,  0.5646582 ,\n",
      "         0.11251439,  0.22100815],\n",
      "       ...,\n",
      "       [ 0.31304032, -0.5955745 , -0.34466562, ...,  0.09856506,\n",
      "         0.2330836 , -0.5352124 ],\n",
      "       [-0.714128  , -0.402061  ,  0.22256942, ..., -0.5886116 ,\n",
      "         0.04714872,  0.05962033],\n",
      "       [ 0.3953012 ,  0.37696984,  0.7386325 , ...,  0.3396097 ,\n",
      "         0.20317905,  0.1846546 ]], shape=(128, 64), dtype=float32), array([[-0.01097698, -0.39204717,  0.34126866, ..., -0.44136396,\n",
      "        -0.01914397,  0.48577234],\n",
      "       [-0.45033967,  0.44150946,  1.0973333 , ...,  0.04489783,\n",
      "        -0.28581965, -0.00131663],\n",
      "       [-0.29405773,  0.27663243, -0.02633004, ..., -0.36102077,\n",
      "        -0.23088397, -0.43987444],\n",
      "       ...,\n",
      "       [-0.07007778, -0.29170156,  0.05018962, ...,  0.03995779,\n",
      "        -0.70015496,  0.08813964],\n",
      "       [ 0.62896496, -0.104601  ,  0.3416828 , ...,  0.20473415,\n",
      "         1.0052451 , -0.077696  ],\n",
      "       [-0.40165582, -0.27237108,  0.5740399 , ...,  0.02129571,\n",
      "        -0.11922266, -0.07703016]], shape=(64, 32), dtype=float32), array([[ 0.7204127 ,  0.7099716 ,  0.69225806, -0.6109203 , -0.27613434,\n",
      "         0.40112773,  0.47902328, -0.55767184, -0.6259416 , -0.1573319 ],\n",
      "       [ 0.9170403 , -0.38125572,  0.22972363, -0.3299394 , -0.59638184,\n",
      "        -0.69619614,  0.7651346 , -0.37037918, -0.0203748 , -0.47461554],\n",
      "       [ 0.83770406, -0.99861836,  0.2715536 ,  0.58497053,  0.48787874,\n",
      "         0.5642876 ,  0.33043402,  0.0450808 , -0.66402847, -0.2971542 ],\n",
      "       [ 0.1197493 ,  0.1907032 ,  0.72373027,  0.41557842, -0.991384  ,\n",
      "         0.50318867, -0.58786845, -1.0777855 ,  0.77291507, -1.1044562 ],\n",
      "       [ 0.2827247 ,  0.2907327 ,  0.94386435,  0.7179124 , -0.64072365,\n",
      "        -0.12279825, -0.4846252 ,  0.80836   , -0.07239278, -0.18898241],\n",
      "       [ 0.58971167, -0.67847794,  0.4483067 ,  1.153679  , -0.820612  ,\n",
      "         0.55143875, -0.202845  ,  0.32297128,  0.49067575,  0.34987888],\n",
      "       [-0.09280388,  0.3492394 ,  0.904619  ,  0.290804  , -0.23271953,\n",
      "         0.12079979, -0.3649038 ,  0.3439376 ,  0.30045256,  0.6159471 ],\n",
      "       [-0.5354497 , -0.26516852, -0.27697515, -0.8514674 ,  0.6712096 ,\n",
      "        -0.18421718, -0.5342671 , -0.646691  , -0.08797527, -0.7688181 ],\n",
      "       [ 0.5668009 , -0.20420077, -0.39120963,  0.5754258 , -0.18239327,\n",
      "        -0.16648374, -0.31866306,  1.1457775 , -0.26645812,  0.17452592],\n",
      "       [ 0.24921803,  0.14576587, -0.50916237,  0.06602102, -0.4467171 ,\n",
      "         0.5543709 ,  0.67179394, -0.41606414,  0.04705325, -0.12727802],\n",
      "       [ 0.04826403,  0.26530164,  0.781513  , -1.1369802 ,  0.20986941,\n",
      "        -0.9059248 ,  0.25102717, -0.4265922 ,  0.3835998 ,  0.42520526],\n",
      "       [-0.52382386, -0.30472362,  0.09557163, -0.45449767, -0.04246317,\n",
      "         0.39942583, -0.01698017, -0.36510253, -0.39326105, -0.60464144],\n",
      "       [-0.3850442 ,  0.4824293 ,  0.31405854,  0.19889323,  0.4759223 ,\n",
      "        -1.0478141 ,  0.6489551 ,  0.34936678, -0.925907  ,  0.6276769 ],\n",
      "       [-0.91379994, -0.22309966, -0.16849779,  0.81454957,  0.23518014,\n",
      "         0.10596516, -0.7416873 ,  0.28009805, -0.3829065 , -0.03763701],\n",
      "       [-0.24763964, -0.29722586,  0.36308882,  0.8860922 ,  0.12226193,\n",
      "         0.47546384, -0.01922692, -0.1523951 , -0.05291554, -0.2079673 ],\n",
      "       [-1.483457  , -0.04348015,  0.54778653, -0.2155732 ,  0.44437858,\n",
      "        -0.7403645 ,  0.86409473, -0.84253085,  0.16756593, -0.09903429],\n",
      "       [ 0.29531106,  0.5942569 , -0.8009987 , -0.20736799, -0.14429502,\n",
      "         0.14975129,  0.23702855, -0.32908502, -0.20407826,  0.09282242],\n",
      "       [-0.83703566,  0.13055521, -0.08705625, -1.1279304 ,  0.44131947,\n",
      "         0.6495838 , -0.03987997,  0.23644815,  0.20671166,  0.09117576],\n",
      "       [ 0.6448284 ,  0.8197347 ,  0.1739718 ,  0.2718735 , -0.41101384,\n",
      "         0.5439576 ,  0.95456505, -0.28252754, -0.09568114, -0.9123923 ],\n",
      "       [ 0.34086248,  0.5755959 ,  0.11127857,  0.05859969,  0.61362624,\n",
      "        -0.8526508 , -0.00527131,  0.76980203, -0.24926631,  0.30326664],\n",
      "       [ 0.1277646 , -0.6877366 , -0.57429105,  0.35579032,  0.04529991,\n",
      "         0.17108971, -0.07515186, -0.40237787,  0.2135834 ,  0.47240144],\n",
      "       [-0.8800322 ,  0.7484577 ,  0.6265876 ,  0.1055163 ,  0.4162778 ,\n",
      "         0.25211826, -0.08330514, -0.5420597 , -0.26711088, -0.5796081 ],\n",
      "       [ 0.23622194,  0.38853624, -0.37822375,  0.7115558 , -0.6243243 ,\n",
      "        -1.3252033 ,  0.02135982,  0.76002175,  0.02737786, -0.6571119 ],\n",
      "       [-0.35177925,  1.0424314 , -0.4518832 , -0.58684206, -0.0633937 ,\n",
      "         0.07116549, -0.70361584,  0.14227147,  0.5006534 ,  0.26803416],\n",
      "       [-0.17366143,  0.6949363 , -0.36704567, -0.8878293 , -0.39850032,\n",
      "        -0.0125149 , -0.12362846,  0.557051  , -0.93291587, -0.4505507 ],\n",
      "       [ 1.2563694 , -0.28107965, -0.2827237 , -0.9006139 ,  0.5401524 ,\n",
      "        -0.3898525 ,  0.80899787, -0.10066852, -0.8509776 ,  0.4827818 ],\n",
      "       [-0.088278  , -0.7226324 ,  0.5763182 , -0.57898456, -0.229248  ,\n",
      "        -0.09635891,  0.33073595,  0.54626995,  0.4034258 , -0.19533426],\n",
      "       [-0.53901434,  0.5742987 , -0.6313185 ,  0.64762175, -0.09365759,\n",
      "        -0.5258117 ,  0.344772  ,  0.09973102, -0.12827821,  0.794588  ],\n",
      "       [ 0.17852451, -0.22931182,  0.11215305, -0.4395629 ,  0.22604047,\n",
      "        -0.79445165,  0.03639711, -0.8455266 , -0.15694278, -0.7006492 ],\n",
      "       [-0.10984758, -0.07025682,  0.53138477,  0.10594755,  0.34747115,\n",
      "        -0.46252462,  0.5969733 , -0.34052768,  0.705917  , -0.79314363],\n",
      "       [-0.39587143,  0.6760719 ,  0.6192406 ,  0.4888085 , -0.9901978 ,\n",
      "        -0.37328103, -1.514959  , -0.20117919,  0.3509496 , -0.43621555],\n",
      "       [-0.51432526,  0.00227906, -0.00676178,  0.3264588 , -0.9080701 ,\n",
      "         0.07512802,  0.8013514 ,  0.07614506, -0.5196732 , -0.5350921 ]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[ 3.94492447e-01, -2.68388569e-01,  5.13341188e-01,\n",
      "        -3.00914466e-01, -7.00361729e-01,  1.39981136e-01,\n",
      "         5.29237926e-01,  4.33071226e-01,  4.38125372e-01,\n",
      "         3.27909648e-01, -1.34062201e-01, -2.24144787e-01,\n",
      "        -4.42302078e-01,  5.21468461e-01, -5.79003215e-01,\n",
      "        -4.67626303e-02, -1.91827968e-01, -8.91853690e-01,\n",
      "        -7.51000524e-01,  1.25623032e-01,  4.13721710e-01,\n",
      "        -4.63612437e-01,  2.96183139e-01, -4.72440898e-01,\n",
      "        -8.38857591e-01, -5.12665331e-01,  9.24483314e-02,\n",
      "        -9.50426579e-01,  9.65727307e-03,  1.47182748e-01,\n",
      "        -4.36681837e-01,  7.29103386e-01,  1.69297144e-01,\n",
      "        -3.39709610e-01, -5.58925748e-01, -9.89288032e-01,\n",
      "        -2.75809944e-01, -1.17612943e-01,  5.78496158e-01,\n",
      "        -7.79117793e-02, -4.92569096e-02, -6.30719244e-01,\n",
      "        -5.52588142e-02,  9.54769959e-04,  3.43548097e-02,\n",
      "         3.08365345e-01, -6.81464195e-01, -6.57052994e-01,\n",
      "         4.37798709e-01,  1.86958238e-01,  6.09728098e-01,\n",
      "        -1.12525070e+00,  7.40925595e-02, -5.50561488e-01,\n",
      "        -2.89281011e-01,  4.71602261e-01, -3.70885760e-01,\n",
      "         8.19538713e-01,  7.11581230e-01, -8.09975922e-01,\n",
      "        -2.76097417e-01, -1.42280839e-03,  7.69419312e-01,\n",
      "        -3.03679556e-01, -3.71441548e-03, -7.66071737e-01,\n",
      "        -9.18572307e-01,  3.32261860e-01, -3.32445055e-01,\n",
      "        -1.00659914e-01, -4.02111039e-02, -6.82542846e-02,\n",
      "         6.53434932e-01, -1.43058911e-01,  3.56220543e-01,\n",
      "         6.47645652e-01,  3.97290796e-01, -4.95959520e-01,\n",
      "         2.58716196e-01, -3.98846805e-01,  6.50611937e-01,\n",
      "         6.90776885e-01,  1.39335677e-01,  8.19832206e-01,\n",
      "         7.99369693e-01,  6.58770859e-01,  3.41742784e-01,\n",
      "        -1.40575528e-01, -7.14725494e-01,  1.08324796e-01,\n",
      "         5.94543032e-02,  4.45702642e-01, -1.21275030e-01,\n",
      "         4.10327464e-01,  9.49784458e-01,  3.54100734e-01,\n",
      "         2.96718460e-02,  3.07525117e-02, -6.86832547e-01,\n",
      "        -1.28142715e-01, -1.67352498e-01,  2.41211846e-01,\n",
      "         1.25670359e-01, -2.48657495e-01, -2.86309253e-02,\n",
      "        -1.93881154e-01,  4.19597596e-01, -7.43409693e-02,\n",
      "         7.01713264e-01, -2.43993804e-01, -5.89550674e-01,\n",
      "        -1.02329135e+00, -4.06341195e-01,  4.59501773e-01,\n",
      "         8.30461979e-01,  3.99443746e-01, -2.20399141e-01,\n",
      "         1.15382262e-01, -9.99832511e-01,  9.93705615e-02,\n",
      "        -8.52853775e-01, -5.85266292e-01,  1.34050339e-01,\n",
      "        -9.40899923e-02,  6.22380197e-01, -1.24202333e-01,\n",
      "        -7.49958336e-01,  4.60065961e-01]], dtype=float32), array([[ 0.57229245, -0.4921641 , -0.02047594, -0.11161993, -0.14837055,\n",
      "         0.67375875, -0.16336799, -0.11275502, -0.68413556, -0.45838147,\n",
      "        -0.19903079, -0.50133336,  0.5108807 , -0.15276337,  0.09734812,\n",
      "         0.40165958,  0.3345365 , -0.07078214,  0.1345577 ,  0.39173922,\n",
      "        -0.5185641 , -0.23932557,  0.8959845 , -0.26165777, -0.11799584,\n",
      "        -0.3322507 ,  0.1984471 , -0.25416863, -0.3084513 , -0.4509186 ,\n",
      "         0.04308396, -0.8567555 ,  0.25783396,  0.6958684 ,  0.13590874,\n",
      "        -0.34085736,  0.4041951 ,  0.27035877, -0.374453  , -0.29089427,\n",
      "         0.3782791 ,  0.26549035,  0.62670785,  0.35680193, -0.31367528,\n",
      "         0.24909583, -0.60611004,  0.36518577,  0.27569142, -0.50282395,\n",
      "         0.6430617 ,  0.28042766,  0.4477292 ,  0.7115216 , -0.30274227,\n",
      "        -0.6049151 , -0.13252312,  0.3566628 ,  0.3981432 , -0.10195444,\n",
      "         0.17771171, -0.00163098,  0.46093804, -0.44854707]],\n",
      "      dtype=float32), array([[-0.67529637,  0.14935479,  0.9539334 ,  0.80657315,  0.05500464,\n",
      "         0.16428562,  0.49200463, -0.07846101,  0.09219555, -0.10993982,\n",
      "         0.7921933 ,  0.09185998,  0.08743745,  1.0153522 ,  0.42775092,\n",
      "         0.14131035, -0.55989796, -1.0037374 , -0.4519436 , -0.4843997 ,\n",
      "         0.38699013,  0.04907554, -0.62295645,  0.23897855,  0.05980467,\n",
      "        -0.0927083 ,  0.2675723 ,  0.53416723, -0.8177954 ,  0.74935466,\n",
      "         0.5718863 , -0.2565842 ]], dtype=float32), array([[-0.47766176, -0.5079046 ,  0.15333942, -0.55035883, -0.27512988,\n",
      "         0.7785856 , -0.09687501,  0.3779984 ,  0.24427278, -0.47351688]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 9 1]\n",
      "Prediction Probability:\n",
      " [[1.33431092e-06 1.07835873e-03 1.49960853e-02 ... 5.61885681e-05\n",
      "  9.75956321e-01 3.98957217e-03]\n",
      " [4.46932245e-06 1.75458030e-04 4.19499956e-05 ... 1.37302547e-03\n",
      "  1.86689699e-03 6.61709979e-02]\n",
      " [2.62662908e-03 2.15866603e-02 7.21748732e-03 ... 1.48233585e-03\n",
      "  7.10108578e-02 3.42200436e-02]\n",
      " ...\n",
      " [1.02461036e-03 1.14386678e-01 7.50571370e-01 ... 2.27898220e-03\n",
      "  1.15592904e-01 5.23065450e-04]\n",
      " [5.81721179e-05 2.13948879e-04 3.72437171e-05 ... 4.72946167e-01\n",
      "  2.87145085e-04 5.22811949e-01]\n",
      " [2.98266878e-06 9.90340889e-01 4.89238882e-03 ... 1.84297969e-04\n",
      "  3.70660750e-03 8.56325714e-05]]\n",
      "Loss:\n",
      " [1.7462277629741472, 1.0167035364979977, 0.8207294853839009, 0.7150969054440373, 0.644987641286893, 0.5938691025455589, 0.5544488577655062, 0.5227499853430485, 0.49640787828423344, 0.47396729994348225, 0.4544989210709601, 0.4372607014766049, 0.421835251327764, 0.4079676841574533, 0.39544551550415463]\n",
      "Accuracy:\n",
      " 0.8529285714285715\n",
      "\n",
      "Testing activation configuration: softplus\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\src\\lib\\FFNNClassifier.py:114: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log(1 + np.exp(x))\n",
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\src\\lib\\FFNNClassifier.py:286: RuntimeWarning: invalid value encountered in matmul\n",
      "  a_k = b_k + (h_k_min_1 @ w_k) # numpy will automatically broadcast b_k (row will be copied to match the result from dot) so that this is addable\n",
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\src\\lib\\FFNNClassifier.py:109: RuntimeWarning: invalid value encountered in subtract\n",
      "  exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]],\n",
      "      shape=(784, 128), dtype=float32), array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]],\n",
      "      shape=(128, 64), dtype=float32), array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]], shape=(64, 32), dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)]\n",
      "Biases:\n",
      " [array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "      dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "      dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan]], dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)]\n",
      "Prediction:\n",
      " [0 0 0 ... 0 0 0]\n",
      "Prediction Probability:\n",
      " [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Loss:\n",
      " [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Accuracy:\n",
      " 0.09592857142857143\n"
     ]
    }
   ],
   "source": [
    "for act_custom in bonus_activation_configs:\n",
    "    print(f\"\\nTesting activation configuration: {act_custom}\")\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[act_custom] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_scratch_output(custom_mlp, X_train_scaled, y_train_one_hot, X_test_scaled, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403053e9c150dd1",
   "metadata": {},
   "source": [
    "# Pengaruh learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67ad2a321d25bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:14:03.775155Z",
     "start_time": "2025-03-29T06:14:03.772185Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.06, 0.006, 0.0009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b21ff3b736552045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:19:32.880447Z",
     "start_time": "2025-03-29T06:14:03.841971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate Variations Experiment:\n",
      "\n",
      "Testing activation configuration: 0.1\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.06\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.006\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.0009\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Rate Variations Experiment:\")\n",
    "for rate in learning_rates:\n",
    "    print(f\"\\nTesting activation configuration: {rate}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb9cda56cd61b7",
   "metadata": {},
   "source": [
    "# Perbandingan Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34d5132af2f90c41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:19:32.916302Z",
     "start_time": "2025-03-29T06:19:32.912598Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_configs =  ['normal', 'zero', 'uniform']\n",
    "additional_weight_configs = [\"xavier_normal\",\"xavier_uniform\",\"he_normal\",\"he_uniform\"]\n",
    "max_iter_weight_test = 5 # The library version for zero ini converges so fast so it stops and the custom one won't stop until max_iter is reached so we need a new smaller one just for this test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5c0d65e76b4a222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:22:53.891454Z",
     "start_time": "2025-03-29T06:19:32.967075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Variations Experiment:\n",
      "\n",
      "Testing weight configuration: normal\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7144285714285714\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.7144285714285714\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing weight configuration: zero\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing weight configuration: uniform\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight Variations Experiment:\")\n",
    "for weight_config in weight_configs:\n",
    "    print(f\"\\nTesting weight configuration: {weight_config}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter_weight_test,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter_weight_test,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab226cab1800ddfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:25:36.174943Z",
     "start_time": "2025-03-29T06:22:53.923367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Variations Experiment:\n",
      "\n",
      "Testing weight configuration: xavier_normal\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[ 0.03708485,  0.02166989,  0.01534337, ..., -0.01172553,\n",
      "         0.09119716, -0.02178094],\n",
      "       [ 0.04667024,  0.01009398,  0.00360856, ..., -0.00838107,\n",
      "         0.00327797, -0.08478315],\n",
      "       [-0.02183744,  0.01568583, -0.08831536, ..., -0.00541024,\n",
      "        -0.05256906,  0.01895807],\n",
      "       ...,\n",
      "       [-0.06742322, -0.03691377,  0.02751252, ..., -0.05121972,\n",
      "        -0.02263478, -0.0154885 ],\n",
      "       [ 0.05464375, -0.07369245,  0.02510242, ...,  0.04568118,\n",
      "         0.04211609, -0.03555795],\n",
      "       [ 0.03066449, -0.02573441, -0.07189611, ..., -0.04477181,\n",
      "        -0.02724217, -0.03371459]], shape=(784, 128), dtype=float32), array([[ 0.07391855,  0.0976223 ,  0.09520578, ...,  0.12700953,\n",
      "        -0.18755   ,  0.1173275 ],\n",
      "       [-0.14079145, -0.02479144,  0.10170959, ..., -0.10474103,\n",
      "        -0.08239645,  0.21884479],\n",
      "       [-0.3020406 ,  0.08188851, -0.00455378, ...,  0.08547568,\n",
      "         0.03392956,  0.10718076],\n",
      "       ...,\n",
      "       [ 0.02982106, -0.1196256 , -0.1213874 , ..., -0.00797964,\n",
      "         0.0950224 , -0.06457277],\n",
      "       [-0.25644332, -0.10264299,  0.08600095, ..., -0.25581792,\n",
      "         0.10702765,  0.06735583],\n",
      "       [ 0.05496527,  0.0795176 ,  0.12153865, ...,  0.08695513,\n",
      "         0.04303795,  0.11744409]], shape=(128, 64), dtype=float32), array([[ 0.08118649,  0.0071267 ,  0.17593232, ...,  0.03730544,\n",
      "        -0.22139601,  0.14148863],\n",
      "       [ 0.08294478,  0.15585697,  0.43094796, ...,  0.07676566,\n",
      "        -0.11778941,  0.03955486],\n",
      "       [-0.00703982,  0.1726818 ,  0.1884085 , ..., -0.18066032,\n",
      "        -0.28278363, -0.18258478],\n",
      "       ...,\n",
      "       [-0.03957481,  0.00111937,  0.09579926, ...,  0.15178087,\n",
      "        -0.44295752, -0.16502449],\n",
      "       [ 0.3420799 , -0.14532997,  0.00322333, ...,  0.02097212,\n",
      "         0.5555436 , -0.10756958],\n",
      "       [-0.19098534,  0.08991858,  0.41303417, ...,  0.2084369 ,\n",
      "        -0.21118176, -0.14570181]], shape=(64, 32), dtype=float32), array([[ 0.44068897,  0.7504395 ,  0.603281  , -0.20553316, -0.5298011 ,\n",
      "         0.2080379 ,  0.16459973,  0.18084492, -0.97298986, -0.25557917],\n",
      "       [ 0.9135727 , -0.87639093, -0.03708228, -0.24004948,  0.14501797,\n",
      "         0.0157495 ,  0.55877095, -0.48409927, -0.0708368 , -0.39966452],\n",
      "       [ 1.2311147 , -1.4103544 , -0.29576534, -0.16487245,  0.5500181 ,\n",
      "         1.118114  ,  0.7173421 ,  0.09635702, -0.8507204 , -0.41514686],\n",
      "       [ 0.22845997,  0.15503897,  1.1816965 ,  0.795725  , -1.1615728 ,\n",
      "         0.5136255 , -0.4067576 , -1.3467233 ,  0.8817272 , -1.3551201 ],\n",
      "       [-0.07072268,  0.25414678,  0.08506779,  0.4561234 , -0.33681643,\n",
      "         0.30689788, -0.52118903,  0.7709103 ,  0.04602546, -0.22989053],\n",
      "       [ 0.8781735 , -0.92543447,  0.1622693 ,  1.0415792 , -1.1673183 ,\n",
      "         0.62833714, -0.5791901 ,  0.17580712,  0.65337855,  0.22556368],\n",
      "       [-0.86633927,  0.5232919 , -0.61492354,  0.12778303,  0.3831565 ,\n",
      "         0.5817342 , -1.3227981 ,  0.69724697,  0.86869276,  0.7305189 ],\n",
      "       [ 0.12825662, -0.813555  , -0.10613627, -0.81386185,  0.33364314,\n",
      "         0.24431746, -0.11771689, -0.495793  ,  0.34432733, -0.4295646 ],\n",
      "       [ 0.9972851 , -0.9816736 , -1.1709228 ,  0.87257475, -0.66629314,\n",
      "         0.1891118 , -1.1499399 ,  1.2709564 ,  0.22673744,  0.8746785 ],\n",
      "       [ 0.36825436, -0.3108369 ,  0.18075038,  0.47149062, -0.8203315 ,\n",
      "         0.25034758,  0.66735864, -0.60979784,  0.14025526, -0.22120821],\n",
      "       [-0.03122089,  0.04491148,  0.38954753, -1.0833998 ,  0.6336714 ,\n",
      "        -0.86590254,  0.6464669 , -0.46610078,  0.02689255,  0.65293676],\n",
      "       [-0.71030676,  0.23779088,  0.15741017, -0.30408347, -0.30484816,\n",
      "         0.5476782 , -0.39701593, -0.17006665,  0.12286535, -0.27598011],\n",
      "       [-0.46207848,  0.46317488, -0.20426576, -0.42268983,  0.8605817 ,\n",
      "        -0.7639962 ,  0.678859  ,  0.48790878, -1.0600762 ,  0.78858864],\n",
      "       [-1.0978291 ,  0.29841635, -0.7649255 ,  1.095653  ,  0.1553274 ,\n",
      "         0.14828409, -1.3692504 ,  0.7446396 , -0.3878684 ,  0.6655471 ],\n",
      "       [ 0.29067045, -0.5142096 ,  0.10399386,  1.2818667 , -0.52580786,\n",
      "         0.9935453 , -0.5083796 , -0.18244332, -0.01592353, -0.49232972],\n",
      "       [-1.8196719 ,  0.2781343 ,  0.65738314,  0.14452422,  0.62035227,\n",
      "        -0.95970476,  0.5924612 , -1.1881415 ,  0.66765815,  0.31211084],\n",
      "       [ 0.6113172 , -0.14684463, -0.68612623, -0.5095826 ,  0.35012317,\n",
      "        -0.11148769,  0.29837275,  0.11851034, -0.6282854 ,  0.5466973 ],\n",
      "       [-0.9292559 ,  0.03730313, -0.00713666, -1.0544116 ,  0.5807091 ,\n",
      "         0.1973358 ,  0.03066563, -0.0260459 ,  0.5326009 ,  0.47128227],\n",
      "       [ 0.81821626,  0.2667205 ,  0.71583116,  0.03563537, -0.7232283 ,\n",
      "         0.29246655,  1.1181381 , -0.5286495 , -0.34670815, -0.8019497 ],\n",
      "       [-0.32122552,  0.17416137, -0.12744966, -0.25447762,  0.95707715,\n",
      "        -0.4751982 , -0.12023502,  0.6418417 , -0.07816061,  0.42957625],\n",
      "       [ 0.4277854 , -1.09532   , -0.7356988 , -0.28779867,  0.40544865,\n",
      "         0.6325287 , -0.06065343, -0.38818356,  0.23350519,  0.692738  ],\n",
      "       [-1.0312185 ,  0.9734295 ,  0.9725203 ,  0.6102257 , -0.06575531,\n",
      "         0.2730225 , -0.4900247 , -0.6751408 ,  0.00489779, -0.67298394],\n",
      "       [-0.10747845,  0.5323518 , -0.59603035,  0.5214167 , -0.61844206,\n",
      "        -1.1167238 , -0.48982945,  1.5179391 , -0.00771379, -0.05225237],\n",
      "       [-0.57656807,  0.95208263, -0.3756385 , -0.77542114,  0.05605681,\n",
      "        -0.13965134, -0.63497657,  0.49392888,  0.5684345 ,  0.36554423],\n",
      "       [-0.75474745,  1.087417  , -0.5475566 , -0.53619254, -0.13698663,\n",
      "        -0.28428257, -0.61630005,  0.8722423 , -0.47252727,  0.34982276],\n",
      "       [ 1.4934213 , -1.0768561 , -0.58061785, -1.2015674 ,  0.7989028 ,\n",
      "        -0.16168854,  1.0494277 , -0.16068406, -0.7422745 ,  0.721713  ],\n",
      "       [-0.03880057, -0.83016914,  0.9209511 , -0.9412293 ,  0.47844478,\n",
      "        -0.40257388,  0.7093605 , -0.24333538,  0.37682012, -0.05656492],\n",
      "       [-0.2262936 ,  0.07848483, -0.33843568,  0.46660075, -0.03532575,\n",
      "         0.04725403,  0.23380823, -0.15230566, -0.1609468 ,  0.35616112],\n",
      "       [ 0.29093224, -0.47210926,  0.6320277 , -0.7538138 ,  0.52628773,\n",
      "        -0.1072223 ,  0.42895424, -1.2329301 ,  0.21904571, -0.82752997],\n",
      "       [-0.29654327, -0.22932647,  0.4751795 , -0.19051167,  0.22112212,\n",
      "        -0.30257648,  0.575927  , -0.27329463,  0.5178084 , -0.24442302],\n",
      "       [-0.81478643,  1.3551807 ,  0.6983902 ,  0.8115054 , -0.97982603,\n",
      "        -0.70990205, -1.4698317 ,  0.08154657,  0.6768039 , -0.5304637 ],\n",
      "       [-0.9805764 ,  0.52396965, -0.01462432,  0.7717676 , -0.77362967,\n",
      "        -0.31195346,  0.2511442 ,  0.5058843 , -0.39442846, -0.17423412]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[ 0.04058427, -0.05959123,  0.05615464, -0.04372266, -0.10319415,\n",
      "        -0.03688085,  0.03770246,  0.04627938, -0.01931207,  0.01894381,\n",
      "        -0.04979936,  0.03507194, -0.06303021,  0.04787599, -0.06874716,\n",
      "        -0.01206857,  0.01169743, -0.08226722, -0.09074818,  0.00383326,\n",
      "         0.02910717, -0.08036447,  0.08999767, -0.13258143, -0.09125937,\n",
      "        -0.0522415 , -0.01147121, -0.09559491,  0.00419744,  0.00298378,\n",
      "         0.00789816,  0.07987943,  0.01413287, -0.03205602, -0.07514531,\n",
      "        -0.1078108 , -0.03154014,  0.06029737,  0.04189657, -0.03453885,\n",
      "        -0.00308995, -0.05552381,  0.01892111, -0.02036132, -0.01376832,\n",
      "         0.04174046, -0.06112448, -0.09329633,  0.03383563,  0.00277318,\n",
      "         0.07283816, -0.12124646, -0.02450467, -0.06835894, -0.04174323,\n",
      "         0.0790077 , -0.04983294,  0.07021482,  0.08509946, -0.06765082,\n",
      "         0.00788253,  0.0221299 ,  0.11949938, -0.06218069, -0.03651457,\n",
      "        -0.11345983, -0.07027812,  0.05066279, -0.04815622, -0.00695932,\n",
      "        -0.02651685,  0.00569781,  0.06580029, -0.00180536,  0.04876673,\n",
      "         0.07207763,  0.04187695, -0.05972267,  0.02162155, -0.02778659,\n",
      "         0.05066432,  0.08713359,  0.00943677,  0.0529476 ,  0.10562756,\n",
      "         0.07009826,  0.01553142, -0.01637008, -0.05502266,  0.03061707,\n",
      "         0.02560081,  0.07788665,  0.02739773,  0.08427389,  0.09250577,\n",
      "         0.05655501,  0.02027885, -0.01057617, -0.11910563, -0.01992379,\n",
      "         0.01484748,  0.00435318,  0.03348789, -0.03542526, -0.01331402,\n",
      "        -0.02860321,  0.034058  ,  0.00706719,  0.0763286 ,  0.01027681,\n",
      "        -0.05263587, -0.07983286,  0.00548713,  0.07815193,  0.06431785,\n",
      "         0.01081917, -0.00275263, -0.01466291, -0.10319364,  0.00513195,\n",
      "        -0.03903161, -0.03712452,  0.0261266 ,  0.01325016,  0.03957788,\n",
      "        -0.01402752, -0.10084792,  0.00890958]], dtype=float32), array([[ 0.10977556, -0.10059822, -0.03895598,  0.04046099, -0.04253783,\n",
      "         0.14515342, -0.00677052, -0.0344807 , -0.11961757, -0.13400787,\n",
      "        -0.03053981, -0.09892493,  0.1056229 , -0.03983799,  0.07009868,\n",
      "         0.07321403,  0.0474694 , -0.05055331,  0.07805353,  0.06737486,\n",
      "        -0.09602978, -0.04973134,  0.18773356, -0.03166308, -0.00662237,\n",
      "        -0.08941416,  0.03411359, -0.00758042, -0.05675077, -0.10253975,\n",
      "         0.04246084, -0.13155416,  0.0374222 ,  0.12547468,  0.05635586,\n",
      "        -0.0433191 ,  0.05100149,  0.06509502, -0.14055939, -0.04501257,\n",
      "         0.11420023,  0.05489393,  0.13914089,  0.07806937, -0.08761612,\n",
      "         0.02616668, -0.12572116,  0.06245978,  0.05212777, -0.07099095,\n",
      "         0.13364993, -0.01174188,  0.07167175,  0.09955091, -0.06858405,\n",
      "        -0.1182358 , -0.01343045,  0.04971243,  0.10273464, -0.06712169,\n",
      "         0.09557631, -0.02384842,  0.09144092, -0.08973415]],\n",
      "      dtype=float32), array([[-0.11203039, -0.00990382,  0.25000155,  0.19183594,  0.0649179 ,\n",
      "        -0.06356146,  0.22555818, -0.04910839,  0.12169559, -0.06095064,\n",
      "         0.17492017,  0.10787683, -0.02868339,  0.31540596,  0.07841744,\n",
      "         0.01866751, -0.07696208, -0.32550988, -0.10343158, -0.14900762,\n",
      "         0.11055017, -0.0526305 , -0.17653035,  0.09484212,  0.08285122,\n",
      "         0.02576355,  0.03716519,  0.16638051, -0.21915703,  0.2621966 ,\n",
      "         0.16445944, -0.08115393]], dtype=float32), array([[-0.05330702, -0.24939875, -0.24110077, -0.2549082 ,  0.03052432,\n",
      "         0.5084042 , -0.10286681,  0.25629956,  0.1152558 , -0.41944686]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 9 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[2.45589385e-04 3.49769834e-03 3.09234187e-02 ... 1.26777519e-03\n",
      "  8.70947897e-01 3.64503777e-03]\n",
      " [6.02544402e-04 5.60475048e-04 2.46264943e-04 ... 2.22281050e-02\n",
      "  6.86765043e-03 5.20308554e-01]\n",
      " [1.66749910e-01 1.53540634e-04 1.02185775e-02 ... 5.85482456e-03\n",
      "  1.38419196e-01 8.22095126e-02]\n",
      " ...\n",
      " [1.85168217e-04 7.47121125e-02 7.23175585e-01 ... 4.37574607e-04\n",
      "  1.61829114e-01 6.72446040e-04]\n",
      " [4.00377001e-04 2.60434137e-03 2.19039448e-05 ... 8.03809106e-01\n",
      "  1.72874541e-03 1.79571331e-01]\n",
      " [1.15448029e-06 9.53269303e-01 6.62106182e-03 ... 1.93188600e-02\n",
      "  7.92974140e-03 4.47712373e-03]]\n",
      "Loss:\n",
      " [2.281686614043999, 2.2042285471326846, 2.0313438073907, 1.7418863725920581, 1.4218034491624894, 1.1596992674282913, 0.9755971165155528, 0.8540421450243171, 0.7683037428259817, 0.6995648186359688, 0.6397848338553591, 0.5877439499470783, 0.5437873689627718, 0.506993479119856, 0.47578481580390136]\n",
      "Accuracy:\n",
      " 0.8744285714285714\n",
      "\n",
      "Testing weight configuration: xavier_uniform\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[-0.03305275,  0.0501374 , -0.02429225, ...,  0.02820321,\n",
      "        -0.0742396 , -0.02735013],\n",
      "       [-0.01061948,  0.06305447, -0.01122776, ...,  0.07354817,\n",
      "         0.03294739,  0.04075682],\n",
      "       [-0.04899646, -0.07805746, -0.01479703, ...,  0.03194785,\n",
      "        -0.07691698, -0.03161498],\n",
      "       ...,\n",
      "       [ 0.01327801,  0.03140747, -0.01201645, ...,  0.03190882,\n",
      "        -0.06375924, -0.0512519 ],\n",
      "       [-0.07493388,  0.02775719, -0.07658998, ..., -0.0685322 ,\n",
      "        -0.05535953, -0.06647736],\n",
      "       [ 0.04121297, -0.07026012, -0.06708209, ..., -0.05890622,\n",
      "        -0.01295747, -0.0397816 ]], shape=(784, 128), dtype=float32), array([[-0.16108637,  0.11088489, -0.08732932, ..., -0.10940838,\n",
      "        -0.16863614,  0.04475698],\n",
      "       [-0.10655601, -0.03367241,  0.17811865, ..., -0.06555834,\n",
      "         0.18965234,  0.06204842],\n",
      "       [ 0.13995329, -0.05319923, -0.02770123, ..., -0.16845018,\n",
      "        -0.20545688, -0.00152359],\n",
      "       ...,\n",
      "       [ 0.19415905,  0.2376569 ,  0.03534824, ...,  0.15713303,\n",
      "        -0.02693848, -0.01725004],\n",
      "       [-0.05555837, -0.20332891, -0.1155934 , ...,  0.04616052,\n",
      "        -0.18606645,  0.13806894],\n",
      "       [-0.10647612,  0.32366675, -0.12172277, ..., -0.05523482,\n",
      "        -0.00052215, -0.15717447]], shape=(128, 64), dtype=float32), array([[-0.35786277, -0.05608181, -0.3241083 , ..., -0.20192169,\n",
      "         0.4531497 , -0.09238674],\n",
      "       [ 0.2743728 ,  0.07036254,  0.218445  , ...,  0.13331409,\n",
      "        -0.0733185 ,  0.12590542],\n",
      "       [ 0.2419151 , -0.08189201,  0.10245009, ..., -0.15054885,\n",
      "         0.28245085, -0.29724807],\n",
      "       ...,\n",
      "       [ 0.06405595, -0.10332213, -0.16509615, ..., -0.15810837,\n",
      "        -0.02440266, -0.32751435],\n",
      "       [ 0.10462112,  0.46412593,  0.30716038, ...,  0.25017715,\n",
      "        -0.1302622 ,  0.44460613],\n",
      "       [ 0.0890357 ,  0.24756132,  0.01386613, ...,  0.21222292,\n",
      "         0.39716858,  0.30438447]], shape=(64, 32), dtype=float32), array([[-1.2771173 ,  0.7471583 ,  0.00216313,  0.2798144 ,  0.39397764,\n",
      "        -0.03263007, -0.403091  , -0.39339656,  0.9559174 ,  0.14932306],\n",
      "       [-1.3213111 ,  1.089869  ,  0.1940948 ,  0.751874  , -0.87480515,\n",
      "         0.13865301, -0.44707307, -0.31486547,  0.4862618 , -0.7005649 ],\n",
      "       [-0.5927613 ,  0.95421803, -0.1493758 ,  0.5432004 , -0.11501697,\n",
      "        -0.12091109, -0.5719285 , -0.10614676,  0.4767591 ,  0.5550126 ],\n",
      "       [ 0.04966174, -0.9626101 , -0.51140624,  0.37564352,  0.33601436,\n",
      "         0.479826  ,  0.37008795,  0.01746822, -0.4026857 ,  0.6756137 ],\n",
      "       [ 0.36227033,  0.10130625,  0.7407507 ,  0.3492728 , -0.87874377,\n",
      "         0.69910127, -0.5344521 , -0.8127245 ,  1.1332462 , -0.7363722 ],\n",
      "       [-0.67353034,  0.92428523,  0.2704484 , -0.57553035,  0.6489204 ,\n",
      "        -0.69531226,  1.0964142 , -0.9721801 , -0.54808944, -0.09403259],\n",
      "       [-1.2002959 ,  0.7588266 , -0.6660693 , -0.56692266,  0.8729971 ,\n",
      "        -0.04961135, -0.46730313,  0.5101649 ,  0.9018493 ,  0.91571206],\n",
      "       [ 0.44919303,  0.4211554 ,  0.10413928,  0.29260227, -0.5463333 ,\n",
      "        -0.23826341,  0.54771006, -0.20445757, -0.48363677, -0.28375047],\n",
      "       [ 0.6353527 , -0.70453316, -0.61426675, -0.53185034, -0.4267817 ,\n",
      "         0.190054  ,  0.1217553 ,  0.06886776, -0.59777516, -0.26236093],\n",
      "       [-0.35232657,  1.1713833 ,  0.00279504,  0.918916  , -0.08181652,\n",
      "        -0.29902375, -0.525721  ,  1.0944468 , -0.5815637 ,  0.77473783],\n",
      "       [ 0.39885703, -0.8126033 , -0.4486006 , -1.3188014 ,  1.2927316 ,\n",
      "         0.08531752,  1.2223138 , -0.5152905 , -0.30077258,  0.06968953],\n",
      "       [-0.71866894,  0.9465501 ,  0.6514896 , -0.4294168 ,  0.25196096,\n",
      "        -0.7891735 ,  0.70617735, -0.6363932 ,  0.0884879 , -0.3296933 ],\n",
      "       [ 0.4218522 , -1.1366686 , -0.86775875, -0.6999161 , -0.14795692,\n",
      "         1.0563257 ,  0.24905944, -0.16513701,  0.6339217 ,  0.57525706],\n",
      "       [ 0.86785036, -0.65935165,  0.333064  ,  0.29455855, -0.10997709,\n",
      "        -0.4457507 ,  0.61092395,  0.5148442 , -0.21081057, -0.8652146 ],\n",
      "       [-0.9606621 ,  0.55274796, -0.11805524, -0.31969672,  0.4804713 ,\n",
      "        -0.2465856 , -0.48144484,  0.8998866 , -0.10816573,  0.7447265 ],\n",
      "       [ 0.20955609, -0.21683054, -0.01304169, -0.88062537,  0.6127894 ,\n",
      "         0.08002421,  1.1011025 , -0.82864887, -0.39608902, -0.04390581],\n",
      "       [ 0.6296485 , -0.78791225,  0.917418  ,  0.29224774, -0.33565927,\n",
      "         0.6569045 ,  0.663492  , -0.6639941 , -0.31305084, -0.46639118],\n",
      "       [ 0.8058041 , -0.9122817 ,  0.58642787,  0.7241584 , -0.8100431 ,\n",
      "         0.00473396,  0.5919647 , -0.25932875, -0.58209825, -0.76818085],\n",
      "       [-0.27963713, -0.32116017,  0.30590412,  0.12375616,  0.1503218 ,\n",
      "        -1.0114082 ,  0.43574262,  1.0368195 , -1.1877855 ,  0.40057454],\n",
      "       [ 0.9752459 , -1.2812612 , -0.51997924,  0.348132  , -0.49839452,\n",
      "         0.5567752 , -0.7551656 ,  0.6536583 , -0.36006373,  0.42193997],\n",
      "       [ 0.8786348 , -0.53604454, -0.85851866,  0.5472591 , -0.31482264,\n",
      "         0.39141864, -0.75781465,  0.6550589 , -0.06128842,  0.48640904],\n",
      "       [-0.00757151, -0.08341095, -0.24633424,  0.66029555, -0.7591027 ,\n",
      "         0.26435366, -0.64706737,  0.6906318 , -0.646526  ,  0.6119473 ],\n",
      "       [-1.4482601 ,  0.7027268 ,  0.566608  ,  0.03786115,  0.4537581 ,\n",
      "         0.41366744,  0.04467563, -1.1227797 ,  0.9119127 , -0.48140597],\n",
      "       [ 0.76283765, -0.36796883, -1.1461465 , -0.7767062 ,  0.51391816,\n",
      "         0.752722  , -0.7426549 ,  0.29657787,  0.14089811,  0.5261877 ],\n",
      "       [ 1.001603  , -0.98601645,  0.6486579 ,  0.9119209 , -1.0566971 ,\n",
      "         0.64880073, -0.35347077,  0.21922693, -0.10946804, -1.0908998 ],\n",
      "       [ 0.2044339 , -0.95954055, -0.34666502, -0.18649666,  0.8435571 ,\n",
      "        -0.11402029, -0.5402648 ,  0.6290034 , -0.11647103,  0.9238663 ],\n",
      "       [-0.03774748,  0.13554256,  0.5852081 , -0.39802018,  0.6899737 ,\n",
      "        -0.7868895 , -0.31862998,  0.25117585, -0.517586  ,  0.35415244],\n",
      "       [-0.18439637, -0.31686735,  0.07306788, -0.55400705,  0.49344423,\n",
      "        -0.34031945,  0.3232398 , -0.48042393, -0.19958052,  0.5334072 ],\n",
      "       [-0.8593536 , -0.1098059 , -1.3602672 , -0.16940698,  0.45348573,\n",
      "         0.42721733, -0.792509  ,  0.7277317 ,  0.86937296,  0.6237783 ],\n",
      "       [ 0.18264076, -0.25716636, -0.08928761,  0.97925276, -0.17248656,\n",
      "         0.07689438, -0.49542215,  0.13661459,  0.10747508,  0.03978503],\n",
      "       [ 0.2817967 ,  0.08019339,  0.7452948 ,  0.03203228, -0.70088595,\n",
      "         0.07503425,  0.28619897, -1.2571037 ,  0.80049497, -0.76590616],\n",
      "       [-0.47987133,  0.8250219 ,  1.0881693 ,  0.33312693, -0.7300631 ,\n",
      "        -0.04863987, -0.84148943,  0.31770605,  0.35680696, -0.6439509 ]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[-2.51495857e-02,  6.37656972e-02,  5.84896244e-02,\n",
      "         1.03398830e-01, -1.64071284e-02, -8.93265232e-02,\n",
      "        -2.55698785e-02, -1.58982091e-02,  4.01568878e-03,\n",
      "         1.37882459e-03,  1.12673006e-04, -5.86522222e-02,\n",
      "        -3.64108607e-02, -5.73935099e-02, -1.41300811e-02,\n",
      "        -1.04156606e-01, -1.32694803e-02, -8.61782487e-03,\n",
      "         3.81368697e-02,  4.89212871e-02,  1.47061497e-02,\n",
      "         7.16534629e-02,  5.94471507e-02,  3.63177769e-02,\n",
      "        -5.31596802e-02, -7.24232867e-02,  6.73298612e-02,\n",
      "         4.56308573e-02, -1.65107418e-02, -7.96990022e-02,\n",
      "        -4.46336390e-03, -9.67364833e-02,  2.43504476e-02,\n",
      "         4.03915904e-02,  5.66375665e-02,  8.69855583e-02,\n",
      "        -5.02082631e-02,  1.47002973e-02,  3.65000276e-04,\n",
      "        -9.15590078e-02,  6.90775365e-02, -7.03518465e-02,\n",
      "         4.63539474e-02, -1.08326254e-02, -1.57023054e-02,\n",
      "        -6.81358427e-02,  2.36649401e-02, -3.99074517e-02,\n",
      "        -7.62772262e-02, -5.88747077e-02,  6.11486472e-02,\n",
      "        -1.85725726e-02,  9.16562825e-02, -1.22841271e-02,\n",
      "         9.62118581e-02, -8.42782632e-02, -6.56637326e-02,\n",
      "         4.85832840e-02, -4.64519374e-02,  3.65834236e-02,\n",
      "         4.76070493e-02, -6.16627932e-02, -8.00151527e-02,\n",
      "         2.92712823e-02, -8.61103535e-02,  4.13741842e-02,\n",
      "        -4.64611948e-02,  1.56369861e-02,  6.50763363e-02,\n",
      "         4.49370593e-02,  6.91020638e-02, -7.31138065e-02,\n",
      "        -5.51150292e-02,  7.58654065e-03,  2.12985799e-02,\n",
      "         7.09635532e-03,  1.57649264e-01,  4.65520658e-02,\n",
      "         2.70156171e-02, -2.94742491e-02,  7.31868073e-02,\n",
      "        -4.82811704e-02,  6.83552772e-02,  3.85259502e-02,\n",
      "         3.21645848e-02,  2.62238607e-02, -1.97626930e-02,\n",
      "         1.81295592e-02, -6.82797283e-02,  3.39409858e-02,\n",
      "        -9.45664421e-02,  4.86131907e-02, -3.41389775e-02,\n",
      "         4.33979370e-03,  2.71080863e-02,  6.54034540e-02,\n",
      "        -3.43220565e-03,  4.48705675e-03,  3.46589796e-02,\n",
      "         6.51647225e-02,  1.36723081e-02, -4.60467488e-02,\n",
      "        -9.67065394e-02, -9.79996193e-03,  4.71126884e-02,\n",
      "         4.09032106e-02, -8.77340436e-02, -4.32009511e-02,\n",
      "        -4.35286574e-03,  3.56322117e-02,  3.33303809e-02,\n",
      "         3.63912508e-02, -2.47982703e-02, -5.53068519e-02,\n",
      "        -9.58827976e-03, -5.75947464e-02, -1.44548379e-02,\n",
      "        -1.71671659e-02, -4.44838554e-02, -2.59642042e-02,\n",
      "         7.83950165e-02, -1.27097545e-02,  4.19598520e-02,\n",
      "        -8.76911432e-02, -3.03270984e-02,  1.14738047e-02,\n",
      "         1.98460687e-02,  5.39230816e-02]], dtype=float32), array([[ 0.02996615,  0.11408096,  0.08594491, -0.0636814 ,  0.19569023,\n",
      "         0.17918567, -0.04315932, -0.03714484,  0.11961879,  0.11582212,\n",
      "         0.13925882,  0.13121517, -0.1278879 ,  0.1155023 , -0.06663744,\n",
      "         0.04133249,  0.10284159, -0.08205439,  0.02361718,  0.06898294,\n",
      "         0.13621548,  0.00204964,  0.04016381, -0.16239358, -0.00450474,\n",
      "        -0.10174643,  0.15384255, -0.16614406,  0.00727204,  0.07168525,\n",
      "         0.10805079,  0.03613798, -0.12213983,  0.04559803, -0.06933762,\n",
      "        -0.10702374,  0.14960489,  0.16402191,  0.06584219,  0.06852116,\n",
      "        -0.06279322,  0.1398318 , -0.08132309,  0.06609347,  0.04587068,\n",
      "        -0.11978331,  0.02885588,  0.04909971, -0.13051899, -0.09888163,\n",
      "         0.01690586, -0.02125611, -0.04173334, -0.14358397,  0.06171134,\n",
      "        -0.01741141,  0.14971378,  0.15121129,  0.0095274 , -0.18658677,\n",
      "        -0.1237215 ,  0.05915866, -0.04465923,  0.006552  ]],\n",
      "      dtype=float32), array([[ 0.25502157, -0.19428456,  0.02586756, -0.15029243, -0.1784901 ,\n",
      "        -0.08483628,  0.07780012,  0.18501194, -0.07805233,  0.3051115 ,\n",
      "        -0.01552835, -0.04939769,  0.19002873, -0.04980064, -0.1482279 ,\n",
      "        -0.26859814,  0.12644793,  0.00936639,  0.08710865,  0.16139832,\n",
      "        -0.11526964, -0.06005018, -0.10226911,  0.17666785,  0.05053337,\n",
      "        -0.08197915,  0.01620589, -0.17514375,  0.19326991, -0.15421005,\n",
      "        -0.09526376,  0.12761973]], dtype=float32), array([[-0.15948226,  0.05598249,  0.2682268 , -0.32095495,  0.03054319,\n",
      "        -0.05253133,  0.25668913,  0.3185268 ,  0.34126478, -0.42988595]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[2.05162549e-04 5.65812504e-03 3.10809212e-03 ... 7.16894632e-04\n",
      "  8.45144808e-01 1.89981121e-03]\n",
      " [6.47461857e-05 1.06071087e-03 6.28058842e-05 ... 1.37113994e-02\n",
      "  4.68973536e-03 4.85600352e-01]\n",
      " [9.71029606e-03 9.91755514e-04 3.93247511e-03 ... 2.01065652e-03\n",
      "  3.44456136e-01 2.45236810e-02]\n",
      " ...\n",
      " [1.61197240e-04 1.76960319e-01 6.14785969e-01 ... 2.23041876e-04\n",
      "  1.43725485e-01 1.98955997e-04]\n",
      " [2.14106892e-03 5.19962996e-05 2.89994259e-05 ... 7.34556139e-01\n",
      "  6.97222829e-04 2.45685086e-01]\n",
      " [1.03765797e-06 9.51510608e-01 1.24992263e-02 ... 2.63420027e-03\n",
      "  1.88938752e-02 4.05747350e-03]]\n",
      "Loss:\n",
      " [2.286219274298136, 2.216430329229475, 2.057585551689217, 1.7333380839456671, 1.4080616940931867, 1.1640634750814032, 0.9727951549883816, 0.829155436223991, 0.7225167698989114, 0.6440189307318224, 0.5868240088901315, 0.5442991504788445, 0.5112248274216717, 0.48428795339202746, 0.46151189237916046]\n",
      "Accuracy:\n",
      " 0.8765714285714286\n",
      "\n",
      "Testing weight configuration: he_normal\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[ 0.03999778,  0.02337201,  0.01654856, ..., -0.01264654,\n",
      "         0.0983605 , -0.02349178],\n",
      "       [ 0.05033609,  0.01088684,  0.003892  , ..., -0.00903939,\n",
      "         0.00353545, -0.09144268],\n",
      "       [-0.02355272,  0.01691791, -0.09525234, ..., -0.0058352 ,\n",
      "        -0.05669824,  0.02044719],\n",
      "       ...,\n",
      "       [-0.07271917, -0.03981327,  0.02967357, ..., -0.05524292,\n",
      "        -0.02441269, -0.01670509],\n",
      "       [ 0.05893589, -0.07948083,  0.02707416, ...,  0.04926933,\n",
      "         0.04542422, -0.03835095],\n",
      "       [ 0.03307312, -0.02775579, -0.07754339, ..., -0.04828853,\n",
      "        -0.02938198, -0.0363628 ]], shape=(784, 128), dtype=float32), array([[ 0.08942038,  0.13168679,  0.1026794 , ...,  0.16195416,\n",
      "        -0.23958607,  0.1090221 ],\n",
      "       [-0.1247969 , -0.00569724,  0.10673641, ..., -0.08415622,\n",
      "        -0.14352778,  0.2733351 ],\n",
      "       [-0.3624361 ,  0.0982481 , -0.01299943, ...,  0.10597099,\n",
      "         0.02758316,  0.10509512],\n",
      "       ...,\n",
      "       [ 0.03119531, -0.14656591, -0.13426548, ..., -0.01835732,\n",
      "         0.11773013, -0.10683049],\n",
      "       [-0.29871124, -0.12804902,  0.08366875, ..., -0.29024386,\n",
      "         0.11753924,  0.07098033],\n",
      "       [ 0.07543116,  0.11066534,  0.16460252, ...,  0.11736406,\n",
      "         0.03305202,  0.1298279 ]], shape=(128, 64), dtype=float32), array([[ 0.06953667, -0.03596313,  0.19297765, ..., -0.04658458,\n",
      "        -0.23807839,  0.25203186],\n",
      "       [ 0.04551318,  0.15027276,  0.54087025, ...,  0.02746398,\n",
      "        -0.16283946,  0.07281636],\n",
      "       [-0.03314218,  0.17944945,  0.1633175 , ..., -0.1809458 ,\n",
      "        -0.289557  , -0.20799458],\n",
      "       ...,\n",
      "       [-0.05308159, -0.01345999,  0.14028491, ...,  0.08127326,\n",
      "        -0.50613356, -0.1503329 ],\n",
      "       [ 0.4177878 , -0.15575968,  0.04856721, ...,  0.0530991 ,\n",
      "         0.6621004 , -0.16947071],\n",
      "       [-0.23209006,  0.04695563,  0.4676271 , ...,  0.20184371,\n",
      "        -0.21558352, -0.12161363]], shape=(64, 32), dtype=float32), array([[ 5.24898827e-01,  8.95770907e-01,  7.10656822e-01,\n",
      "        -2.49458879e-01, -6.84279442e-01,  2.33759001e-01,\n",
      "         1.08968578e-01,  2.83142895e-01, -1.04843986e+00,\n",
      "        -3.35105866e-01],\n",
      "       [ 8.55818033e-01, -8.75442982e-01, -3.24433334e-02,\n",
      "        -1.68886349e-01,  1.92320421e-01, -1.21215425e-01,\n",
      "         4.58630651e-01, -4.02746707e-01, -3.37593891e-02,\n",
      "        -4.16471094e-01],\n",
      "       [ 1.25693655e+00, -1.38796592e+00, -2.00890914e-01,\n",
      "        -9.11312774e-02,  6.25624061e-01,  1.12391686e+00,\n",
      "         7.13441730e-01,  2.90030956e-01, -9.92747486e-01,\n",
      "        -6.77226126e-01],\n",
      "       [ 2.23526999e-01,  7.71407709e-02,  1.28953815e+00,\n",
      "         7.82634258e-01, -1.08246911e+00,  5.00894904e-01,\n",
      "        -5.58205128e-01, -1.38616872e+00,  9.52772141e-01,\n",
      "        -1.38839138e+00],\n",
      "       [-2.11762507e-02,  1.98062137e-01,  1.46290839e-01,\n",
      "         3.52767944e-01, -2.42065355e-01,  3.51912111e-01,\n",
      "        -4.54706937e-01,  8.47077429e-01, -5.74546261e-03,\n",
      "        -3.01094741e-01],\n",
      "       [ 8.65554273e-01, -9.74058986e-01,  2.30626792e-01,\n",
      "         1.04416716e+00, -1.30819273e+00,  5.64556062e-01,\n",
      "        -6.26368105e-01,  2.10732877e-01,  6.97734535e-01,\n",
      "         5.47628641e-01],\n",
      "       [-8.52219522e-01,  5.31711578e-01, -8.23104322e-01,\n",
      "         3.45736854e-02,  5.21812379e-01,  7.64644802e-01,\n",
      "        -1.31498861e+00,  6.69474483e-01,  9.52418745e-01,\n",
      "         7.85470307e-01],\n",
      "       [ 1.08031660e-01, -8.03279459e-01, -1.84794307e-01,\n",
      "        -8.76428187e-01,  3.76829565e-01,  2.64259875e-01,\n",
      "        -2.96927691e-01, -4.30933177e-01,  3.71202141e-01,\n",
      "        -5.05437732e-01],\n",
      "       [ 1.07047355e+00, -1.05494928e+00, -1.12854004e+00,\n",
      "         9.45215881e-01, -7.49841511e-01,  1.87369846e-02,\n",
      "        -1.17816782e+00,  1.32562828e+00,  2.64103472e-01,\n",
      "         1.01723003e+00],\n",
      "       [ 3.25765312e-01, -2.52339959e-01,  1.02988183e-01,\n",
      "         4.98854786e-01, -9.66280341e-01,  2.35012129e-01,\n",
      "         7.01357722e-01, -6.26976252e-01,  2.27793485e-01,\n",
      "        -1.12958834e-01],\n",
      "       [ 4.55719791e-02,  8.14471170e-02,  5.29472351e-01,\n",
      "        -1.11920369e+00,  5.54777145e-01, -1.06699765e+00,\n",
      "         5.81128478e-01, -3.74545753e-01,  4.12252098e-02,\n",
      "         6.67321622e-01],\n",
      "       [-6.83727562e-01,  2.15429410e-01,  3.03390156e-02,\n",
      "        -4.73116100e-01, -2.83823580e-01,  7.68307805e-01,\n",
      "        -3.94548446e-01, -1.85666502e-01,  1.25814557e-01,\n",
      "        -3.75273764e-01],\n",
      "       [-4.53858763e-01,  5.56571364e-01, -1.50945053e-01,\n",
      "        -3.71194929e-01,  8.26962292e-01, -8.45695615e-01,\n",
      "         7.55166411e-01,  4.93517339e-01, -1.17593992e+00,\n",
      "         7.84737110e-01],\n",
      "       [-1.13035142e+00,  2.53824085e-01, -7.51977563e-01,\n",
      "         1.23709238e+00,  3.25640261e-01,  7.84088895e-02,\n",
      "        -1.35912490e+00,  7.46891677e-01, -6.58716083e-01,\n",
      "         6.71728611e-01],\n",
      "       [ 1.66437984e-01, -5.45264244e-01,  5.98739386e-02,\n",
      "         1.36211801e+00, -4.33588237e-01,  1.15650010e+00,\n",
      "        -4.67002571e-01, -2.42991328e-01, -9.51643065e-02,\n",
      "        -4.67175305e-01],\n",
      "       [-1.87127411e+00,  1.23182423e-01,  6.38950944e-01,\n",
      "         3.05683792e-01,  6.98586404e-01, -1.12855124e+00,\n",
      "         6.44814432e-01, -1.30088484e+00,  6.35982335e-01,\n",
      "         4.57419932e-01],\n",
      "       [ 6.35784745e-01,  4.25419919e-02, -7.42967367e-01,\n",
      "        -4.81808782e-01,  2.60066748e-01, -1.56274229e-01,\n",
      "         3.06658536e-01,  4.33160812e-02, -7.05012202e-01,\n",
      "         6.17472649e-01],\n",
      "       [-9.06531811e-01, -1.74565744e-02, -9.85658616e-02,\n",
      "        -1.08977437e+00,  6.08425140e-01,  2.86980987e-01,\n",
      "         1.25098554e-02, -5.80697954e-02,  5.84869087e-01,\n",
      "         4.86340612e-01],\n",
      "       [ 8.36509466e-01,  4.88647729e-01,  7.21181035e-01,\n",
      "         3.45581886e-03, -8.32182109e-01,  3.67585391e-01,\n",
      "         1.15521312e+00, -5.45755982e-01, -3.30337375e-01,\n",
      "        -8.94562423e-01],\n",
      "       [-2.79285133e-01,  1.70533553e-01, -2.34322660e-02,\n",
      "        -2.00686753e-01,  1.00019419e+00, -5.40606260e-01,\n",
      "        -6.01141304e-02,  7.12485969e-01, -1.37398183e-01,\n",
      "         3.04504722e-01],\n",
      "       [ 4.02320832e-01, -1.10340083e+00, -8.79243612e-01,\n",
      "        -3.12726825e-01,  5.08094907e-01,  6.76705122e-01,\n",
      "        -1.34285942e-01, -5.24245620e-01,  2.88659930e-01,\n",
      "         8.76890063e-01],\n",
      "       [-1.13523376e+00,  9.13738072e-01,  9.03952360e-01,\n",
      "         5.58681309e-01,  2.16713414e-01,  5.34658551e-01,\n",
      "        -5.06140172e-01, -8.39711905e-01, -2.55332072e-03,\n",
      "        -7.59832203e-01],\n",
      "       [-6.44668413e-04,  5.27468860e-01, -4.64645356e-01,\n",
      "         5.84016919e-01, -7.06856251e-01, -1.34832203e+00,\n",
      "        -4.92751718e-01,  1.65029883e+00,  8.73371866e-03,\n",
      "        -2.34748483e-01],\n",
      "       [-5.09025514e-01,  1.00260913e+00, -4.16407704e-01,\n",
      "        -9.27499533e-01, -7.08059743e-02, -4.80063558e-02,\n",
      "        -5.75387537e-01,  4.52242345e-01,  6.90538943e-01,\n",
      "         3.25888664e-01],\n",
      "       [-7.37759888e-01,  1.11055171e+00, -5.74173808e-01,\n",
      "        -6.05745971e-01, -2.41876245e-01, -2.34889984e-01,\n",
      "        -5.51763952e-01,  8.70746255e-01, -4.90404218e-01,\n",
      "         2.64870644e-01],\n",
      "       [ 1.52367520e+00, -9.91409540e-01, -5.89742601e-01,\n",
      "        -1.20162427e+00,  7.16191411e-01, -2.29865789e-01,\n",
      "         1.10601437e+00, -1.37092486e-01, -7.91007817e-01,\n",
      "         7.54999399e-01],\n",
      "       [-9.39376578e-02, -9.36243653e-01,  1.15662062e+00,\n",
      "        -9.62577939e-01,  4.07130569e-01, -5.37453055e-01,\n",
      "         6.90013826e-01, -2.88278963e-02,  3.97554219e-01,\n",
      "        -1.23316072e-01],\n",
      "       [-9.90685523e-02,  3.93233262e-02, -4.08026695e-01,\n",
      "         4.92310971e-01, -4.73014638e-02,  5.57217002e-02,\n",
      "         2.30948299e-01, -1.73627689e-01, -1.69603378e-01,\n",
      "         3.87503773e-01],\n",
      "       [ 2.33359307e-01, -4.04752761e-01,  5.79451442e-01,\n",
      "        -8.50301325e-01,  6.20108962e-01, -7.37228543e-02,\n",
      "         3.43676031e-01, -1.29415166e+00,  2.50765800e-01,\n",
      "        -8.89587998e-01],\n",
      "       [-2.41231188e-01, -2.43622079e-01,  3.50811958e-01,\n",
      "        -1.20551445e-01,  1.36294425e-01, -3.08457881e-01,\n",
      "         4.61470485e-01, -1.16000548e-01,  5.29006779e-01,\n",
      "        -1.57457441e-01],\n",
      "       [-7.28532016e-01,  1.30106330e+00,  8.05784822e-01,\n",
      "         7.41943240e-01, -1.07053125e+00, -8.24611306e-01,\n",
      "        -1.62847519e+00,  8.21297169e-02,  7.68307149e-01,\n",
      "        -4.56832081e-01],\n",
      "       [-1.06218207e+00,  4.98118848e-01,  1.12833232e-02,\n",
      "         8.09984088e-01, -9.69440401e-01, -3.10662687e-01,\n",
      "         5.75234532e-01,  5.07301271e-01, -4.61260527e-01,\n",
      "        -2.81954944e-01]], dtype=float32)]\n",
      "Biases:\n",
      " [array([[ 3.42454463e-02, -5.97536378e-02,  5.72330505e-02,\n",
      "        -4.24214564e-02, -1.14384092e-01, -3.89425159e-02,\n",
      "         3.93754020e-02,  5.13672382e-02, -1.79946851e-02,\n",
      "         3.03938147e-02, -4.87077683e-02,  1.50790121e-02,\n",
      "        -8.53966326e-02,  5.74673153e-02, -7.24824443e-02,\n",
      "        -1.51691083e-02,  1.46480389e-02, -9.08525586e-02,\n",
      "        -8.89078453e-02,  5.36589976e-03,  3.17238420e-02,\n",
      "        -8.52058008e-02,  9.52714309e-02, -1.34401202e-01,\n",
      "        -9.55010504e-02, -3.66288982e-02, -1.30098667e-02,\n",
      "        -1.07075728e-01,  9.57188103e-03, -4.97154950e-04,\n",
      "         7.99940061e-03,  1.05996415e-01,  2.38171779e-02,\n",
      "        -3.38059589e-02, -8.36739019e-02, -1.18216403e-01,\n",
      "        -2.96966955e-02,  4.90012579e-02,  5.58546074e-02,\n",
      "        -3.35103758e-02,  2.66241282e-03, -5.12611903e-02,\n",
      "         4.22659516e-03, -1.15609178e-02, -1.83177721e-02,\n",
      "         3.90712991e-02, -6.53470829e-02, -1.06453165e-01,\n",
      "         2.13454254e-02,  7.00192433e-03,  7.61969462e-02,\n",
      "        -1.30111501e-01, -2.33377088e-02, -5.32268211e-02,\n",
      "        -4.95203063e-02,  7.24866316e-02, -4.46273908e-02,\n",
      "         7.46080726e-02,  8.39457065e-02, -8.38240981e-02,\n",
      "         7.90740084e-03,  2.23806873e-02,  1.20845504e-01,\n",
      "        -7.16720372e-02, -3.54884677e-02, -1.13441952e-01,\n",
      "        -6.70017004e-02,  5.74857257e-02, -5.03070541e-02,\n",
      "        -1.96789857e-02, -2.75506452e-02,  5.47150150e-03,\n",
      "         6.32523224e-02, -1.20227569e-05,  4.84268963e-02,\n",
      "         7.83842504e-02,  5.14056310e-02, -7.00637102e-02,\n",
      "         2.72788759e-02, -3.13638449e-02,  5.66674173e-02,\n",
      "         9.62790623e-02,  1.76626425e-02,  5.93034811e-02,\n",
      "         1.11808345e-01,  8.01139176e-02,  1.40730860e-02,\n",
      "        -2.45712195e-02, -5.98560087e-02,  1.37005495e-02,\n",
      "         3.72506380e-02,  8.20040032e-02,  1.95888150e-02,\n",
      "         9.16928649e-02,  9.09088328e-02,  5.09428009e-02,\n",
      "         1.88024901e-02, -2.39951238e-02, -1.21216215e-01,\n",
      "        -2.17078794e-02,  6.48626219e-03,  1.65849607e-02,\n",
      "         3.39413024e-02, -3.46321724e-02, -2.79827137e-02,\n",
      "        -3.00292112e-02,  3.72484662e-02,  5.65554621e-03,\n",
      "         9.55802500e-02,  5.96323097e-03, -6.22398108e-02,\n",
      "        -9.16547403e-02,  3.12763709e-03,  8.97577778e-02,\n",
      "         6.51627108e-02,  6.17771223e-03, -7.55939493e-03,\n",
      "        -2.89000738e-02, -1.09459765e-01,  4.61198762e-03,\n",
      "        -4.85264063e-02, -3.95697169e-02,  3.60540748e-02,\n",
      "         3.20582860e-03,  4.51770276e-02, -2.20606644e-02,\n",
      "        -9.80584398e-02,  1.29677830e-02]], dtype=float32), array([[ 0.13520303, -0.12238137, -0.03979922,  0.03742794, -0.07406917,\n",
      "         0.18054555, -0.02448441, -0.05020901, -0.15027075, -0.16889425,\n",
      "        -0.03186076, -0.12831017,  0.13511908, -0.05009675,  0.09260856,\n",
      "         0.08766464,  0.0652899 , -0.05544794,  0.07415263,  0.09308296,\n",
      "        -0.12193428, -0.06462196,  0.22874285, -0.04580663, -0.00801297,\n",
      "        -0.10706912,  0.03760988, -0.02249793, -0.07893223, -0.13493524,\n",
      "         0.05392314, -0.16886795,  0.0356633 ,  0.14330481,  0.0762221 ,\n",
      "        -0.05588658,  0.06248895,  0.08629889, -0.15463628, -0.06609274,\n",
      "         0.12628023,  0.06661821,  0.17154843,  0.10325375, -0.09314483,\n",
      "         0.03711261, -0.15090016,  0.08250368,  0.07503472, -0.07665721,\n",
      "         0.15980878, -0.01178693,  0.08449592,  0.13600051, -0.08423974,\n",
      "        -0.13896097, -0.02033661,  0.06505229,  0.12194204, -0.06990433,\n",
      "         0.10625685, -0.0286042 ,  0.10480438, -0.1144105 ]],\n",
      "      dtype=float32), array([[-0.1459855 ,  0.0074638 ,  0.32385653,  0.20827493,  0.06897123,\n",
      "        -0.08177488,  0.25350085, -0.05902895,  0.1419682 , -0.06459204,\n",
      "         0.21649963,  0.1127893 , -0.03113155,  0.36713633,  0.09165808,\n",
      "         0.01302628, -0.09739548, -0.4155502 , -0.1206191 , -0.1757345 ,\n",
      "         0.1335712 , -0.03055713, -0.20159048,  0.10994053,  0.11531267,\n",
      "         0.04219574,  0.05800894,  0.2414891 , -0.27285084,  0.32512426,\n",
      "         0.20361951, -0.09997624]], dtype=float32), array([[-0.05929651, -0.25808927, -0.28033066, -0.3032852 ,  0.0545853 ,\n",
      "         0.5637993 , -0.11181162,  0.27753797,  0.12740427, -0.48084497]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[2.04359210e-04 1.56837527e-03 2.09420342e-02 ... 4.86798759e-04\n",
      "  9.24772024e-01 2.61785905e-03]\n",
      " [7.30146014e-04 4.98259033e-04 2.88851734e-04 ... 1.34542333e-02\n",
      "  5.25642000e-03 3.73889148e-01]\n",
      " [7.74721280e-02 2.61832669e-04 6.80546276e-03 ... 4.34043165e-03\n",
      "  1.45390987e-01 7.09536895e-02]\n",
      " ...\n",
      " [4.01021854e-04 6.68768808e-02 7.67346561e-01 ... 6.33729564e-04\n",
      "  1.33176118e-01 6.08054921e-04]\n",
      " [7.42298202e-04 2.24412605e-03 2.30516998e-05 ... 8.58935118e-01\n",
      "  1.11903134e-03 1.28960177e-01]\n",
      " [3.86116562e-06 9.53963697e-01 8.57549626e-03 ... 2.03541443e-02\n",
      "  5.64049976e-03 3.90635943e-03]]\n",
      "Loss:\n",
      " [2.2504370926488324, 2.0608039526307755, 1.7394582778861316, 1.3818274001101856, 1.0994431506285842, 0.9121667738934474, 0.7857923284471605, 0.6910743361701808, 0.6156802882981515, 0.5553292431862338, 0.5069023942996886, 0.46755334297309503, 0.43514482693762563, 0.40813182674352755, 0.38536024616469755]\n",
      "Accuracy:\n",
      " 0.8972142857142857\n",
      "\n",
      "Testing weight configuration: he_uniform\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[-0.03564897,  0.05407558, -0.02620035, ...,  0.0304185 ,\n",
      "        -0.08007096, -0.02949842],\n",
      "       [-0.01145362,  0.06800726, -0.01210968, ...,  0.07932521,\n",
      "         0.03553534,  0.04395818],\n",
      "       [-0.05284502, -0.0841887 , -0.0159593 , ...,  0.03445728,\n",
      "        -0.08295864, -0.03409827],\n",
      "       ...,\n",
      "       [ 0.01432097,  0.03387446, -0.01296032, ...,  0.03441519,\n",
      "        -0.06876738, -0.05527762],\n",
      "       [-0.08081977,  0.02993746, -0.08260595, ..., -0.07391525,\n",
      "        -0.0597079 , -0.07169901],\n",
      "       [ 0.04445016, -0.07577889, -0.07235124, ..., -0.06353316,\n",
      "        -0.01397525, -0.04290636]], shape=(784, 128), dtype=float32), array([[-0.20008855,  0.13011397, -0.11728434, ..., -0.14728731,\n",
      "        -0.20785445,  0.05075846],\n",
      "       [-0.10342659, -0.07882838,  0.20636274, ..., -0.07004441,\n",
      "         0.21543741,  0.06670508],\n",
      "       [ 0.15744741, -0.0360052 , -0.0234774 , ..., -0.1954596 ,\n",
      "        -0.23513259,  0.00287105],\n",
      "       ...,\n",
      "       [ 0.22702383,  0.27237296,  0.06941772, ...,  0.16183512,\n",
      "        -0.04936318, -0.04759614],\n",
      "       [-0.08875652, -0.23243794, -0.13283406, ...,  0.06531018,\n",
      "        -0.22717433,  0.16091791],\n",
      "       [-0.11679857,  0.361654  , -0.14856513, ..., -0.08986659,\n",
      "        -0.01600381, -0.18109156]], shape=(128, 64), dtype=float32), array([[-0.396397  , -0.01325412, -0.32891053, ..., -0.23848355,\n",
      "         0.48803952, -0.083886  ],\n",
      "       [ 0.29993176,  0.08545858,  0.22590657, ...,  0.15274392,\n",
      "        -0.05520468,  0.15873592],\n",
      "       [ 0.2279725 , -0.08375856,  0.07888179, ..., -0.10961116,\n",
      "         0.3301382 , -0.33701143],\n",
      "       ...,\n",
      "       [ 0.1009101 , -0.07312872, -0.2100194 , ..., -0.23054583,\n",
      "        -0.02512583, -0.3590472 ],\n",
      "       [ 0.07491774,  0.49082088,  0.31291544, ...,  0.27058315,\n",
      "        -0.17055467,  0.45242482],\n",
      "       [ 0.08465695,  0.21525194, -0.01504937, ...,  0.20121719,\n",
      "         0.4456138 ,  0.2999094 ]], shape=(64, 32), dtype=float32), array([[-1.2667699 ,  0.7281971 , -0.05655456,  0.37256214,  0.46247333,\n",
      "         0.00266762, -0.40675616, -0.46107432,  1.0290045 ,  0.07985133],\n",
      "       [-1.3511022 ,  1.1277909 , -0.00942604,  0.81182826, -0.9531714 ,\n",
      "         0.31562904, -0.38830236, -0.37059632,  0.42287645, -0.74874395],\n",
      "       [-0.53083295,  1.0129352 , -0.20476197,  0.59666276, -0.11052009,\n",
      "        -0.09239798, -0.542922  , -0.2375491 ,  0.48719096,  0.6224065 ],\n",
      "       [-0.09491617, -0.9766847 , -0.5869499 ,  0.6655137 ,  0.3550114 ,\n",
      "         0.5756047 ,  0.4049007 , -0.20260951, -0.45162648,  0.8016502 ],\n",
      "       [ 0.43371007,  0.04571716,  0.7748462 ,  0.26772994, -0.8562127 ,\n",
      "         0.7037354 , -0.5700173 , -0.8425097 ,  1.246807  , -0.71843624],\n",
      "       [-0.69435775,  0.9865158 ,  0.1135518 , -0.52986926,  0.6375935 ,\n",
      "        -0.7275884 ,  1.1549095 , -0.98661625, -0.6104693 , -0.05237179],\n",
      "       [-1.1657615 ,  0.7080437 , -0.6329083 , -0.5887535 ,  0.9322823 ,\n",
      "        -0.04617975, -0.4389151 ,  0.5261615 ,  0.9789637 ,  0.8834139 ],\n",
      "       [ 0.4465738 ,  0.6078403 , -0.18931928,  0.31676406, -0.6173069 ,\n",
      "        -0.14393142,  0.67596   , -0.22566843, -0.6240821 , -0.17997715],\n",
      "       [ 0.55837727, -0.58562124, -0.64357233, -0.5979368 , -0.5078991 ,\n",
      "         0.17356524,  0.0850535 ,  0.06062103, -0.633063  , -0.34005523],\n",
      "       [-0.30417702,  1.2916846 ,  0.02118999,  0.9838185 , -0.11376512,\n",
      "        -0.24785684, -0.5286071 ,  1.1081123 , -0.63770074,  0.8581531 ],\n",
      "       [ 0.41896725, -0.8416266 , -0.4342315 , -1.3533131 ,  1.4270611 ,\n",
      "         0.08354668,  1.2671263 , -0.52141255, -0.3161121 , -0.10481995],\n",
      "       [-0.7000857 ,  0.9770474 ,  0.6109514 , -0.44642222,  0.20175742,\n",
      "        -0.8875217 ,  0.74933946, -0.6378102 ,  0.11019456, -0.27379876],\n",
      "       [ 0.37856805, -1.1330506 , -0.8980129 , -0.7339188 , -0.16321115,\n",
      "         1.146103  ,  0.31841448, -0.28793463,  0.67751825,  0.60270786],\n",
      "       [ 0.8785078 , -0.6551549 ,  0.32696125,  0.3323938 , -0.09941231,\n",
      "        -0.6235319 ,  0.6090364 ,  0.6794079 , -0.08152409, -0.9884761 ],\n",
      "       [-0.950096  ,  0.47595227,  0.04572425, -0.3907739 ,  0.48548618,\n",
      "        -0.215849  , -0.48956206,  0.97356665, -0.15677135,  0.730099  ],\n",
      "       [ 0.18648337, -0.15993991, -0.16691253, -0.86244184,  0.61102164,\n",
      "         0.14909692,  1.190708  , -0.86428106, -0.5061415 , -0.0079616 ],\n",
      "       [ 0.61616355, -0.79355717,  0.966799  ,  0.31163812, -0.3250884 ,\n",
      "         0.71820027,  0.6887496 , -0.74050194, -0.36676064, -0.39660978],\n",
      "       [ 0.79407316, -0.85370386,  0.5415663 ,  0.7616069 , -0.88472795,\n",
      "        -0.05805301,  0.6165972 , -0.28721744, -0.61892676, -0.7201912 ],\n",
      "       [-0.38401416, -0.38051423,  0.44763038,  0.24777563,  0.0197252 ,\n",
      "        -1.1321226 ,  0.3885217 ,  1.1495441 , -1.1935889 ,  0.43964562],\n",
      "       [ 0.9772627 , -1.307319  , -0.44572508,  0.30751297, -0.4887516 ,\n",
      "         0.54685277, -0.8327999 ,  0.5872059 , -0.36733922,  0.49711546],\n",
      "       [ 0.9347962 , -0.46848512, -0.90172905,  0.50119424, -0.23169744,\n",
      "         0.38358274, -0.75370383,  0.5802479 , -0.09429839,  0.5430458 ],\n",
      "       [-0.05396811, -0.03862915, -0.26177415,  0.6809654 , -0.84958225,\n",
      "         0.39522824, -0.65970665,  0.651118  , -0.7852452 ,  0.7351042 ],\n",
      "       [-1.430982  ,  0.65036726,  0.5580399 ,  0.03477639,  0.5581963 ,\n",
      "         0.4771005 ,  0.06009674, -1.1222037 ,  0.9179755 , -0.61313254],\n",
      "       [ 0.89396524, -0.28384596, -1.1419208 , -0.93925047,  0.57379156,\n",
      "         0.82055867, -0.7726153 ,  0.28103608,  0.04893779,  0.4731363 ],\n",
      "       [ 0.991891  , -0.9225689 ,  0.6255428 ,  0.9005617 , -1.0711893 ,\n",
      "         0.6389072 , -0.3647151 ,  0.2553664 , -0.15927486, -1.0850843 ],\n",
      "       [ 0.1754545 , -1.0561559 , -0.18099046, -0.17184436,  0.95034015,\n",
      "        -0.28876   , -0.60168225,  0.60862064, -0.02090796,  0.9724652 ],\n",
      "       [ 0.02468515,  0.10857864,  0.8747187 , -0.49685252,  0.71995765,\n",
      "        -0.9824633 , -0.4826588 ,  0.32634556, -0.49767017,  0.3562948 ],\n",
      "       [-0.17088561, -0.39344984,  0.16882955, -0.5945606 ,  0.4988618 ,\n",
      "        -0.44236535,  0.29757202, -0.5745997 , -0.17783271,  0.64096403],\n",
      "       [-0.87095016, -0.1644844 , -1.4563546 , -0.06822073,  0.439044  ,\n",
      "         0.46772078, -0.7914102 ,  0.70107037,  0.9556416 ,  0.5705434 ],\n",
      "       [ 0.14097394, -0.23944536, -0.1401191 ,  1.0664461 , -0.10605118,\n",
      "         0.04101354, -0.47726947,  0.02521455,  0.12248858,  0.14907709],\n",
      "       [ 0.37503144,  0.02132495,  0.8115413 , -0.02925657, -0.73595834,\n",
      "        -0.01022232,  0.24442264, -1.3201805 ,  0.8885161 , -0.7296687 ],\n",
      "       [-0.36802226,  0.840137  ,  1.179749  ,  0.18129654, -0.79577637,\n",
      "        -0.07476135, -0.91680545,  0.5035758 ,  0.36848783, -0.7153114 ]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[-2.75966469e-02,  6.63383827e-02,  6.36350662e-02,\n",
      "         1.05909877e-01, -2.11306456e-02, -8.42636600e-02,\n",
      "        -3.60061005e-02,  5.70732821e-03,  9.55877360e-03,\n",
      "         8.19679350e-03, -1.01075443e-02, -6.05863817e-02,\n",
      "        -3.23989689e-02, -6.98814616e-02, -1.78886261e-02,\n",
      "        -1.14994794e-01, -1.78009700e-02, -1.07703200e-02,\n",
      "         3.18330750e-02,  4.84716259e-02,  1.97690167e-02,\n",
      "         7.59162456e-02,  6.62284493e-02,  3.26707251e-02,\n",
      "        -5.82690910e-02, -8.00541416e-02,  6.60708919e-02,\n",
      "         5.56423850e-02, -1.94463879e-02, -7.97466263e-02,\n",
      "        -3.92794702e-03, -9.57532004e-02,  2.92339865e-02,\n",
      "         3.46662700e-02,  5.99724837e-02,  8.47230405e-02,\n",
      "        -5.75568937e-02,  1.48548745e-02, -1.63595498e-04,\n",
      "        -8.81929919e-02,  7.13686273e-02, -7.17326105e-02,\n",
      "         4.71899956e-02, -1.70756895e-02, -2.00698245e-02,\n",
      "        -7.83282518e-02,  2.52497271e-02, -4.39816527e-02,\n",
      "        -8.23279545e-02, -6.45150915e-02,  5.83217740e-02,\n",
      "        -2.99752615e-02,  9.70335305e-02, -1.17421495e-02,\n",
      "         1.00939050e-01, -8.68902206e-02, -6.94433376e-02,\n",
      "         5.54914661e-02, -4.60920408e-02,  3.68972570e-02,\n",
      "         3.67910229e-02, -5.53587116e-02, -8.39395151e-02,\n",
      "         2.91938055e-02, -8.62090215e-02,  4.05363292e-02,\n",
      "        -5.13350517e-02,  1.48072951e-02,  6.96235225e-02,\n",
      "         5.21032661e-02,  7.38455430e-02, -7.72768557e-02,\n",
      "        -5.83958961e-02, -8.75834562e-03,  1.28770899e-02,\n",
      "         1.20988919e-03,  1.64137736e-01,  4.11651805e-02,\n",
      "         1.52001344e-02, -4.31653894e-02,  7.11720586e-02,\n",
      "        -5.12675941e-02,  7.35741183e-02,  4.88532260e-02,\n",
      "         4.30871546e-02,  2.76897606e-02, -1.03631085e-02,\n",
      "         2.35182066e-02, -8.27829912e-02,  4.55046482e-02,\n",
      "        -9.86870229e-02,  5.16705774e-02, -3.28520648e-02,\n",
      "         3.12781730e-03,  3.14394012e-02,  7.59903938e-02,\n",
      "        -9.05813649e-03,  7.09675578e-03,  3.01186293e-02,\n",
      "         7.19698220e-02,  2.48498209e-02, -4.39340733e-02,\n",
      "        -1.06228501e-01, -1.94239113e-02,  4.71292362e-02,\n",
      "         4.01793569e-02, -9.76380333e-02, -4.05522846e-02,\n",
      "        -1.18734231e-02,  3.67390402e-02,  4.82901372e-02,\n",
      "         4.22427915e-02, -2.05898862e-02, -5.43307923e-02,\n",
      "        -1.83936860e-02, -6.16765320e-02, -1.60722006e-02,\n",
      "        -1.46403331e-02, -3.95615399e-02, -1.83118135e-02,\n",
      "         8.16087723e-02, -1.41607514e-02,  4.40561026e-02,\n",
      "        -1.01611435e-01, -3.26127596e-02,  5.21788187e-03,\n",
      "         2.11725477e-02,  6.17449135e-02]], dtype=float32), array([[ 0.03184361,  0.13835245,  0.09666719, -0.07825517,  0.24058472,\n",
      "         0.2200655 , -0.05391503, -0.04569014,  0.14818409,  0.14447089,\n",
      "         0.16575411,  0.16534449, -0.15816452,  0.14430025, -0.08080015,\n",
      "         0.05731252,  0.13825195, -0.09445249,  0.02747705,  0.07140769,\n",
      "         0.1535639 ,  0.00999412,  0.04068539, -0.19300592, -0.00994123,\n",
      "        -0.12287237,  0.18708   , -0.20622338,  0.0067202 ,  0.09365762,\n",
      "         0.13000505,  0.03894601, -0.14245678,  0.06342229, -0.08841246,\n",
      "        -0.1221998 ,  0.17610537,  0.18895316,  0.08244903,  0.08338569,\n",
      "        -0.08345573,  0.18230085, -0.10445077,  0.08078562,  0.05816348,\n",
      "        -0.14475273,  0.04764347,  0.05936689, -0.16753016, -0.1226382 ,\n",
      "         0.01912296, -0.03864149, -0.06262607, -0.17337856,  0.08184149,\n",
      "        -0.02606374,  0.18070792,  0.19338112,  0.00144472, -0.22474809,\n",
      "        -0.15915826,  0.06859478, -0.05287386,  0.00823362]],\n",
      "      dtype=float32), array([[ 0.30154955, -0.22861746,  0.02678604, -0.22027661, -0.20508826,\n",
      "        -0.10000192,  0.0868618 ,  0.22732635, -0.08767508,  0.3655701 ,\n",
      "        -0.02652812, -0.05114394,  0.23607612, -0.06239817, -0.18636952,\n",
      "        -0.33211428,  0.15883626,  0.00791817,  0.08251152,  0.20104036,\n",
      "        -0.15169455, -0.08045783, -0.13603117,  0.20730226,  0.06133066,\n",
      "        -0.09939872,  0.00976351, -0.21403655,  0.22368434, -0.19394204,\n",
      "        -0.1221082 ,  0.15913816]], dtype=float32), array([[-0.16019486,  0.09658203,  0.31211743, -0.39440623,  0.03223838,\n",
      "        -0.07443672,  0.2969274 ,  0.36489442,  0.38382006, -0.5042495 ]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[1.34231042e-04 4.96332254e-03 2.08526826e-03 ... 3.44050874e-04\n",
      "  9.08314347e-01 1.28524844e-03]\n",
      " [5.93005170e-05 1.06932176e-03 8.59136489e-05 ... 6.47913991e-03\n",
      "  4.96978592e-03 3.49327296e-01]\n",
      " [5.80215873e-03 1.33684452e-03 2.54567433e-03 ... 5.53915161e-04\n",
      "  3.22201610e-01 1.50454920e-02]\n",
      " ...\n",
      " [2.49081786e-04 1.41246662e-01 6.66775882e-01 ... 2.56367581e-04\n",
      "  1.36888549e-01 1.54563517e-04]\n",
      " [2.13770801e-03 9.43285122e-05 7.62083655e-05 ... 8.01931143e-01\n",
      "  5.71944402e-04 1.82158366e-01]\n",
      " [1.24906410e-06 9.63102877e-01 8.93785339e-03 ... 2.52026063e-03\n",
      "  1.26939127e-02 3.43460077e-03]]\n",
      "Loss:\n",
      " [2.2591719605181164, 2.0785246991204622, 1.729265387254908, 1.361444234082927, 1.0874166337494082, 0.8859898528424501, 0.7445089022251848, 0.6489110769792745, 0.5828727416636568, 0.5344164845701531, 0.49661907992845555, 0.4657482607524133, 0.43973213974094916, 0.4173402196848806, 0.3977716238969937]\n",
      "Accuracy:\n",
      " 0.8917857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight Variations Experiment:\")\n",
    "for weight_config in additional_weight_configs:\n",
    "    print(f\"\\nTesting weight configuration: {weight_config}\")\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "\n",
    "    model_scratch_output(custom_mlp, X_train_scaled, y_train_one_hot, X_test_scaled, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7734b1a1eb82bc",
   "metadata": {},
   "source": [
    "# Pengaruh Regularisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f1679aeb669fd7f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-29T06:25:36.211991Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scikit-learn MLP\n",
    "sk_mlp = MLPLIB(\n",
    "    max_iter=max_iter,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    activation=activation_mlplib,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Custom MLP\n",
    "custom_mlp = FFNNClassifier(\n",
    "    max_epoch=max_iter,\n",
    "    learning_rate=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    loss_func=\"categorical_cross_entropy\",\n",
    "    activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    ")\n",
    "\n",
    "\n",
    "model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "816dc319367ceb2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T05:59:48.412373Z",
     "start_time": "2025-03-29T05:58:26.446727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8455\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8455\n",
      "\n",
      "[Comparison Result]\n",
      "[[ 1.25334943e-02 -2.04976459e-06 -1.27172225e-05 ... -2.26038901e-06\n",
      "   5.20470560e-01 -1.36140570e-05]\n",
      " [ 1.02603912e-01  1.83600187e-05 -3.02603439e-07 ... -1.41504988e-05\n",
      "   1.37276784e-05 -4.60157186e-01]\n",
      " [ 1.54448335e-05  5.31605838e-06 -4.93295789e-01 ... -1.91982090e-05\n",
      "  -1.57920301e-01 -5.13424675e-06]\n",
      " ...\n",
      " [-2.97288984e-01 -1.08179813e-02 -1.83952561e-05 ... -1.45242214e-01\n",
      "   2.75011917e-06 -3.18426100e-06]\n",
      " [ 1.77501559e-01 -3.56105864e-01  1.37034640e-05 ...  9.33108330e-02\n",
      "   5.98134138e-02  2.83952613e-06]\n",
      " [ 8.59687134e-07 -4.67437712e-06 -3.39252919e-01 ... -8.46586823e-02\n",
      "  -1.31968245e-05  4.98523514e-06]] != [[ 1.25334943e-02 -2.04976459e-06 -1.27172225e-05 ... -2.26038901e-06\n",
      "   5.20470560e-01 -1.36140570e-05]\n",
      " [ 1.02603912e-01  1.83600187e-05 -3.02603439e-07 ... -1.41504988e-05\n",
      "   1.37276784e-05 -4.60157186e-01]\n",
      " [ 1.54448335e-05  5.31605838e-06 -4.93295789e-01 ... -1.91982090e-05\n",
      "  -1.57920301e-01 -5.13424675e-06]\n",
      " ...\n",
      " [-2.97288984e-01 -1.08179813e-02 -1.83952561e-05 ... -1.45242214e-01\n",
      "   2.75011917e-06 -3.18426100e-06]\n",
      " [ 1.77501559e-01 -3.56105864e-01  1.37034640e-05 ...  9.33108330e-02\n",
      "   5.98134138e-02  2.83952613e-06]\n",
      " [ 8.59687134e-07 -4.67437712e-06 -3.39252919e-01 ... -8.46586823e-02\n",
      "  -1.31968245e-05  4.98523514e-06]]\n",
      "❌ Weight is not equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scikit-learn MLP\n",
    "sk_mlp = MLPLIB(\n",
    "    max_iter=max_iter,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    activation=activation_mlplib,\n",
    "    verbose=False,\n",
    "    alpha_l1=l1\n",
    ")\n",
    "\n",
    "# Custom MLP\n",
    "custom_mlp = FFNNClassifier(\n",
    "    max_epoch=max_iter,\n",
    "    learning_rate=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    loss_func=\"categorical_cross_entropy\",\n",
    "    activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    l1 = l1\n",
    ")\n",
    "\n",
    "\n",
    "model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36d5d02615bd9b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ITB\\Semester 6\\ML\\Tubes 1\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.86\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.86\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scikit-learn MLP\n",
    "sk_mlp = MLPLIB(\n",
    "    max_iter=max_iter,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    activation=activation_mlplib,\n",
    "    verbose=False,\n",
    "    alpha=l2\n",
    ")\n",
    "\n",
    "# Custom MLP\n",
    "custom_mlp = FFNNClassifier(\n",
    "    max_epoch=max_iter,\n",
    "    learning_rate=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    loss_func=\"categorical_cross_entropy\",\n",
    "    activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    l2 = l2\n",
    ")\n",
    "\n",
    "\n",
    "model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
