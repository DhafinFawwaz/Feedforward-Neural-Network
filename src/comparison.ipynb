{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "cbf762c7c5709d70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:00.513568Z",
     "start_time": "2025-03-29T06:05:58.320609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.FFNNClassifier import FFNNClassifier\n",
    "\n",
    "from lib.MLPLib import MLPLIB\n",
    "from lib.Utils import model_comparison, model_scratch_output\n"
   ],
   "id": "801534e44fcbe2c0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:00.532337Z",
     "start_time": "2025-03-29T06:06:00.528314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_encode(y, num_classes=10):\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    one_hot = np.zeros((len(y), num_classes), dtype=int)\n",
    "    one_hot[np.arange(len(y)), y] = 1\n",
    "    return one_hot"
   ],
   "id": "696c483c9ba4e7cb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:04.889499Z",
     "start_time": "2025-03-29T06:06:00.541768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# Type conversion\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "y_test_one_hot = one_hot_encode(y_test)"
   ],
   "id": "28a4bd5cdff5847f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:05.061698Z",
     "start_time": "2025-03-29T06:06:05.057706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "DEFAULT PARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "lower_bound=5.39294405e-05\n",
    "upper_bound=1\n",
    "mean=5.39294405e-05\n",
    "std=.44\n",
    "seed=69\n",
    "hidden_layer_sizes=[128,64,32]\n",
    "max_iter=15\n",
    "init_method=\"normal\"\n",
    "learning_rate_init=0.01\n",
    "batch_size=50\n",
    "activation_mlplib=\"logistic\"\n",
    "activation_ffnn=\"sigmoid\"\n",
    "l1=0.1\n",
    "l2=0.1\n"
   ],
   "id": "690823e3c6017152",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pengaruh depth (banyak layer) dan width (banyak neuron per layer)",
   "id": "bdbb694a07f20a30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:05.078669Z",
     "start_time": "2025-03-29T06:06:05.075029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration for depth variation (keeping width constant)\n",
    "depth_configs = [\n",
    "    [10, 10],  # 2 layers\n",
    "    [10, 10, 10],  # 3 layers\n",
    "    [10, 10, 10, 10]  # 4 layers\n",
    "]\n",
    "\n",
    "# Configuration for width variation (keeping depth constant)\n",
    "width_configs = [\n",
    "    [5],  # narrow layer\n",
    "    [15],  # medium layer\n",
    "    [30]  # wide layer\n",
    "]"
   ],
   "id": "d4b5a127ebeacf8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:06:44.095232Z",
     "start_time": "2025-03-29T06:06:05.142738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Experiment for depth variations (keeping width fixed)\n",
    "print(\"Depth Variations Experiment:\")\n",
    "for depth_config in depth_configs:\n",
    "    print(f\"\\nTesting depth configuration: {depth_config}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(depth_config) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "59dfa7da3d6601c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth Variations Experiment:\n",
      "\n",
      "Testing depth configuration: [10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.6517142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.6517142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing depth configuration: [10, 10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.4722142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.4722142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing depth configuration: [10, 10, 10, 10]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.24035714285714285\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.24035714285714285\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:07:28.042275Z",
     "start_time": "2025-03-29T06:06:44.115539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Width Variations Experiment:\")\n",
    "for width in width_configs:\n",
    "    print(f\"\\nTesting width configuration: {width}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=width,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=width,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(width) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "ce96bdb39bc445",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing width configuration: [5]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7432142857142857\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.7432142857142857\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing width configuration: [15]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8022142857142858\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8022142857142858\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing width configuration: [30]\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8432857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8432857142857143\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pengaruh fungsi aktivasi hidden layer",
   "id": "613282673cb7adca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:07:28.059674Z",
     "start_time": "2025-03-29T06:07:28.055703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activation_configs = [\n",
    "    ('linear','identity'),\n",
    "    ('relu','relu'),\n",
    "    ('sigmoid','logistic'),\n",
    "    ('tanh','tanh')\n",
    "]\n",
    "\n",
    "bonus_activation_configs = [\n",
    "    'softsign',\n",
    "    'softplus'\n",
    "]"
   ],
   "id": "34b1a12acf7ac72",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:12:52.431154Z",
     "start_time": "2025-03-29T06:07:28.082268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Activation Function Variations Experiment:\")\n",
    "for act_custom, act_sklearn in activation_configs:\n",
    "    print(f\"\\nTesting activation configuration: {act_custom}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=act_sklearn,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[act_custom] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp,X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "e7a0630da20efc9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Function Variations Experiment:\n",
      "\n",
      "Testing activation configuration: linear\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8857857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8857857142857143\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: relu\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7580714285714286\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.7580714285714286\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: sigmoid\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing activation configuration: tanh\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8095\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8095\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:14:03.739050Z",
     "start_time": "2025-03-29T06:12:52.489458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for act_custom in bonus_activation_configs:\n",
    "    print(f\"\\nTesting activation configuration: {act_custom}\")\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[act_custom] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_scratch_output(custom_mlp, X_train_scaled, y_train_one_hot, X_test_scaled, y_test_one_hot)"
   ],
   "id": "b8078fd0146278d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing activation configuration: softsign\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[ 0.34849682,  0.20366047,  0.14421766, ..., -0.11011714,\n",
      "         0.85692686, -0.20459601],\n",
      "       [ 0.43855953,  0.09489525,  0.03395932, ..., -0.07869318,\n",
      "         0.03085322, -0.7965541 ],\n",
      "       [-0.20512688,  0.14743526, -0.8297421 , ..., -0.05077973,\n",
      "        -0.49387592,  0.17818075],\n",
      "       ...,\n",
      "       [-0.6334432 , -0.34678155,  0.25855687, ..., -0.48119783,\n",
      "        -0.21261859, -0.14547339],\n",
      "       [ 0.5134772 , -0.6923477 ,  0.23591197, ...,  0.42926645,\n",
      "         0.39576954, -0.33404246],\n",
      "       [ 0.28817222, -0.24174216, -0.67546964, ..., -0.4206143 ,\n",
      "        -0.25590882, -0.3167226 ]], shape=(784, 128), dtype=float32), array([[ 0.26231116,  0.22627188,  0.23337834, ...,  0.32387826,\n",
      "        -0.35762906,  0.15279643],\n",
      "       [-0.30226976,  0.03051095,  0.4826649 , ..., -0.04104296,\n",
      "        -0.5140538 ,  0.8041288 ],\n",
      "       [-1.0443975 ,  0.4134605 ,  0.00576117, ...,  0.5646582 ,\n",
      "         0.11251439,  0.22100815],\n",
      "       ...,\n",
      "       [ 0.31304032, -0.5955745 , -0.34466562, ...,  0.09856506,\n",
      "         0.2330836 , -0.5352124 ],\n",
      "       [-0.714128  , -0.402061  ,  0.22256942, ..., -0.5886116 ,\n",
      "         0.04714872,  0.05962033],\n",
      "       [ 0.3953012 ,  0.37696984,  0.7386325 , ...,  0.3396097 ,\n",
      "         0.20317905,  0.1846546 ]], shape=(128, 64), dtype=float32), array([[-0.01097698, -0.39204717,  0.34126866, ..., -0.44136396,\n",
      "        -0.01914397,  0.48577234],\n",
      "       [-0.45033967,  0.44150946,  1.0973333 , ...,  0.04489783,\n",
      "        -0.28581965, -0.00131663],\n",
      "       [-0.29405773,  0.27663243, -0.02633004, ..., -0.36102077,\n",
      "        -0.23088397, -0.43987444],\n",
      "       ...,\n",
      "       [-0.07007778, -0.29170156,  0.05018962, ...,  0.03995779,\n",
      "        -0.70015496,  0.08813964],\n",
      "       [ 0.62896496, -0.104601  ,  0.3416828 , ...,  0.20473415,\n",
      "         1.0052451 , -0.077696  ],\n",
      "       [-0.40165582, -0.27237108,  0.5740399 , ...,  0.02129571,\n",
      "        -0.11922266, -0.07703016]], shape=(64, 32), dtype=float32), array([[ 0.7204127 ,  0.7099716 ,  0.69225806, -0.6109203 , -0.27613434,\n",
      "         0.40112773,  0.47902328, -0.55767184, -0.6259416 , -0.1573319 ],\n",
      "       [ 0.9170403 , -0.38125572,  0.22972363, -0.3299394 , -0.59638184,\n",
      "        -0.69619614,  0.7651346 , -0.37037918, -0.0203748 , -0.47461554],\n",
      "       [ 0.83770406, -0.99861836,  0.2715536 ,  0.58497053,  0.48787874,\n",
      "         0.5642876 ,  0.33043402,  0.0450808 , -0.66402847, -0.2971542 ],\n",
      "       [ 0.1197493 ,  0.1907032 ,  0.72373027,  0.41557842, -0.991384  ,\n",
      "         0.50318867, -0.58786845, -1.0777855 ,  0.77291507, -1.1044562 ],\n",
      "       [ 0.2827247 ,  0.2907327 ,  0.94386435,  0.7179124 , -0.64072365,\n",
      "        -0.12279825, -0.4846252 ,  0.80836   , -0.07239278, -0.18898241],\n",
      "       [ 0.58971167, -0.67847794,  0.4483067 ,  1.153679  , -0.820612  ,\n",
      "         0.55143875, -0.202845  ,  0.32297128,  0.49067575,  0.34987888],\n",
      "       [-0.09280388,  0.3492394 ,  0.904619  ,  0.290804  , -0.23271953,\n",
      "         0.12079979, -0.3649038 ,  0.3439376 ,  0.30045256,  0.6159471 ],\n",
      "       [-0.5354497 , -0.26516852, -0.27697515, -0.8514674 ,  0.6712096 ,\n",
      "        -0.18421718, -0.5342671 , -0.646691  , -0.08797527, -0.7688181 ],\n",
      "       [ 0.5668009 , -0.20420077, -0.39120963,  0.5754258 , -0.18239327,\n",
      "        -0.16648374, -0.31866306,  1.1457775 , -0.26645812,  0.17452592],\n",
      "       [ 0.24921803,  0.14576587, -0.50916237,  0.06602102, -0.4467171 ,\n",
      "         0.5543709 ,  0.67179394, -0.41606414,  0.04705325, -0.12727802],\n",
      "       [ 0.04826403,  0.26530164,  0.781513  , -1.1369802 ,  0.20986941,\n",
      "        -0.9059248 ,  0.25102717, -0.4265922 ,  0.3835998 ,  0.42520526],\n",
      "       [-0.52382386, -0.30472362,  0.09557163, -0.45449767, -0.04246317,\n",
      "         0.39942583, -0.01698017, -0.36510253, -0.39326105, -0.60464144],\n",
      "       [-0.3850442 ,  0.4824293 ,  0.31405854,  0.19889323,  0.4759223 ,\n",
      "        -1.0478141 ,  0.6489551 ,  0.34936678, -0.925907  ,  0.6276769 ],\n",
      "       [-0.91379994, -0.22309966, -0.16849779,  0.81454957,  0.23518014,\n",
      "         0.10596516, -0.7416873 ,  0.28009805, -0.3829065 , -0.03763701],\n",
      "       [-0.24763964, -0.29722586,  0.36308882,  0.8860922 ,  0.12226193,\n",
      "         0.47546384, -0.01922692, -0.1523951 , -0.05291554, -0.2079673 ],\n",
      "       [-1.483457  , -0.04348015,  0.54778653, -0.2155732 ,  0.44437858,\n",
      "        -0.7403645 ,  0.86409473, -0.84253085,  0.16756593, -0.09903429],\n",
      "       [ 0.29531106,  0.5942569 , -0.8009987 , -0.20736799, -0.14429502,\n",
      "         0.14975129,  0.23702855, -0.32908502, -0.20407826,  0.09282242],\n",
      "       [-0.83703566,  0.13055521, -0.08705625, -1.1279304 ,  0.44131947,\n",
      "         0.6495838 , -0.03987997,  0.23644815,  0.20671166,  0.09117576],\n",
      "       [ 0.6448284 ,  0.8197347 ,  0.1739718 ,  0.2718735 , -0.41101384,\n",
      "         0.5439576 ,  0.95456505, -0.28252754, -0.09568114, -0.9123923 ],\n",
      "       [ 0.34086248,  0.5755959 ,  0.11127857,  0.05859969,  0.61362624,\n",
      "        -0.8526508 , -0.00527131,  0.76980203, -0.24926631,  0.30326664],\n",
      "       [ 0.1277646 , -0.6877366 , -0.57429105,  0.35579032,  0.04529991,\n",
      "         0.17108971, -0.07515186, -0.40237787,  0.2135834 ,  0.47240144],\n",
      "       [-0.8800322 ,  0.7484577 ,  0.6265876 ,  0.1055163 ,  0.4162778 ,\n",
      "         0.25211826, -0.08330514, -0.5420597 , -0.26711088, -0.5796081 ],\n",
      "       [ 0.23622194,  0.38853624, -0.37822375,  0.7115558 , -0.6243243 ,\n",
      "        -1.3252033 ,  0.02135982,  0.76002175,  0.02737786, -0.6571119 ],\n",
      "       [-0.35177925,  1.0424314 , -0.4518832 , -0.58684206, -0.0633937 ,\n",
      "         0.07116549, -0.70361584,  0.14227147,  0.5006534 ,  0.26803416],\n",
      "       [-0.17366143,  0.6949363 , -0.36704567, -0.8878293 , -0.39850032,\n",
      "        -0.0125149 , -0.12362846,  0.557051  , -0.93291587, -0.4505507 ],\n",
      "       [ 1.2563694 , -0.28107965, -0.2827237 , -0.9006139 ,  0.5401524 ,\n",
      "        -0.3898525 ,  0.80899787, -0.10066852, -0.8509776 ,  0.4827818 ],\n",
      "       [-0.088278  , -0.7226324 ,  0.5763182 , -0.57898456, -0.229248  ,\n",
      "        -0.09635891,  0.33073595,  0.54626995,  0.4034258 , -0.19533426],\n",
      "       [-0.53901434,  0.5742987 , -0.6313185 ,  0.64762175, -0.09365759,\n",
      "        -0.5258117 ,  0.344772  ,  0.09973102, -0.12827821,  0.794588  ],\n",
      "       [ 0.17852451, -0.22931182,  0.11215305, -0.4395629 ,  0.22604047,\n",
      "        -0.79445165,  0.03639711, -0.8455266 , -0.15694278, -0.7006492 ],\n",
      "       [-0.10984758, -0.07025682,  0.53138477,  0.10594755,  0.34747115,\n",
      "        -0.46252462,  0.5969733 , -0.34052768,  0.705917  , -0.79314363],\n",
      "       [-0.39587143,  0.6760719 ,  0.6192406 ,  0.4888085 , -0.9901978 ,\n",
      "        -0.37328103, -1.514959  , -0.20117919,  0.3509496 , -0.43621555],\n",
      "       [-0.51432526,  0.00227906, -0.00676178,  0.3264588 , -0.9080701 ,\n",
      "         0.07512802,  0.8013514 ,  0.07614506, -0.5196732 , -0.5350921 ]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[ 3.94492447e-01, -2.68388569e-01,  5.13341188e-01,\n",
      "        -3.00914466e-01, -7.00361729e-01,  1.39981136e-01,\n",
      "         5.29237926e-01,  4.33071226e-01,  4.38125372e-01,\n",
      "         3.27909648e-01, -1.34062201e-01, -2.24144787e-01,\n",
      "        -4.42302078e-01,  5.21468461e-01, -5.79003215e-01,\n",
      "        -4.67626303e-02, -1.91827968e-01, -8.91853690e-01,\n",
      "        -7.51000524e-01,  1.25623032e-01,  4.13721710e-01,\n",
      "        -4.63612437e-01,  2.96183139e-01, -4.72440898e-01,\n",
      "        -8.38857591e-01, -5.12665331e-01,  9.24483314e-02,\n",
      "        -9.50426579e-01,  9.65727307e-03,  1.47182748e-01,\n",
      "        -4.36681837e-01,  7.29103386e-01,  1.69297144e-01,\n",
      "        -3.39709610e-01, -5.58925748e-01, -9.89288032e-01,\n",
      "        -2.75809944e-01, -1.17612943e-01,  5.78496158e-01,\n",
      "        -7.79117793e-02, -4.92569096e-02, -6.30719244e-01,\n",
      "        -5.52588142e-02,  9.54769959e-04,  3.43548097e-02,\n",
      "         3.08365345e-01, -6.81464195e-01, -6.57052994e-01,\n",
      "         4.37798709e-01,  1.86958238e-01,  6.09728098e-01,\n",
      "        -1.12525070e+00,  7.40925595e-02, -5.50561488e-01,\n",
      "        -2.89281011e-01,  4.71602261e-01, -3.70885760e-01,\n",
      "         8.19538713e-01,  7.11581230e-01, -8.09975922e-01,\n",
      "        -2.76097417e-01, -1.42280839e-03,  7.69419312e-01,\n",
      "        -3.03679556e-01, -3.71441548e-03, -7.66071737e-01,\n",
      "        -9.18572307e-01,  3.32261860e-01, -3.32445055e-01,\n",
      "        -1.00659914e-01, -4.02111039e-02, -6.82542846e-02,\n",
      "         6.53434932e-01, -1.43058911e-01,  3.56220543e-01,\n",
      "         6.47645652e-01,  3.97290796e-01, -4.95959520e-01,\n",
      "         2.58716196e-01, -3.98846805e-01,  6.50611937e-01,\n",
      "         6.90776885e-01,  1.39335677e-01,  8.19832206e-01,\n",
      "         7.99369693e-01,  6.58770859e-01,  3.41742784e-01,\n",
      "        -1.40575528e-01, -7.14725494e-01,  1.08324796e-01,\n",
      "         5.94543032e-02,  4.45702642e-01, -1.21275030e-01,\n",
      "         4.10327464e-01,  9.49784458e-01,  3.54100734e-01,\n",
      "         2.96718460e-02,  3.07525117e-02, -6.86832547e-01,\n",
      "        -1.28142715e-01, -1.67352498e-01,  2.41211846e-01,\n",
      "         1.25670359e-01, -2.48657495e-01, -2.86309253e-02,\n",
      "        -1.93881154e-01,  4.19597596e-01, -7.43409693e-02,\n",
      "         7.01713264e-01, -2.43993804e-01, -5.89550674e-01,\n",
      "        -1.02329135e+00, -4.06341195e-01,  4.59501773e-01,\n",
      "         8.30461979e-01,  3.99443746e-01, -2.20399141e-01,\n",
      "         1.15382262e-01, -9.99832511e-01,  9.93705615e-02,\n",
      "        -8.52853775e-01, -5.85266292e-01,  1.34050339e-01,\n",
      "        -9.40899923e-02,  6.22380197e-01, -1.24202333e-01,\n",
      "        -7.49958336e-01,  4.60065961e-01]], dtype=float32), array([[ 0.57229245, -0.4921641 , -0.02047594, -0.11161993, -0.14837055,\n",
      "         0.67375875, -0.16336799, -0.11275502, -0.68413556, -0.45838147,\n",
      "        -0.19903079, -0.50133336,  0.5108807 , -0.15276337,  0.09734812,\n",
      "         0.40165958,  0.3345365 , -0.07078214,  0.1345577 ,  0.39173922,\n",
      "        -0.5185641 , -0.23932557,  0.8959845 , -0.26165777, -0.11799584,\n",
      "        -0.3322507 ,  0.1984471 , -0.25416863, -0.3084513 , -0.4509186 ,\n",
      "         0.04308396, -0.8567555 ,  0.25783396,  0.6958684 ,  0.13590874,\n",
      "        -0.34085736,  0.4041951 ,  0.27035877, -0.374453  , -0.29089427,\n",
      "         0.3782791 ,  0.26549035,  0.62670785,  0.35680193, -0.31367528,\n",
      "         0.24909583, -0.60611004,  0.36518577,  0.27569142, -0.50282395,\n",
      "         0.6430617 ,  0.28042766,  0.4477292 ,  0.7115216 , -0.30274227,\n",
      "        -0.6049151 , -0.13252312,  0.3566628 ,  0.3981432 , -0.10195444,\n",
      "         0.17771171, -0.00163098,  0.46093804, -0.44854707]],\n",
      "      dtype=float32), array([[-0.67529637,  0.14935479,  0.9539334 ,  0.80657315,  0.05500464,\n",
      "         0.16428562,  0.49200463, -0.07846101,  0.09219555, -0.10993982,\n",
      "         0.7921933 ,  0.09185998,  0.08743745,  1.0153522 ,  0.42775092,\n",
      "         0.14131035, -0.55989796, -1.0037374 , -0.4519436 , -0.4843997 ,\n",
      "         0.38699013,  0.04907554, -0.62295645,  0.23897855,  0.05980467,\n",
      "        -0.0927083 ,  0.2675723 ,  0.53416723, -0.8177954 ,  0.74935466,\n",
      "         0.5718863 , -0.2565842 ]], dtype=float32), array([[-0.47766176, -0.5079046 ,  0.15333942, -0.55035883, -0.27512988,\n",
      "         0.7785856 , -0.09687501,  0.3779984 ,  0.24427278, -0.47351688]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 9 1]\n",
      "Prediction Probability:\n",
      " [[1.33431092e-06 1.07835873e-03 1.49960853e-02 ... 5.61885681e-05\n",
      "  9.75956321e-01 3.98957217e-03]\n",
      " [4.46932245e-06 1.75458030e-04 4.19499956e-05 ... 1.37302547e-03\n",
      "  1.86689699e-03 6.61709979e-02]\n",
      " [2.62662908e-03 2.15866603e-02 7.21748732e-03 ... 1.48233585e-03\n",
      "  7.10108578e-02 3.42200436e-02]\n",
      " ...\n",
      " [1.02461036e-03 1.14386678e-01 7.50571370e-01 ... 2.27898220e-03\n",
      "  1.15592904e-01 5.23065450e-04]\n",
      " [5.81721179e-05 2.13948879e-04 3.72437171e-05 ... 4.72946167e-01\n",
      "  2.87145085e-04 5.22811949e-01]\n",
      " [2.98266878e-06 9.90340889e-01 4.89238882e-03 ... 1.84297969e-04\n",
      "  3.70660750e-03 8.56325714e-05]]\n",
      "Loss:\n",
      " [1.7462277629741472, 1.0167035364979977, 0.8207294853839009, 0.7150969054440373, 0.644987641286893, 0.5938691025455589, 0.5544488577655062, 0.5227499853430485, 0.49640787828423344, 0.47396729994348225, 0.4544989210709601, 0.4372607014766049, 0.421835251327764, 0.4079676841574533, 0.39544551550415463]\n",
      "Accuracy:\n",
      " 0.8529285714285715\n",
      "\n",
      "Testing activation configuration: softplus\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:112: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log(1 + np.exp(x))\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:283: RuntimeWarning: invalid value encountered in matmul\n",
      "  a_k = b_k + (h_k_min_1 @ w_k) # numpy will automatically broadcast b_k (row will be copied to match the result from dot) so that this is addable\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:107: RuntimeWarning: invalid value encountered in subtract\n",
      "  exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:137: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x)) # sigmoid(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]],\n",
      "      shape=(784, 128), dtype=float32), array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]],\n",
      "      shape=(128, 64), dtype=float32), array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]], shape=(64, 32), dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)]\n",
      "Biases:\n",
      " [array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "      dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "      dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan]], dtype=float32), array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)]\n",
      "Prediction:\n",
      " [0 0 0 ... 0 0 0]\n",
      "Prediction Probability:\n",
      " [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Loss:\n",
      " [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Accuracy:\n",
      " 0.09592857142857143\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pengaruh learning rate",
   "id": "f403053e9c150dd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:14:03.775155Z",
     "start_time": "2025-03-29T06:14:03.772185Z"
    }
   },
   "cell_type": "code",
   "source": "learning_rates = [0.1, 0.06, 0.006, 0.0009]",
   "id": "d67ad2a321d25bbf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:19:32.880447Z",
     "start_time": "2025-03-29T06:14:03.841971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Learning Rate Variations Experiment:\")\n",
    "for rate in learning_rates:\n",
    "    print(f\"\\nTesting activation configuration: {rate}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=init_method,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "b21ff3b736552045",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate Variations Experiment:\n",
      "\n",
      "Testing activation configuration: 0.1\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8362857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "[[-1.2339124e-05  6.1707797e-06 -2.0272801e-06 ...  1.4391768e-05\n",
      "   3.2699811e-01  1.6529350e-05]\n",
      " [ 2.8024482e-02  1.6078342e-05 -6.2238705e-06 ...  1.0345961e-05\n",
      "  -1.2563138e-05 -2.8385484e-01]\n",
      " [ 1.5986505e-05  8.2681636e-06 -3.0757144e-01 ... -1.1510952e-05\n",
      "  -6.7554668e-02  9.9791687e-06]\n",
      " ...\n",
      " [-1.6729239e-01  5.4763477e-06  4.2207848e-06 ... -5.8494825e-02\n",
      "   1.8479319e-05 -1.5473250e-05]\n",
      " [ 8.1562303e-02 -2.0938627e-01  7.4062227e-06 ...  2.1383431e-02\n",
      "   2.8339946e-06 -1.0776417e-05]\n",
      " [-1.7302587e-05  7.2310340e-06 -1.9732551e-01 ... -1.5200627e-02\n",
      "  -1.6433622e-05  1.6390066e-05]] != [[ 0.34849682  0.20366047  0.14421766 ... -0.11011714  0.85692686\n",
      "  -0.20459601]\n",
      " [ 0.43855953  0.09489525  0.03395932 ... -0.07869318  0.03085322\n",
      "  -0.7965541 ]\n",
      " [-0.20512688  0.14743526 -0.8297421  ... -0.05077973 -0.49387592\n",
      "   0.17818075]\n",
      " ...\n",
      " [-0.6334432  -0.34678155  0.25855687 ... -0.48119783 -0.21261859\n",
      "  -0.14547339]\n",
      " [ 0.5134772  -0.6923477   0.23591197 ...  0.42926645  0.39576954\n",
      "  -0.33404246]\n",
      " [ 0.28817222 -0.24174216 -0.67546964 ... -0.4206143  -0.25590882\n",
      "  -0.3167226 ]]\n",
      "❌ Weight is not equal\n",
      "[ 0.34541878 -0.30712166  0.5128488  -0.30251643 -0.69670784  0.14878309\n",
      "  0.5452603   0.47974178  0.34924644  0.29811734 -0.12199063 -0.15518275\n",
      " -0.39104673  0.48191002 -0.5993515  -0.0363385  -0.20320347 -0.8636746\n",
      " -0.7627112   0.13968942  0.39563003 -0.52148813  0.33583224 -0.46464124\n",
      " -0.87039274 -0.48156792  0.06638193 -0.97056335  0.00920691  0.11480398\n",
      " -0.38946232  0.70793015  0.14215922 -0.2573876  -0.5114342  -0.9761748\n",
      " -0.30373698 -0.05856661  0.5742081  -0.07955136 -0.08781307 -0.5735589\n",
      " -0.08638193 -0.01953233  0.02971209  0.28889525 -0.6892418  -0.5713967\n",
      "  0.3846094   0.19209358  0.61518127 -1.0976732   0.06896095 -0.51621234\n",
      " -0.2964217   0.42266056 -0.2684471   0.80217755  0.6477866  -0.7656369\n",
      " -0.24580753  0.04094169  0.7928772  -0.32642135  0.0601295  -0.7632569\n",
      " -0.872376    0.32710376 -0.30702573 -0.04316778 -0.10955929 -0.05613354\n",
      "  0.60653234 -0.19567479  0.32773307  0.6649624   0.3719435  -0.52469903\n",
      "  0.23486353 -0.37950015  0.64071107  0.671582    0.15010543  0.83088666\n",
      "  0.7680851   0.59771574  0.31786156 -0.14728881 -0.6465453   0.16046338\n",
      "  0.05503958  0.38165212 -0.01995325  0.45715642  0.9457689   0.391658\n",
      " -0.01326181 -0.02243148 -0.6643187  -0.15170328 -0.16890296  0.22360955\n",
      "  0.08744767 -0.2649966  -0.0472195  -0.13810168  0.4469174  -0.08987375\n",
      "  0.7030968  -0.24140397 -0.5545762  -1.0331299  -0.38860837  0.45160547\n",
      "  0.8156796   0.404415   -0.26204303  0.08217209 -1.0641197   0.06205386\n",
      " -0.8612699  -0.5444995   0.16815262 -0.1352088   0.63377726 -0.13194498\n",
      " -0.72448117  0.4497912 ] != [[ 0.3843087  -0.29688656  0.49724793 -0.28930914 -0.70555353  0.17150219\n",
      "   0.54977214  0.46768335  0.38018295  0.31251106 -0.11688785 -0.23131967\n",
      "  -0.39918327  0.5052186  -0.5813782  -0.044542   -0.19723064 -0.874634\n",
      "  -0.78190833  0.11687379  0.39293426 -0.50267774  0.32230118 -0.4756778\n",
      "  -0.8770544  -0.5136607   0.0707184  -0.96808916  0.00460624  0.13499096\n",
      "  -0.43886957  0.72422564  0.1468646  -0.28035358 -0.53608465 -0.9949935\n",
      "  -0.3113414  -0.07738227  0.5936222  -0.08947714 -0.08513924 -0.6109076\n",
      "  -0.07670642 -0.02981681  0.02459542  0.32015744 -0.70636004 -0.60070086\n",
      "   0.39980406  0.1817733   0.60889643 -1.1293083   0.07157541 -0.51670843\n",
      "  -0.3064252   0.43554595 -0.30872113  0.81861776  0.66368765 -0.7776041\n",
      "  -0.28340557  0.04373093  0.80078864 -0.3198678   0.04232036 -0.7869165\n",
      "  -0.9044475   0.331164   -0.28484946 -0.06050663 -0.09502597 -0.05080884\n",
      "   0.61707103 -0.16437104  0.34050396  0.6627105   0.39226943 -0.5011954\n",
      "   0.24984759 -0.3549917   0.6455956   0.6711182   0.14952399  0.8361552\n",
      "   0.7868884   0.62411594  0.33130804 -0.15233496 -0.6622102   0.161451\n",
      "   0.05876899  0.39965543 -0.07105149  0.44568205  0.94896543  0.38349134\n",
      "  -0.00707594 -0.00114139 -0.6657302  -0.14320013 -0.16470422  0.24496756\n",
      "   0.08497234 -0.27031964 -0.04653125 -0.14063287  0.4510741  -0.09183381\n",
      "   0.7254135  -0.2105374  -0.5700184  -1.0215135  -0.40055174  0.46007922\n",
      "   0.81848013  0.41192296 -0.2513124   0.10021974 -1.0650507   0.07894867\n",
      "  -0.85007894 -0.552549    0.15138772 -0.13564011  0.62701714 -0.12457432\n",
      "  -0.74283904  0.47657514]]\n",
      "❌ Bias is not equal\n",
      "8 != 5\n",
      "❌ Prediction is not equal\n",
      "[0.00563823 0.03765884 0.13985676 0.09721578 0.01519534 0.11560182\n",
      " 0.01166354 0.00779734 0.5490797  0.0202926 ] != [6.62872189e-05 5.36913751e-03 3.78053822e-02 2.55300235e-02\n",
      " 1.60590967e-03 3.25715691e-02 3.79314326e-04 8.14578554e-04\n",
      " 8.92411649e-01 3.44610773e-03]\n",
      "❌ Prediction Probability is not equal\n",
      "59.31636048044477 != 2.1326456593752354\n",
      "❌ Loss is not equal\n",
      "❌ Accuracy is not equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.06\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8362857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "[[-1.2339124e-05  6.1707797e-06 -2.0272801e-06 ...  1.4391768e-05\n",
      "   3.2699811e-01  1.6529350e-05]\n",
      " [ 2.8024482e-02  1.6078342e-05 -6.2238705e-06 ...  1.0345961e-05\n",
      "  -1.2563138e-05 -2.8385484e-01]\n",
      " [ 1.5986505e-05  8.2681636e-06 -3.0757144e-01 ... -1.1510952e-05\n",
      "  -6.7554668e-02  9.9791687e-06]\n",
      " ...\n",
      " [-1.6729239e-01  5.4763477e-06  4.2207848e-06 ... -5.8494825e-02\n",
      "   1.8479319e-05 -1.5473250e-05]\n",
      " [ 8.1562303e-02 -2.0938627e-01  7.4062227e-06 ...  2.1383431e-02\n",
      "   2.8339946e-06 -1.0776417e-05]\n",
      " [-1.7302587e-05  7.2310340e-06 -1.9732551e-01 ... -1.5200627e-02\n",
      "  -1.6433622e-05  1.6390066e-05]] != [[ 0.34849682  0.20366047  0.14421766 ... -0.11011714  0.85692686\n",
      "  -0.20459601]\n",
      " [ 0.43855953  0.09489525  0.03395932 ... -0.07869318  0.03085322\n",
      "  -0.7965541 ]\n",
      " [-0.20512688  0.14743526 -0.8297421  ... -0.05077973 -0.49387592\n",
      "   0.17818075]\n",
      " ...\n",
      " [-0.6334432  -0.34678155  0.25855687 ... -0.48119783 -0.21261859\n",
      "  -0.14547339]\n",
      " [ 0.5134772  -0.6923477   0.23591197 ...  0.42926645  0.39576954\n",
      "  -0.33404246]\n",
      " [ 0.28817222 -0.24174216 -0.67546964 ... -0.4206143  -0.25590882\n",
      "  -0.3167226 ]]\n",
      "❌ Weight is not equal\n",
      "[ 0.34541878 -0.30712166  0.5128488  -0.30251643 -0.69670784  0.14878309\n",
      "  0.5452603   0.47974178  0.34924644  0.29811734 -0.12199063 -0.15518275\n",
      " -0.39104673  0.48191002 -0.5993515  -0.0363385  -0.20320347 -0.8636746\n",
      " -0.7627112   0.13968942  0.39563003 -0.52148813  0.33583224 -0.46464124\n",
      " -0.87039274 -0.48156792  0.06638193 -0.97056335  0.00920691  0.11480398\n",
      " -0.38946232  0.70793015  0.14215922 -0.2573876  -0.5114342  -0.9761748\n",
      " -0.30373698 -0.05856661  0.5742081  -0.07955136 -0.08781307 -0.5735589\n",
      " -0.08638193 -0.01953233  0.02971209  0.28889525 -0.6892418  -0.5713967\n",
      "  0.3846094   0.19209358  0.61518127 -1.0976732   0.06896095 -0.51621234\n",
      " -0.2964217   0.42266056 -0.2684471   0.80217755  0.6477866  -0.7656369\n",
      " -0.24580753  0.04094169  0.7928772  -0.32642135  0.0601295  -0.7632569\n",
      " -0.872376    0.32710376 -0.30702573 -0.04316778 -0.10955929 -0.05613354\n",
      "  0.60653234 -0.19567479  0.32773307  0.6649624   0.3719435  -0.52469903\n",
      "  0.23486353 -0.37950015  0.64071107  0.671582    0.15010543  0.83088666\n",
      "  0.7680851   0.59771574  0.31786156 -0.14728881 -0.6465453   0.16046338\n",
      "  0.05503958  0.38165212 -0.01995325  0.45715642  0.9457689   0.391658\n",
      " -0.01326181 -0.02243148 -0.6643187  -0.15170328 -0.16890296  0.22360955\n",
      "  0.08744767 -0.2649966  -0.0472195  -0.13810168  0.4469174  -0.08987375\n",
      "  0.7030968  -0.24140397 -0.5545762  -1.0331299  -0.38860837  0.45160547\n",
      "  0.8156796   0.404415   -0.26204303  0.08217209 -1.0641197   0.06205386\n",
      " -0.8612699  -0.5444995   0.16815262 -0.1352088   0.63377726 -0.13194498\n",
      " -0.72448117  0.4497912 ] != [[ 0.3843087  -0.29688656  0.49724793 -0.28930914 -0.70555353  0.17150219\n",
      "   0.54977214  0.46768335  0.38018295  0.31251106 -0.11688785 -0.23131967\n",
      "  -0.39918327  0.5052186  -0.5813782  -0.044542   -0.19723064 -0.874634\n",
      "  -0.78190833  0.11687379  0.39293426 -0.50267774  0.32230118 -0.4756778\n",
      "  -0.8770544  -0.5136607   0.0707184  -0.96808916  0.00460624  0.13499096\n",
      "  -0.43886957  0.72422564  0.1468646  -0.28035358 -0.53608465 -0.9949935\n",
      "  -0.3113414  -0.07738227  0.5936222  -0.08947714 -0.08513924 -0.6109076\n",
      "  -0.07670642 -0.02981681  0.02459542  0.32015744 -0.70636004 -0.60070086\n",
      "   0.39980406  0.1817733   0.60889643 -1.1293083   0.07157541 -0.51670843\n",
      "  -0.3064252   0.43554595 -0.30872113  0.81861776  0.66368765 -0.7776041\n",
      "  -0.28340557  0.04373093  0.80078864 -0.3198678   0.04232036 -0.7869165\n",
      "  -0.9044475   0.331164   -0.28484946 -0.06050663 -0.09502597 -0.05080884\n",
      "   0.61707103 -0.16437104  0.34050396  0.6627105   0.39226943 -0.5011954\n",
      "   0.24984759 -0.3549917   0.6455956   0.6711182   0.14952399  0.8361552\n",
      "   0.7868884   0.62411594  0.33130804 -0.15233496 -0.6622102   0.161451\n",
      "   0.05876899  0.39965543 -0.07105149  0.44568205  0.94896543  0.38349134\n",
      "  -0.00707594 -0.00114139 -0.6657302  -0.14320013 -0.16470422  0.24496756\n",
      "   0.08497234 -0.27031964 -0.04653125 -0.14063287  0.4510741  -0.09183381\n",
      "   0.7254135  -0.2105374  -0.5700184  -1.0215135  -0.40055174  0.46007922\n",
      "   0.81848013  0.41192296 -0.2513124   0.10021974 -1.0650507   0.07894867\n",
      "  -0.85007894 -0.552549    0.15138772 -0.13564011  0.62701714 -0.12457432\n",
      "  -0.74283904  0.47657514]]\n",
      "❌ Bias is not equal\n",
      "8 != 5\n",
      "❌ Prediction is not equal\n",
      "[0.00563823 0.03765884 0.13985676 0.09721578 0.01519534 0.11560182\n",
      " 0.01166354 0.00779734 0.5490797  0.0202926 ] != [6.62872189e-05 5.36913751e-03 3.78053822e-02 2.55300235e-02\n",
      " 1.60590967e-03 3.25715691e-02 3.79314326e-04 8.14578554e-04\n",
      " 8.92411649e-01 3.44610773e-03]\n",
      "❌ Prediction Probability is not equal\n",
      "59.31636048044477 != 2.1326456593752354\n",
      "❌ Loss is not equal\n",
      "❌ Accuracy is not equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.006\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8362857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "[[-1.2339124e-05  6.1707797e-06 -2.0272801e-06 ...  1.4391768e-05\n",
      "   3.2699811e-01  1.6529350e-05]\n",
      " [ 2.8024482e-02  1.6078342e-05 -6.2238705e-06 ...  1.0345961e-05\n",
      "  -1.2563138e-05 -2.8385484e-01]\n",
      " [ 1.5986505e-05  8.2681636e-06 -3.0757144e-01 ... -1.1510952e-05\n",
      "  -6.7554668e-02  9.9791687e-06]\n",
      " ...\n",
      " [-1.6729239e-01  5.4763477e-06  4.2207848e-06 ... -5.8494825e-02\n",
      "   1.8479319e-05 -1.5473250e-05]\n",
      " [ 8.1562303e-02 -2.0938627e-01  7.4062227e-06 ...  2.1383431e-02\n",
      "   2.8339946e-06 -1.0776417e-05]\n",
      " [-1.7302587e-05  7.2310340e-06 -1.9732551e-01 ... -1.5200627e-02\n",
      "  -1.6433622e-05  1.6390066e-05]] != [[ 0.34849682  0.20366047  0.14421766 ... -0.11011714  0.85692686\n",
      "  -0.20459601]\n",
      " [ 0.43855953  0.09489525  0.03395932 ... -0.07869318  0.03085322\n",
      "  -0.7965541 ]\n",
      " [-0.20512688  0.14743526 -0.8297421  ... -0.05077973 -0.49387592\n",
      "   0.17818075]\n",
      " ...\n",
      " [-0.6334432  -0.34678155  0.25855687 ... -0.48119783 -0.21261859\n",
      "  -0.14547339]\n",
      " [ 0.5134772  -0.6923477   0.23591197 ...  0.42926645  0.39576954\n",
      "  -0.33404246]\n",
      " [ 0.28817222 -0.24174216 -0.67546964 ... -0.4206143  -0.25590882\n",
      "  -0.3167226 ]]\n",
      "❌ Weight is not equal\n",
      "[ 0.34541878 -0.30712166  0.5128488  -0.30251643 -0.69670784  0.14878309\n",
      "  0.5452603   0.47974178  0.34924644  0.29811734 -0.12199063 -0.15518275\n",
      " -0.39104673  0.48191002 -0.5993515  -0.0363385  -0.20320347 -0.8636746\n",
      " -0.7627112   0.13968942  0.39563003 -0.52148813  0.33583224 -0.46464124\n",
      " -0.87039274 -0.48156792  0.06638193 -0.97056335  0.00920691  0.11480398\n",
      " -0.38946232  0.70793015  0.14215922 -0.2573876  -0.5114342  -0.9761748\n",
      " -0.30373698 -0.05856661  0.5742081  -0.07955136 -0.08781307 -0.5735589\n",
      " -0.08638193 -0.01953233  0.02971209  0.28889525 -0.6892418  -0.5713967\n",
      "  0.3846094   0.19209358  0.61518127 -1.0976732   0.06896095 -0.51621234\n",
      " -0.2964217   0.42266056 -0.2684471   0.80217755  0.6477866  -0.7656369\n",
      " -0.24580753  0.04094169  0.7928772  -0.32642135  0.0601295  -0.7632569\n",
      " -0.872376    0.32710376 -0.30702573 -0.04316778 -0.10955929 -0.05613354\n",
      "  0.60653234 -0.19567479  0.32773307  0.6649624   0.3719435  -0.52469903\n",
      "  0.23486353 -0.37950015  0.64071107  0.671582    0.15010543  0.83088666\n",
      "  0.7680851   0.59771574  0.31786156 -0.14728881 -0.6465453   0.16046338\n",
      "  0.05503958  0.38165212 -0.01995325  0.45715642  0.9457689   0.391658\n",
      " -0.01326181 -0.02243148 -0.6643187  -0.15170328 -0.16890296  0.22360955\n",
      "  0.08744767 -0.2649966  -0.0472195  -0.13810168  0.4469174  -0.08987375\n",
      "  0.7030968  -0.24140397 -0.5545762  -1.0331299  -0.38860837  0.45160547\n",
      "  0.8156796   0.404415   -0.26204303  0.08217209 -1.0641197   0.06205386\n",
      " -0.8612699  -0.5444995   0.16815262 -0.1352088   0.63377726 -0.13194498\n",
      " -0.72448117  0.4497912 ] != [[ 0.3843087  -0.29688656  0.49724793 -0.28930914 -0.70555353  0.17150219\n",
      "   0.54977214  0.46768335  0.38018295  0.31251106 -0.11688785 -0.23131967\n",
      "  -0.39918327  0.5052186  -0.5813782  -0.044542   -0.19723064 -0.874634\n",
      "  -0.78190833  0.11687379  0.39293426 -0.50267774  0.32230118 -0.4756778\n",
      "  -0.8770544  -0.5136607   0.0707184  -0.96808916  0.00460624  0.13499096\n",
      "  -0.43886957  0.72422564  0.1468646  -0.28035358 -0.53608465 -0.9949935\n",
      "  -0.3113414  -0.07738227  0.5936222  -0.08947714 -0.08513924 -0.6109076\n",
      "  -0.07670642 -0.02981681  0.02459542  0.32015744 -0.70636004 -0.60070086\n",
      "   0.39980406  0.1817733   0.60889643 -1.1293083   0.07157541 -0.51670843\n",
      "  -0.3064252   0.43554595 -0.30872113  0.81861776  0.66368765 -0.7776041\n",
      "  -0.28340557  0.04373093  0.80078864 -0.3198678   0.04232036 -0.7869165\n",
      "  -0.9044475   0.331164   -0.28484946 -0.06050663 -0.09502597 -0.05080884\n",
      "   0.61707103 -0.16437104  0.34050396  0.6627105   0.39226943 -0.5011954\n",
      "   0.24984759 -0.3549917   0.6455956   0.6711182   0.14952399  0.8361552\n",
      "   0.7868884   0.62411594  0.33130804 -0.15233496 -0.6622102   0.161451\n",
      "   0.05876899  0.39965543 -0.07105149  0.44568205  0.94896543  0.38349134\n",
      "  -0.00707594 -0.00114139 -0.6657302  -0.14320013 -0.16470422  0.24496756\n",
      "   0.08497234 -0.27031964 -0.04653125 -0.14063287  0.4510741  -0.09183381\n",
      "   0.7254135  -0.2105374  -0.5700184  -1.0215135  -0.40055174  0.46007922\n",
      "   0.81848013  0.41192296 -0.2513124   0.10021974 -1.0650507   0.07894867\n",
      "  -0.85007894 -0.552549    0.15138772 -0.13564011  0.62701714 -0.12457432\n",
      "  -0.74283904  0.47657514]]\n",
      "❌ Bias is not equal\n",
      "8 != 5\n",
      "❌ Prediction is not equal\n",
      "[0.00563823 0.03765884 0.13985676 0.09721578 0.01519534 0.11560182\n",
      " 0.01166354 0.00779734 0.5490797  0.0202926 ] != [6.62872189e-05 5.36913751e-03 3.78053822e-02 2.55300235e-02\n",
      " 1.60590967e-03 3.25715691e-02 3.79314326e-04 8.14578554e-04\n",
      " 8.92411649e-01 3.44610773e-03]\n",
      "❌ Prediction Probability is not equal\n",
      "59.31636048044477 != 2.1326456593752354\n",
      "❌ Loss is not equal\n",
      "❌ Accuracy is not equal\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.0009\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8362857142857143\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "[[-1.2339124e-05  6.1707797e-06 -2.0272801e-06 ...  1.4391768e-05\n",
      "   3.2699811e-01  1.6529350e-05]\n",
      " [ 2.8024482e-02  1.6078342e-05 -6.2238705e-06 ...  1.0345961e-05\n",
      "  -1.2563138e-05 -2.8385484e-01]\n",
      " [ 1.5986505e-05  8.2681636e-06 -3.0757144e-01 ... -1.1510952e-05\n",
      "  -6.7554668e-02  9.9791687e-06]\n",
      " ...\n",
      " [-1.6729239e-01  5.4763477e-06  4.2207848e-06 ... -5.8494825e-02\n",
      "   1.8479319e-05 -1.5473250e-05]\n",
      " [ 8.1562303e-02 -2.0938627e-01  7.4062227e-06 ...  2.1383431e-02\n",
      "   2.8339946e-06 -1.0776417e-05]\n",
      " [-1.7302587e-05  7.2310340e-06 -1.9732551e-01 ... -1.5200627e-02\n",
      "  -1.6433622e-05  1.6390066e-05]] != [[ 0.34849682  0.20366047  0.14421766 ... -0.11011714  0.85692686\n",
      "  -0.20459601]\n",
      " [ 0.43855953  0.09489525  0.03395932 ... -0.07869318  0.03085322\n",
      "  -0.7965541 ]\n",
      " [-0.20512688  0.14743526 -0.8297421  ... -0.05077973 -0.49387592\n",
      "   0.17818075]\n",
      " ...\n",
      " [-0.6334432  -0.34678155  0.25855687 ... -0.48119783 -0.21261859\n",
      "  -0.14547339]\n",
      " [ 0.5134772  -0.6923477   0.23591197 ...  0.42926645  0.39576954\n",
      "  -0.33404246]\n",
      " [ 0.28817222 -0.24174216 -0.67546964 ... -0.4206143  -0.25590882\n",
      "  -0.3167226 ]]\n",
      "❌ Weight is not equal\n",
      "[ 0.34541878 -0.30712166  0.5128488  -0.30251643 -0.69670784  0.14878309\n",
      "  0.5452603   0.47974178  0.34924644  0.29811734 -0.12199063 -0.15518275\n",
      " -0.39104673  0.48191002 -0.5993515  -0.0363385  -0.20320347 -0.8636746\n",
      " -0.7627112   0.13968942  0.39563003 -0.52148813  0.33583224 -0.46464124\n",
      " -0.87039274 -0.48156792  0.06638193 -0.97056335  0.00920691  0.11480398\n",
      " -0.38946232  0.70793015  0.14215922 -0.2573876  -0.5114342  -0.9761748\n",
      " -0.30373698 -0.05856661  0.5742081  -0.07955136 -0.08781307 -0.5735589\n",
      " -0.08638193 -0.01953233  0.02971209  0.28889525 -0.6892418  -0.5713967\n",
      "  0.3846094   0.19209358  0.61518127 -1.0976732   0.06896095 -0.51621234\n",
      " -0.2964217   0.42266056 -0.2684471   0.80217755  0.6477866  -0.7656369\n",
      " -0.24580753  0.04094169  0.7928772  -0.32642135  0.0601295  -0.7632569\n",
      " -0.872376    0.32710376 -0.30702573 -0.04316778 -0.10955929 -0.05613354\n",
      "  0.60653234 -0.19567479  0.32773307  0.6649624   0.3719435  -0.52469903\n",
      "  0.23486353 -0.37950015  0.64071107  0.671582    0.15010543  0.83088666\n",
      "  0.7680851   0.59771574  0.31786156 -0.14728881 -0.6465453   0.16046338\n",
      "  0.05503958  0.38165212 -0.01995325  0.45715642  0.9457689   0.391658\n",
      " -0.01326181 -0.02243148 -0.6643187  -0.15170328 -0.16890296  0.22360955\n",
      "  0.08744767 -0.2649966  -0.0472195  -0.13810168  0.4469174  -0.08987375\n",
      "  0.7030968  -0.24140397 -0.5545762  -1.0331299  -0.38860837  0.45160547\n",
      "  0.8156796   0.404415   -0.26204303  0.08217209 -1.0641197   0.06205386\n",
      " -0.8612699  -0.5444995   0.16815262 -0.1352088   0.63377726 -0.13194498\n",
      " -0.72448117  0.4497912 ] != [[ 0.3843087  -0.29688656  0.49724793 -0.28930914 -0.70555353  0.17150219\n",
      "   0.54977214  0.46768335  0.38018295  0.31251106 -0.11688785 -0.23131967\n",
      "  -0.39918327  0.5052186  -0.5813782  -0.044542   -0.19723064 -0.874634\n",
      "  -0.78190833  0.11687379  0.39293426 -0.50267774  0.32230118 -0.4756778\n",
      "  -0.8770544  -0.5136607   0.0707184  -0.96808916  0.00460624  0.13499096\n",
      "  -0.43886957  0.72422564  0.1468646  -0.28035358 -0.53608465 -0.9949935\n",
      "  -0.3113414  -0.07738227  0.5936222  -0.08947714 -0.08513924 -0.6109076\n",
      "  -0.07670642 -0.02981681  0.02459542  0.32015744 -0.70636004 -0.60070086\n",
      "   0.39980406  0.1817733   0.60889643 -1.1293083   0.07157541 -0.51670843\n",
      "  -0.3064252   0.43554595 -0.30872113  0.81861776  0.66368765 -0.7776041\n",
      "  -0.28340557  0.04373093  0.80078864 -0.3198678   0.04232036 -0.7869165\n",
      "  -0.9044475   0.331164   -0.28484946 -0.06050663 -0.09502597 -0.05080884\n",
      "   0.61707103 -0.16437104  0.34050396  0.6627105   0.39226943 -0.5011954\n",
      "   0.24984759 -0.3549917   0.6455956   0.6711182   0.14952399  0.8361552\n",
      "   0.7868884   0.62411594  0.33130804 -0.15233496 -0.6622102   0.161451\n",
      "   0.05876899  0.39965543 -0.07105149  0.44568205  0.94896543  0.38349134\n",
      "  -0.00707594 -0.00114139 -0.6657302  -0.14320013 -0.16470422  0.24496756\n",
      "   0.08497234 -0.27031964 -0.04653125 -0.14063287  0.4510741  -0.09183381\n",
      "   0.7254135  -0.2105374  -0.5700184  -1.0215135  -0.40055174  0.46007922\n",
      "   0.81848013  0.41192296 -0.2513124   0.10021974 -1.0650507   0.07894867\n",
      "  -0.85007894 -0.552549    0.15138772 -0.13564011  0.62701714 -0.12457432\n",
      "  -0.74283904  0.47657514]]\n",
      "❌ Bias is not equal\n",
      "8 != 5\n",
      "❌ Prediction is not equal\n",
      "[0.00563823 0.03765884 0.13985676 0.09721578 0.01519534 0.11560182\n",
      " 0.01166354 0.00779734 0.5490797  0.0202926 ] != [6.62872189e-05 5.36913751e-03 3.78053822e-02 2.55300235e-02\n",
      " 1.60590967e-03 3.25715691e-02 3.79314326e-04 8.14578554e-04\n",
      " 8.92411649e-01 3.44610773e-03]\n",
      "❌ Prediction Probability is not equal\n",
      "59.31636048044477 != 2.1326456593752354\n",
      "❌ Loss is not equal\n",
      "❌ Accuracy is not equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Perbandingan Weight",
   "id": "ddcb9cda56cd61b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:19:32.916302Z",
     "start_time": "2025-03-29T06:19:32.912598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight_configs =  ['normal', 'zero', 'uniform']\n",
    "additional_weight_configs = [\"xavier_normal\",\"xavier_uniform\",\"he_normal\",\"he_uniform\"]"
   ],
   "id": "34d5132af2f90c41",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:22:53.891454Z",
     "start_time": "2025-03-29T06:19:32.967075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Weight Variations Experiment:\")\n",
    "for weight_config in weight_configs:\n",
    "    print(f\"\\nTesting weight configuration: {weight_config}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPLIB(\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        activation=activation_mlplib,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "d5c0d65e76b4a222",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Variations Experiment:\n",
      "\n",
      "Testing weight configuration: normal\n",
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.8449285714285715\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing weight configuration: zero\n",
      "[SKLearn MLPClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[From Scratch FFNNClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[Comparison Result]\n",
      "[[2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " ...\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]\n",
      " [2.2941954e-06 2.2941954e-06 2.2941954e-06 ... 2.2941954e-06\n",
      "  2.2941954e-06 2.2941954e-06]] != [[3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " ...\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]\n",
      " [3.6016156e-06 3.6016156e-06 3.6016156e-06 ... 3.6016152e-06\n",
      "  3.6016152e-06 3.6016152e-06]]\n",
      "❌ Weight is not equal\n",
      "[4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883903e-06 4.5883903e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06 4.5883912e-06\n",
      " 4.5883912e-06 4.5883903e-06 4.5883903e-06 4.5883903e-06 4.5883903e-06\n",
      " 4.5883908e-06 4.5883908e-06 4.5883908e-06 4.5883908e-06] != [[7.2032235e-06 7.2032235e-06 7.2032235e-06 7.2032235e-06 7.2032235e-06\n",
      "  7.2032235e-06 7.2032180e-06 7.2032180e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032171e-06 7.2032171e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032171e-06 7.2032171e-06 7.2032199e-06 7.2032199e-06\n",
      "  7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032199e-06 7.2032171e-06\n",
      "  7.2032171e-06 7.2032180e-06 7.2032180e-06 7.2032180e-06 7.2032180e-06\n",
      "  7.2032212e-06 7.2032212e-06 7.2032212e-06 7.2032212e-06]]\n",
      "❌ Bias is not equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n",
      "\n",
      "Testing weight configuration: uniform\n",
      "[SKLearn MLPClassifier]\n",
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.11428571428571428\n",
      "\n",
      "[Comparison Result]\n",
      "✅ Weight is equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:25:36.174943Z",
     "start_time": "2025-03-29T06:22:53.923367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Weight Variations Experiment:\")\n",
    "for weight_config in additional_weight_configs:\n",
    "    print(f\"\\nTesting weight configuration: {weight_config}\")\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=max_iter,\n",
    "        learning_rate=learning_rate_init,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        init_method=weight_config,\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        loss_func=\"categorical_cross_entropy\",\n",
    "        activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    )\n",
    "\n",
    "\n",
    "    model_scratch_output(custom_mlp, X_train_scaled, y_train_one_hot, X_test_scaled, y_test_one_hot)"
   ],
   "id": "ab226cab1800ddfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Variations Experiment:\n",
      "\n",
      "Testing weight configuration: xavier_normal\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [array([[ 0.03708485,  0.02166989,  0.01534337, ..., -0.01172553,\n",
      "         0.09119716, -0.02178094],\n",
      "       [ 0.04667024,  0.01009398,  0.00360856, ..., -0.00838107,\n",
      "         0.00327797, -0.08478315],\n",
      "       [-0.02183744,  0.01568583, -0.08831536, ..., -0.00541024,\n",
      "        -0.05256906,  0.01895807],\n",
      "       ...,\n",
      "       [-0.06742322, -0.03691377,  0.02751252, ..., -0.05121972,\n",
      "        -0.02263478, -0.0154885 ],\n",
      "       [ 0.05464375, -0.07369245,  0.02510242, ...,  0.04568118,\n",
      "         0.04211609, -0.03555795],\n",
      "       [ 0.03066449, -0.02573441, -0.07189611, ..., -0.04477181,\n",
      "        -0.02724217, -0.03371459]], shape=(784, 128), dtype=float32), array([[ 0.07391854,  0.09762227,  0.0952058 , ...,  0.12700953,\n",
      "        -0.18754998,  0.11732751],\n",
      "       [-0.14079145, -0.02479143,  0.10170957, ..., -0.10474101,\n",
      "        -0.08239639,  0.2188448 ],\n",
      "       [-0.3020406 ,  0.08188853, -0.00455378, ...,  0.08547567,\n",
      "         0.03392957,  0.10718075],\n",
      "       ...,\n",
      "       [ 0.02982106, -0.11962556, -0.12138741, ..., -0.00797965,\n",
      "         0.09502236, -0.06457274],\n",
      "       [-0.25644338, -0.10264298,  0.0860009 , ..., -0.255818  ,\n",
      "         0.10702767,  0.06735586],\n",
      "       [ 0.05496534,  0.07951762,  0.12153868, ...,  0.08695514,\n",
      "         0.04303795,  0.11744409]], shape=(128, 64), dtype=float32), array([[ 0.0811865 ,  0.00712669,  0.17593239, ...,  0.03730543,\n",
      "        -0.22139604,  0.14148867],\n",
      "       [ 0.0829448 ,  0.15585694,  0.43094802, ...,  0.07676567,\n",
      "        -0.11778932,  0.03955482],\n",
      "       [-0.00703985,  0.1726818 ,  0.18840848, ..., -0.18066029,\n",
      "        -0.2827837 , -0.1825848 ],\n",
      "       ...,\n",
      "       [-0.03957482,  0.00111938,  0.09579929, ...,  0.15178092,\n",
      "        -0.4429578 , -0.16502456],\n",
      "       [ 0.34207976, -0.14533006,  0.00322332, ...,  0.02097213,\n",
      "         0.55554366, -0.10756957],\n",
      "       [-0.19098538,  0.08991863,  0.4130342 , ...,  0.20843694,\n",
      "        -0.21118166, -0.1457018 ]], shape=(64, 32), dtype=float32), array([[ 0.44068897,  0.7504397 ,  0.60328096, -0.20553319, -0.52980113,\n",
      "         0.20803757,  0.16459982,  0.18084496, -0.9729898 , -0.2555791 ],\n",
      "       [ 0.9135727 , -0.8763912 , -0.03708204, -0.24004951,  0.1450179 ,\n",
      "         0.01574939,  0.558771  , -0.48409918, -0.07083689, -0.39966422],\n",
      "       [ 1.231114  , -1.4103545 , -0.29576516, -0.16487229,  0.550018  ,\n",
      "         1.1181141 ,  0.717342  ,  0.09635694, -0.8507204 , -0.41514727],\n",
      "       [ 0.22846015,  0.15503888,  1.1816963 ,  0.79572505, -1.1615727 ,\n",
      "         0.51362574, -0.4067577 , -1.3467234 ,  0.8817274 , -1.3551202 ],\n",
      "       [-0.07072261,  0.25414675,  0.08506785,  0.45612356, -0.33681667,\n",
      "         0.30689788, -0.52118903,  0.7709099 ,  0.04602538, -0.22989051],\n",
      "       [ 0.8781735 , -0.9254346 ,  0.1622693 ,  1.041579  , -1.1673183 ,\n",
      "         0.628337  , -0.57919014,  0.17580706,  0.6533787 ,  0.22556353],\n",
      "       [-0.8663392 ,  0.52329177, -0.6149236 ,  0.12778291,  0.38315648,\n",
      "         0.58173424, -1.322798  ,  0.6972468 ,  0.8686927 ,  0.73051876],\n",
      "       [ 0.12825674, -0.8135549 , -0.10613614, -0.8138618 ,  0.33364326,\n",
      "         0.24431723, -0.11771678, -0.49579272,  0.34432727, -0.42956477],\n",
      "       [ 0.9972848 , -0.98167336, -1.1709231 ,  0.8725745 , -0.6662932 ,\n",
      "         0.1891116 , -1.1499401 ,  1.2709564 ,  0.22673726,  0.8746785 ],\n",
      "       [ 0.36825442, -0.31083673,  0.1807503 ,  0.47149044, -0.8203316 ,\n",
      "         0.2503475 ,  0.66735864, -0.60979825,  0.14025538, -0.22120827],\n",
      "       [-0.03122089,  0.04491156,  0.38954732, -1.0834    ,  0.63367146,\n",
      "        -0.8659026 ,  0.6464671 , -0.4661007 ,  0.0268925 ,  0.6529368 ],\n",
      "       [-0.71030676,  0.23779082,  0.15741012, -0.30408356, -0.30484805,\n",
      "         0.5476781 , -0.3970161 , -0.17006648,  0.12286539, -0.27597973],\n",
      "       [-0.46207845,  0.46317515, -0.20426567, -0.42268994,  0.86058176,\n",
      "        -0.7639961 ,  0.678859  ,  0.48790866, -1.0600759 ,  0.7885886 ],\n",
      "       [-1.0978291 ,  0.29841623, -0.7649255 ,  1.095653  ,  0.15532753,\n",
      "         0.14828432, -1.3692505 ,  0.74463964, -0.38786858,  0.6655469 ],\n",
      "       [ 0.29067045, -0.5142096 ,  0.10399384,  1.2818666 , -0.52580786,\n",
      "         0.9935456 , -0.50837934, -0.1824432 , -0.01592355, -0.49232978],\n",
      "       [-1.8196719 ,  0.27813426,  0.65738314,  0.14452425,  0.6203521 ,\n",
      "        -0.9597046 ,  0.59246147, -1.1881417 ,  0.667658  ,  0.3121105 ],\n",
      "       [ 0.61131746, -0.14684466, -0.686126  , -0.5095826 ,  0.35012302,\n",
      "        -0.11148766,  0.29837257,  0.11851045, -0.6282855 ,  0.5466973 ],\n",
      "       [-0.92925596,  0.03730316, -0.00713646, -1.0544114 ,  0.58070904,\n",
      "         0.19733569,  0.03066563, -0.02604593,  0.5326009 ,  0.47128242],\n",
      "       [ 0.81821626,  0.26672062,  0.7158312 ,  0.03563547, -0.72322816,\n",
      "         0.2924666 ,  1.1181381 , -0.5286495 , -0.3467081 , -0.80194956],\n",
      "       [-0.3212255 ,  0.17416137, -0.12744972, -0.2544776 ,  0.9570772 ,\n",
      "        -0.47519815, -0.12023493,  0.64184153, -0.07816062,  0.4295762 ],\n",
      "       [ 0.42778546, -1.0953197 , -0.7356991 , -0.28779873,  0.40544888,\n",
      "         0.6325287 , -0.06065338, -0.38818356,  0.23350516,  0.6927378 ],\n",
      "       [-1.0312185 ,  0.9734298 ,  0.97252   ,  0.6102258 , -0.06575517,\n",
      "         0.27302268, -0.4900247 , -0.67514056,  0.00489785, -0.6729838 ],\n",
      "       [-0.10747834,  0.53235155, -0.5960299 ,  0.5214168 , -0.6184421 ,\n",
      "        -1.116724  , -0.4898295 ,  1.5179393 , -0.00771392, -0.05225243],\n",
      "       [-0.57656795,  0.9520823 , -0.37563854, -0.775421  ,  0.05605666,\n",
      "        -0.13965149, -0.6349765 ,  0.49392882,  0.5684347 ,  0.36554435],\n",
      "       [-0.7547475 ,  1.0874168 , -0.5475566 , -0.53619254, -0.13698648,\n",
      "        -0.28428254, -0.61630005,  0.872242  , -0.47252724,  0.3498228 ],\n",
      "       [ 1.4934214 , -1.0768563 , -0.580618  , -1.2015672 ,  0.7989026 ,\n",
      "        -0.16168833,  1.0494276 , -0.16068408, -0.7422746 ,  0.721713  ],\n",
      "       [-0.03880053, -0.83016926,  0.92095095, -0.9412295 ,  0.47844467,\n",
      "        -0.40257382,  0.7093605 , -0.24333549,  0.37682012, -0.05656488],\n",
      "       [-0.22629367,  0.07848475, -0.33843562,  0.46660078, -0.03532567,\n",
      "         0.0472539 ,  0.23380823, -0.15230545, -0.16094673,  0.35616127],\n",
      "       [ 0.29093224, -0.47210944,  0.6320276 , -0.7538139 ,  0.52628773,\n",
      "        -0.10722246,  0.42895412, -1.23293   ,  0.21904556, -0.8275297 ],\n",
      "       [-0.29654318, -0.2293266 ,  0.4751796 , -0.19051173,  0.22112212,\n",
      "        -0.30257645,  0.5759271 , -0.27329457,  0.5178081 , -0.24442299],\n",
      "       [-0.8147864 ,  1.355181  ,  0.69839025,  0.8115052 , -0.97982633,\n",
      "        -0.7099024 , -1.4698318 ,  0.08154647,  0.676804  , -0.5304636 ],\n",
      "       [-0.9805764 ,  0.5239698 , -0.01462435,  0.77176774, -0.7736297 ,\n",
      "        -0.31195343,  0.2511441 ,  0.5058844 , -0.39442846, -0.1742341 ]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[ 0.04058428, -0.05959126,  0.05615465, -0.04372266, -0.10319418,\n",
      "        -0.03688088,  0.03770249,  0.04627939, -0.01931208,  0.01894381,\n",
      "        -0.04979937,  0.03507194, -0.06303024,  0.04787597, -0.06874714,\n",
      "        -0.01206856,  0.01169742, -0.08226725, -0.0907482 ,  0.00383325,\n",
      "         0.02910713, -0.08036444,  0.08999767, -0.13258144, -0.09125933,\n",
      "        -0.05224153, -0.01147121, -0.09559492,  0.00419745,  0.00298377,\n",
      "         0.00789816,  0.07987945,  0.01413286, -0.03205603, -0.07514527,\n",
      "        -0.10781076, -0.03154015,  0.06029737,  0.0418966 , -0.03453885,\n",
      "        -0.00308995, -0.05552378,  0.01892113, -0.02036132, -0.01376833,\n",
      "         0.04174047, -0.06112448, -0.09329635,  0.03383562,  0.00277317,\n",
      "         0.07283816, -0.1212465 , -0.02450467, -0.06835894, -0.0417432 ,\n",
      "         0.07900771, -0.04983295,  0.07021484,  0.08509943, -0.06765082,\n",
      "         0.00788253,  0.02212991,  0.11949941, -0.06218071, -0.03651458,\n",
      "        -0.11345983, -0.07027811,  0.0506628 , -0.0481562 , -0.00695932,\n",
      "        -0.02651684,  0.00569781,  0.06580027, -0.00180536,  0.04876675,\n",
      "         0.07207764,  0.04187692, -0.05972267,  0.02162155, -0.02778659,\n",
      "         0.05066434,  0.08713356,  0.00943678,  0.05294763,  0.10562757,\n",
      "         0.07009827,  0.01553143, -0.01637007, -0.05502265,  0.03061707,\n",
      "         0.0256008 ,  0.07788666,  0.02739774,  0.08427392,  0.09250576,\n",
      "         0.05655502,  0.02027886, -0.01057617, -0.11910563, -0.0199238 ,\n",
      "         0.01484747,  0.00435319,  0.03348787, -0.03542525, -0.01331402,\n",
      "        -0.02860322,  0.03405799,  0.00706719,  0.07632858,  0.01027681,\n",
      "        -0.05263587, -0.07983284,  0.00548712,  0.07815191,  0.06431784,\n",
      "         0.01081916, -0.00275262, -0.01466292, -0.10319365,  0.00513194,\n",
      "        -0.03903162, -0.03712451,  0.02612662,  0.01325016,  0.03957788,\n",
      "        -0.01402753, -0.10084793,  0.00890958]], dtype=float32), array([[ 0.10977562, -0.10059825, -0.03895596,  0.04046101, -0.04253785,\n",
      "         0.14515342, -0.00677054, -0.03448072, -0.11961761, -0.1340079 ,\n",
      "        -0.0305398 , -0.09892491,  0.1056229 , -0.03983798,  0.07009868,\n",
      "         0.073214  ,  0.04746941, -0.05055331,  0.07805356,  0.06737485,\n",
      "        -0.09602978, -0.04973135,  0.18773353, -0.03166308, -0.00662238,\n",
      "        -0.0894141 ,  0.03411357, -0.00758041, -0.05675074, -0.10253976,\n",
      "         0.04246086, -0.13155414,  0.03742223,  0.12547469,  0.05635587,\n",
      "        -0.04331913,  0.05100152,  0.06509498, -0.14055938, -0.04501258,\n",
      "         0.11420023,  0.05489391,  0.13914095,  0.07806937, -0.08761609,\n",
      "         0.02616668, -0.12572108,  0.06245976,  0.05212777, -0.07099097,\n",
      "         0.1336499 , -0.01174189,  0.07167164,  0.0995509 , -0.06858407,\n",
      "        -0.11823583, -0.01343048,  0.04971242,  0.10273463, -0.06712173,\n",
      "         0.09557636, -0.02384843,  0.09144088, -0.08973415]],\n",
      "      dtype=float32), array([[-0.11203037, -0.00990381,  0.25000167,  0.19183601,  0.06491791,\n",
      "        -0.06356157,  0.22555819, -0.0491084 ,  0.1216956 , -0.0609506 ,\n",
      "         0.17492011,  0.10787679, -0.02868337,  0.3154059 ,  0.07841749,\n",
      "         0.01866751, -0.07696201, -0.32550976, -0.10343156, -0.14900771,\n",
      "         0.11055017, -0.05263044, -0.17653042,  0.09484214,  0.08285122,\n",
      "         0.02576354,  0.0371652 ,  0.16638045, -0.21915714,  0.2621965 ,\n",
      "         0.16445938, -0.08115402]], dtype=float32), array([[-0.053307  , -0.24939881, -0.2411006 , -0.25490794,  0.03052438,\n",
      "         0.5084044 , -0.10286677,  0.25629953,  0.11525578, -0.41944686]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 9 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[2.45589792e-04 3.49770044e-03 3.09234336e-02 ... 1.26777601e-03\n",
      "  8.70947659e-01 3.64504033e-03]\n",
      " [6.02543878e-04 5.60475281e-04 2.46264710e-04 ... 2.22281106e-02\n",
      "  6.86764624e-03 5.20308554e-01]\n",
      " [1.66749805e-01 1.53540692e-04 1.02185784e-02 ... 5.85482642e-03\n",
      "  1.38419151e-01 8.22095051e-02]\n",
      " ...\n",
      " [1.85168377e-04 7.47121647e-02 7.23175526e-01 ... 4.37574985e-04\n",
      "  1.61829218e-01 6.72446273e-04]\n",
      " [4.00376390e-04 2.60434113e-03 2.19039539e-05 ... 8.03809464e-01\n",
      "  1.72874460e-03 1.79571062e-01]\n",
      " [1.15448142e-06 9.53269303e-01 6.62106555e-03 ... 1.93188544e-02\n",
      "  7.92974140e-03 4.47712233e-03]]\n",
      "Loss:\n",
      " [2.2816866146684904, 2.204228546851591, 2.0313438041046856, 1.7418863693941153, 1.4218034558095285, 1.1596992749773443, 0.9755971183511574, 0.8540421438973712, 0.7683037422146973, 0.6995648250773232, 0.6397848385063775, 0.5877439518650506, 0.5437873699498303, 0.5069934765773257, 0.47578481317079807]\n",
      "Accuracy:\n",
      " 0.8744285714285714\n",
      "\n",
      "Testing weight configuration: xavier_uniform\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[-0.03305275,  0.0501374 , -0.02429225, ...,  0.02820321,\n",
      "        -0.0742396 , -0.02735013],\n",
      "       [-0.01061948,  0.06305447, -0.01122776, ...,  0.07354817,\n",
      "         0.03294739,  0.04075682],\n",
      "       [-0.04899646, -0.07805746, -0.01479703, ...,  0.03194785,\n",
      "        -0.07691698, -0.03161498],\n",
      "       ...,\n",
      "       [ 0.01327801,  0.03140747, -0.01201645, ...,  0.03190882,\n",
      "        -0.06375924, -0.0512519 ],\n",
      "       [-0.07493388,  0.02775719, -0.07658998, ..., -0.0685322 ,\n",
      "        -0.05535953, -0.06647736],\n",
      "       [ 0.04121297, -0.07026012, -0.06708209, ..., -0.05890622,\n",
      "        -0.01295747, -0.0397816 ]], shape=(784, 128), dtype=float32), array([[-0.16108638,  0.11088486, -0.08732931, ..., -0.10940836,\n",
      "        -0.16863613,  0.04475697],\n",
      "       [-0.10655603, -0.0336724 ,  0.17811874, ..., -0.06555838,\n",
      "         0.18965237,  0.06204841],\n",
      "       [ 0.13995329, -0.05319922, -0.02770126, ..., -0.1684502 ,\n",
      "        -0.20545685, -0.00152359],\n",
      "       ...,\n",
      "       [ 0.19415902,  0.23765686,  0.03534828, ...,  0.157133  ,\n",
      "        -0.02693849, -0.01725008],\n",
      "       [-0.05555839, -0.20332897, -0.1155934 , ...,  0.04616054,\n",
      "        -0.18606652,  0.13806896],\n",
      "       [-0.10647608,  0.32366672, -0.12172271, ..., -0.05523483,\n",
      "        -0.00052215, -0.15717447]], shape=(128, 64), dtype=float32), array([[-0.3578629 , -0.05608175, -0.32410836, ..., -0.2019216 ,\n",
      "         0.4531497 , -0.09238669],\n",
      "       [ 0.27437276,  0.07036249,  0.218445  , ...,  0.13331407,\n",
      "        -0.07331847,  0.12590529],\n",
      "       [ 0.2419152 , -0.08189201,  0.10245015, ..., -0.15054885,\n",
      "         0.28245082, -0.29724798],\n",
      "       ...,\n",
      "       [ 0.06405598, -0.10332207, -0.16509613, ..., -0.15810837,\n",
      "        -0.02440268, -0.32751438],\n",
      "       [ 0.10462105,  0.46412584,  0.30716026, ...,  0.25017715,\n",
      "        -0.13026217,  0.4446061 ],\n",
      "       [ 0.08903575,  0.24756126,  0.01386613, ...,  0.21222301,\n",
      "         0.3971685 ,  0.30438444]], shape=(64, 32), dtype=float32), array([[-1.2771171 ,  0.74715817,  0.00216311,  0.27981454,  0.39397776,\n",
      "        -0.03263016, -0.4030912 , -0.39339644,  0.9559175 ,  0.14932312],\n",
      "       [-1.3213112 ,  1.0898689 ,  0.19409467,  0.75187397, -0.87480503,\n",
      "         0.13865314, -0.447073  , -0.31486547,  0.48626176, -0.70056474],\n",
      "       [-0.5927612 ,  0.95421773, -0.14937575,  0.54320014, -0.11501703,\n",
      "        -0.12091108, -0.57192844, -0.1061467 ,  0.47675887,  0.55501246],\n",
      "       [ 0.0496618 , -0.9626105 , -0.51140636,  0.37564358,  0.33601442,\n",
      "         0.4798262 ,  0.3700879 ,  0.01746837, -0.4026859 ,  0.6756139 ],\n",
      "       [ 0.36227039,  0.10130628,  0.7407505 ,  0.34927273, -0.87874377,\n",
      "         0.69910127, -0.534452  , -0.8127246 ,  1.133246  , -0.7363724 ],\n",
      "       [-0.6735303 ,  0.9242852 ,  0.27044836, -0.5755304 ,  0.64892036,\n",
      "        -0.6953124 ,  1.0964139 , -0.9721802 , -0.5480895 , -0.09403253],\n",
      "       [-1.2002959 ,  0.7588271 , -0.6660694 , -0.5669226 ,  0.872997  ,\n",
      "        -0.04961132, -0.46730313,  0.5101646 ,  0.9018494 ,  0.9157119 ],\n",
      "       [ 0.44919324,  0.42115512,  0.10413943,  0.29260227, -0.5463332 ,\n",
      "        -0.23826332,  0.54771006, -0.20445764, -0.48363686, -0.28375053],\n",
      "       [ 0.6353526 , -0.7045333 , -0.6142669 , -0.5318505 , -0.42678165,\n",
      "         0.1900541 ,  0.12175529,  0.06886774, -0.5977753 , -0.2623609 ],\n",
      "       [-0.35232645,  1.1713833 ,  0.00279506,  0.9189158 , -0.08181642,\n",
      "        -0.29902366, -0.52572095,  1.094447  , -0.58156383,  0.7747379 ],\n",
      "       [ 0.39885706, -0.8126035 , -0.44860038, -1.3188015 ,  1.292731  ,\n",
      "         0.08531752,  1.2223138 , -0.5152905 , -0.3007724 ,  0.06968957],\n",
      "       [-0.71866894,  0.9465501 ,  0.6514897 , -0.4294167 ,  0.25196102,\n",
      "        -0.78917366,  0.7061774 , -0.6363932 ,  0.08848783, -0.32969335],\n",
      "       [ 0.42185226, -1.1366683 , -0.86775875, -0.6999158 , -0.14795715,\n",
      "         1.0563254 ,  0.2490594 , -0.16513702,  0.63392186,  0.57525676],\n",
      "       [ 0.86785054, -0.6593516 ,  0.33306408,  0.2945587 , -0.10997707,\n",
      "        -0.44575083,  0.6109238 ,  0.5148441 , -0.21081048, -0.86521447],\n",
      "       [-0.9606621 ,  0.5527478 , -0.11805528, -0.31969664,  0.48047134,\n",
      "        -0.24658565, -0.48144484,  0.8998867 , -0.10816585,  0.7447266 ],\n",
      "       [ 0.20955618, -0.21683057, -0.01304165, -0.8806253 ,  0.61278933,\n",
      "         0.08002417,  1.1011027 , -0.828649  , -0.39608896, -0.04390587],\n",
      "       [ 0.62964845, -0.78791237,  0.917418  ,  0.2922475 , -0.335659  ,\n",
      "         0.6569045 ,  0.663492  , -0.6639939 , -0.313051  , -0.4663912 ],\n",
      "       [ 0.8058041 , -0.9122816 ,  0.5864278 ,  0.7241587 , -0.8100431 ,\n",
      "         0.00473392,  0.59196484, -0.25932878, -0.5820983 , -0.76818097],\n",
      "       [-0.27963728, -0.32116017,  0.305904  ,  0.12375633,  0.1503217 ,\n",
      "        -1.011408  ,  0.4357424 ,  1.0368195 , -1.1877853 ,  0.40057477],\n",
      "       [ 0.97524583, -1.281261  , -0.51997924,  0.34813204, -0.49839458,\n",
      "         0.55677533, -0.75516576,  0.65365833, -0.3600637 ,  0.4219398 ],\n",
      "       [ 0.8786348 , -0.5360447 , -0.85851866,  0.5472593 , -0.31482273,\n",
      "         0.3914187 , -0.75781465,  0.6550589 , -0.06128835,  0.4864092 ],\n",
      "       [-0.00757159, -0.08341095, -0.24633406,  0.6602959 , -0.7591028 ,\n",
      "         0.26435372, -0.6470674 ,  0.6906319 , -0.6465257 ,  0.61194706],\n",
      "       [-1.4482603 ,  0.70272684,  0.5666082 ,  0.0378611 ,  0.45375806,\n",
      "         0.41366744,  0.04467551, -1.1227796 ,  0.91191274, -0.48140576],\n",
      "       [ 0.7628376 , -0.36796886, -1.1461465 , -0.77670646,  0.51391864,\n",
      "         0.7527219 , -0.7426548 ,  0.29657793,  0.14089803,  0.5261878 ],\n",
      "       [ 1.001603  , -0.98601645,  0.64865786,  0.9119208 , -1.0566971 ,\n",
      "         0.6488007 , -0.35347098,  0.21922693, -0.10946783, -1.0908995 ],\n",
      "       [ 0.20443387, -0.9595407 , -0.346665  , -0.18649684,  0.84355736,\n",
      "        -0.11402024, -0.54026455,  0.6290032 , -0.116471  ,  0.92386645],\n",
      "       [-0.03774749,  0.13554257,  0.5852078 , -0.3980202 ,  0.68997353,\n",
      "        -0.7868895 , -0.3186299 ,  0.25117597, -0.51758593,  0.35415238],\n",
      "       [-0.18439628, -0.31686726,  0.0730679 , -0.55400705,  0.49344423,\n",
      "        -0.3403195 ,  0.3232398 , -0.48042414, -0.19958073,  0.53340715],\n",
      "       [-0.85935354, -0.10980574, -1.3602672 , -0.16940702,  0.45348573,\n",
      "         0.42721757, -0.79250926,  0.7277316 ,  0.86937296,  0.62377816],\n",
      "       [ 0.18264078, -0.25716633, -0.08928761,  0.9792527 , -0.1724866 ,\n",
      "         0.0768943 , -0.4954222 ,  0.13661464,  0.10747512,  0.03978502],\n",
      "       [ 0.28179672,  0.08019356,  0.7452948 ,  0.03203232, -0.7008861 ,\n",
      "         0.07503424,  0.28619906, -1.2571038 ,  0.80049515, -0.76590616],\n",
      "       [-0.47987124,  0.8250218 ,  1.0881696 ,  0.33312687, -0.7300631 ,\n",
      "        -0.04863995, -0.8414895 ,  0.31770587,  0.35680687, -0.64395094]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[-2.51495801e-02,  6.37657121e-02,  5.84896356e-02,\n",
      "         1.03398860e-01, -1.64071321e-02, -8.93265605e-02,\n",
      "        -2.55698878e-02, -1.58982277e-02,  4.01567947e-03,\n",
      "         1.37881003e-03,  1.12671441e-04, -5.86522259e-02,\n",
      "        -3.64108719e-02, -5.73935024e-02, -1.41300848e-02,\n",
      "        -1.04156621e-01, -1.32694775e-02, -8.61781929e-03,\n",
      "         3.81368510e-02,  4.89212796e-02,  1.47061562e-02,\n",
      "         7.16535002e-02,  5.94471619e-02,  3.63177620e-02,\n",
      "        -5.31596430e-02, -7.24233091e-02,  6.73298612e-02,\n",
      "         4.56308648e-02, -1.65107306e-02, -7.96990097e-02,\n",
      "        -4.46336949e-03, -9.67364535e-02,  2.43504550e-02,\n",
      "         4.03915979e-02,  5.66375665e-02,  8.69855434e-02,\n",
      "        -5.02082817e-02,  1.47002935e-02,  3.64998094e-04,\n",
      "        -9.15590227e-02,  6.90775514e-02, -7.03518614e-02,\n",
      "         4.63539399e-02, -1.08326422e-02, -1.57023016e-02,\n",
      "        -6.81358799e-02,  2.36649420e-02, -3.99074517e-02,\n",
      "        -7.62772188e-02, -5.88746741e-02,  6.11486398e-02,\n",
      "        -1.85725652e-02,  9.16562602e-02, -1.22841205e-02,\n",
      "         9.62118804e-02, -8.42782855e-02, -6.56637251e-02,\n",
      "         4.85832952e-02, -4.64519411e-02,  3.65834199e-02,\n",
      "         4.76070493e-02, -6.16627894e-02, -8.00151378e-02,\n",
      "         2.92712711e-02, -8.61103535e-02,  4.13741805e-02,\n",
      "        -4.64611873e-02,  1.56369768e-02,  6.50763437e-02,\n",
      "         4.49370816e-02,  6.91020712e-02, -7.31137916e-02,\n",
      "        -5.51150143e-02,  7.58655742e-03,  2.12985724e-02,\n",
      "         7.09635764e-03,  1.57649264e-01,  4.65520658e-02,\n",
      "         2.70156171e-02, -2.94742528e-02,  7.31868222e-02,\n",
      "        -4.82811779e-02,  6.83552623e-02,  3.85259502e-02,\n",
      "         3.21645960e-02,  2.62238588e-02, -1.97626650e-02,\n",
      "         1.81295518e-02, -6.82797432e-02,  3.39409932e-02,\n",
      "        -9.45664197e-02,  4.86131795e-02, -3.41389701e-02,\n",
      "         4.33979370e-03,  2.71080956e-02,  6.54034615e-02,\n",
      "        -3.43221240e-03,  4.48703859e-03,  3.46590094e-02,\n",
      "         6.51647225e-02,  1.36723202e-02, -4.60467450e-02,\n",
      "        -9.67065245e-02, -9.79994051e-03,  4.71126772e-02,\n",
      "         4.09032218e-02, -8.77340212e-02, -4.32009436e-02,\n",
      "        -4.35286341e-03,  3.56321856e-02,  3.33303772e-02,\n",
      "         3.63912694e-02, -2.47982554e-02, -5.53068370e-02,\n",
      "        -9.58827604e-03, -5.75947389e-02, -1.44548304e-02,\n",
      "        -1.71671566e-02, -4.44838479e-02, -2.59642005e-02,\n",
      "         7.83950239e-02, -1.27097219e-02,  4.19598483e-02,\n",
      "        -8.76911581e-02, -3.03271003e-02,  1.14737991e-02,\n",
      "         1.98460668e-02,  5.39230891e-02]], dtype=float32), array([[ 0.02996616,  0.1140809 ,  0.0859449 , -0.06368142,  0.19569018,\n",
      "         0.17918567, -0.0431593 , -0.03714484,  0.1196188 ,  0.11582213,\n",
      "         0.1392588 ,  0.13121517, -0.12788785,  0.11550234, -0.06663743,\n",
      "         0.04133248,  0.10284153, -0.08205435,  0.02361719,  0.06898291,\n",
      "         0.13621551,  0.00204964,  0.04016384, -0.16239356, -0.00450473,\n",
      "        -0.10174637,  0.15384255, -0.166144  ,  0.00727203,  0.07168524,\n",
      "         0.10805085,  0.03613793, -0.12213984,  0.04559805, -0.06933759,\n",
      "        -0.10702375,  0.1496048 ,  0.16402194,  0.06584214,  0.06852117,\n",
      "        -0.06279323,  0.1398318 , -0.08132307,  0.06609343,  0.04587069,\n",
      "        -0.11978332,  0.02885587,  0.0490997 , -0.130519  , -0.09888161,\n",
      "         0.01690587, -0.02125611, -0.04173336, -0.143584  ,  0.06171137,\n",
      "        -0.01741139,  0.14971375,  0.15121129,  0.0095274 , -0.18658678,\n",
      "        -0.12372153,  0.05915864, -0.04465923,  0.00655201]],\n",
      "      dtype=float32), array([[ 0.25502163, -0.19428459,  0.02586756, -0.1502924 , -0.17849003,\n",
      "        -0.0848363 ,  0.0778001 ,  0.18501197, -0.07805233,  0.3051115 ,\n",
      "        -0.01552835, -0.04939774,  0.19002867, -0.04980067, -0.1482279 ,\n",
      "        -0.2685981 ,  0.12644792,  0.00936641,  0.08710861,  0.16139825,\n",
      "        -0.11526969, -0.06005019, -0.10226906,  0.17666784,  0.05053332,\n",
      "        -0.08197922,  0.0162059 , -0.17514376,  0.19326995, -0.15420999,\n",
      "        -0.09526376,  0.12761968]], dtype=float32), array([[-0.15948239,  0.05598256,  0.26822683, -0.32095504,  0.03054322,\n",
      "        -0.05253133,  0.25668934,  0.318527  ,  0.34126484, -0.42988595]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[2.05162389e-04 5.65812550e-03 3.10809235e-03 ... 7.16894458e-04\n",
      "  8.45144868e-01 1.89980946e-03]\n",
      " [6.47461711e-05 1.06071169e-03 6.28058042e-05 ... 1.37113938e-02\n",
      "  4.68973443e-03 4.85600471e-01]\n",
      " [9.71030258e-03 9.91755980e-04 3.93247558e-03 ... 2.01065629e-03\n",
      "  3.44456345e-01 2.45236885e-02]\n",
      " ...\n",
      " [1.61197269e-04 1.76960140e-01 6.14786088e-01 ... 2.23041905e-04\n",
      "  1.43725574e-01 1.98956026e-04]\n",
      " [2.14106776e-03 5.19962996e-05 2.89993695e-05 ... 7.34556139e-01\n",
      "  6.97222480e-04 2.45685086e-01]\n",
      " [1.03766001e-06 9.51510608e-01 1.24992505e-02 ... 2.63420283e-03\n",
      "  1.88938901e-02 4.05747723e-03]]\n",
      "Loss:\n",
      " [2.2862192739150093, 2.2164303288385714, 2.057585554426415, 1.733338089501207, 1.4080616986371717, 1.16406347942843, 0.9727951580479592, 0.829155436245229, 0.7225167716470575, 0.6440189325361223, 0.5868240115286684, 0.5442991545385412, 0.5112248335771531, 0.48428795970384836, 0.46151189940541276]\n",
      "Accuracy:\n",
      " 0.8765714285714286\n",
      "\n",
      "Testing weight configuration: he_normal\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [array([[ 0.03999778,  0.02337201,  0.01654856, ..., -0.01264654,\n",
      "         0.0983605 , -0.02349178],\n",
      "       [ 0.05033609,  0.01088684,  0.003892  , ..., -0.00903939,\n",
      "         0.00353545, -0.09144268],\n",
      "       [-0.02355272,  0.01691791, -0.09525234, ..., -0.0058352 ,\n",
      "        -0.05669824,  0.02044719],\n",
      "       ...,\n",
      "       [-0.07271917, -0.03981327,  0.02967357, ..., -0.05524292,\n",
      "        -0.02441269, -0.01670509],\n",
      "       [ 0.05893589, -0.07948083,  0.02707416, ...,  0.04926933,\n",
      "         0.04542422, -0.03835095],\n",
      "       [ 0.03307312, -0.02775579, -0.07754339, ..., -0.04828853,\n",
      "        -0.02938198, -0.0363628 ]], shape=(784, 128), dtype=float32), array([[ 0.08942035,  0.13168676,  0.10267941, ...,  0.16195412,\n",
      "        -0.23958616,  0.10902213],\n",
      "       [-0.12479687, -0.00569725,  0.10673644, ..., -0.08415622,\n",
      "        -0.14352779,  0.27333504],\n",
      "       [-0.36243618,  0.09824809, -0.01299943, ...,  0.10597096,\n",
      "         0.02758318,  0.10509517],\n",
      "       ...,\n",
      "       [ 0.03119531, -0.14656597, -0.1342655 , ..., -0.01835732,\n",
      "         0.1177301 , -0.10683046],\n",
      "       [-0.2987112 , -0.128049  ,  0.08366878, ..., -0.29024383,\n",
      "         0.11753923,  0.07098035],\n",
      "       [ 0.07543119,  0.11066535,  0.16460255, ...,  0.11736403,\n",
      "         0.03305198,  0.12982787]], shape=(128, 64), dtype=float32), array([[ 0.06953664, -0.0359631 ,  0.19297774, ..., -0.04658463,\n",
      "        -0.23807827,  0.25203192],\n",
      "       [ 0.04551322,  0.15027277,  0.54087025, ...,  0.02746398,\n",
      "        -0.16283953,  0.07281642],\n",
      "       [-0.03314213,  0.17944941,  0.1633175 , ..., -0.18094578,\n",
      "        -0.289557  , -0.2079946 ],\n",
      "       ...,\n",
      "       [-0.05308162, -0.01345998,  0.14028496, ...,  0.08127322,\n",
      "        -0.50613356, -0.15033278],\n",
      "       [ 0.4177879 , -0.15575965,  0.04856715, ...,  0.0530991 ,\n",
      "         0.6621003 , -0.1694707 ],\n",
      "       [-0.23209007,  0.0469556 ,  0.46762708, ...,  0.20184368,\n",
      "        -0.21558346, -0.12161364]], shape=(64, 32), dtype=float32), array([[ 5.24898887e-01,  8.95770848e-01,  7.10656881e-01,\n",
      "        -2.49458894e-01, -6.84279323e-01,  2.33758897e-01,\n",
      "         1.08968467e-01,  2.83142954e-01, -1.04844022e+00,\n",
      "        -3.35106045e-01],\n",
      "       [ 8.55818033e-01, -8.75442743e-01, -3.24432664e-02,\n",
      "        -1.68886259e-01,  1.92320362e-01, -1.21215358e-01,\n",
      "         4.58630770e-01, -4.02746558e-01, -3.37594151e-02,\n",
      "        -4.16471303e-01],\n",
      "       [ 1.25693619e+00, -1.38796604e+00, -2.00890839e-01,\n",
      "        -9.11312997e-02,  6.25624120e-01,  1.12391675e+00,\n",
      "         7.13441908e-01,  2.90031105e-01, -9.92747724e-01,\n",
      "        -6.77226126e-01],\n",
      "       [ 2.23526984e-01,  7.71406442e-02,  1.28953779e+00,\n",
      "         7.82633960e-01, -1.08246922e+00,  5.00894904e-01,\n",
      "        -5.58205187e-01, -1.38616860e+00,  9.52772021e-01,\n",
      "        -1.38839138e+00],\n",
      "       [-2.11762432e-02,  1.98062152e-01,  1.46290869e-01,\n",
      "         3.52767915e-01, -2.42065355e-01,  3.51912051e-01,\n",
      "        -4.54706907e-01,  8.47077489e-01, -5.74550452e-03,\n",
      "        -3.01094562e-01],\n",
      "       [ 8.65554094e-01, -9.74058986e-01,  2.30626822e-01,\n",
      "         1.04416716e+00, -1.30819285e+00,  5.64556122e-01,\n",
      "        -6.26367986e-01,  2.10732847e-01,  6.97734177e-01,\n",
      "         5.47628760e-01],\n",
      "       [-8.52219284e-01,  5.31711340e-01, -8.23104262e-01,\n",
      "         3.45737450e-02,  5.21812439e-01,  7.64645040e-01,\n",
      "        -1.31498861e+00,  6.69474661e-01,  9.52418566e-01,\n",
      "         7.85470188e-01],\n",
      "       [ 1.08031645e-01, -8.03279459e-01, -1.84794486e-01,\n",
      "        -8.76428306e-01,  3.76829654e-01,  2.64259875e-01,\n",
      "        -2.96927691e-01, -4.30933326e-01,  3.71202290e-01,\n",
      "        -5.05437493e-01],\n",
      "       [ 1.07047355e+00, -1.05494952e+00, -1.12854016e+00,\n",
      "         9.45215583e-01, -7.49841332e-01,  1.87370218e-02,\n",
      "        -1.17816758e+00,  1.32562804e+00,  2.64103532e-01,\n",
      "         1.01723003e+00],\n",
      "       [ 3.25765282e-01, -2.52340078e-01,  1.02988191e-01,\n",
      "         4.98854637e-01, -9.66280222e-01,  2.35012114e-01,\n",
      "         7.01357722e-01, -6.26976192e-01,  2.27793336e-01,\n",
      "        -1.12958878e-01],\n",
      "       [ 4.55718711e-02,  8.14472362e-02,  5.29472232e-01,\n",
      "        -1.11920393e+00,  5.54777205e-01, -1.06699729e+00,\n",
      "         5.81128299e-01, -3.74545634e-01,  4.12252322e-02,\n",
      "         6.67321086e-01],\n",
      "       [-6.83727622e-01,  2.15429351e-01,  3.03390604e-02,\n",
      "        -4.73116010e-01, -2.83823967e-01,  7.68307686e-01,\n",
      "        -3.94548655e-01, -1.85666412e-01,  1.25814423e-01,\n",
      "        -3.75273824e-01],\n",
      "       [-4.53858644e-01,  5.56571305e-01, -1.50945053e-01,\n",
      "        -3.71195048e-01,  8.26962292e-01, -8.45695376e-01,\n",
      "         7.55166590e-01,  4.93517131e-01, -1.17593980e+00,\n",
      "         7.84737110e-01],\n",
      "       [-1.13035131e+00,  2.53824383e-01, -7.51977623e-01,\n",
      "         1.23709249e+00,  3.25640172e-01,  7.84089938e-02,\n",
      "        -1.35912490e+00,  7.46891558e-01, -6.58716023e-01,\n",
      "         6.71728373e-01],\n",
      "       [ 1.66437805e-01, -5.45264423e-01,  5.98739609e-02,\n",
      "         1.36211789e+00, -4.33588147e-01,  1.15650022e+00,\n",
      "        -4.67002571e-01, -2.42991403e-01, -9.51642245e-02,\n",
      "        -4.67175364e-01],\n",
      "       [-1.87127411e+00,  1.23182423e-01,  6.38950884e-01,\n",
      "         3.05683821e-01,  6.98586285e-01, -1.12855101e+00,\n",
      "         6.44814372e-01, -1.30088496e+00,  6.35981917e-01,\n",
      "         4.57419991e-01],\n",
      "       [ 6.35784745e-01,  4.25418466e-02, -7.42967010e-01,\n",
      "        -4.81808871e-01,  2.60066569e-01, -1.56274378e-01,\n",
      "         3.06658357e-01,  4.33162674e-02, -7.05012023e-01,\n",
      "         6.17472529e-01],\n",
      "       [-9.06532109e-01, -1.74566116e-02, -9.85658690e-02,\n",
      "        -1.08977437e+00,  6.08425140e-01,  2.86980957e-01,\n",
      "         1.25099365e-02, -5.80698028e-02,  5.84868968e-01,\n",
      "         4.86340612e-01],\n",
      "       [ 8.36509466e-01,  4.88647610e-01,  7.21181035e-01,\n",
      "         3.45594250e-03, -8.32182407e-01,  3.67585212e-01,\n",
      "         1.15521288e+00, -5.45756102e-01, -3.30337256e-01,\n",
      "        -8.94562602e-01],\n",
      "       [-2.79285163e-01,  1.70533717e-01, -2.34322716e-02,\n",
      "        -2.00686693e-01,  1.00019407e+00, -5.40606499e-01,\n",
      "        -6.01140969e-02,  7.12485969e-01, -1.37398168e-01,\n",
      "         3.04504752e-01],\n",
      "       [ 4.02321070e-01, -1.10340106e+00, -8.79243553e-01,\n",
      "        -3.12726796e-01,  5.08094907e-01,  6.76704943e-01,\n",
      "        -1.34286001e-01, -5.24245560e-01,  2.88660020e-01,\n",
      "         8.76890004e-01],\n",
      "       [-1.13523364e+00,  9.13738072e-01,  9.03952360e-01,\n",
      "         5.58681130e-01,  2.16713294e-01,  5.34658492e-01,\n",
      "        -5.06140411e-01, -8.39711964e-01, -2.55299662e-03,\n",
      "        -7.59832263e-01],\n",
      "       [-6.44660555e-04,  5.27468860e-01, -4.64645475e-01,\n",
      "         5.84016979e-01, -7.06856310e-01, -1.34832215e+00,\n",
      "        -4.92751837e-01,  1.65029895e+00,  8.73366185e-03,\n",
      "        -2.34748289e-01],\n",
      "       [-5.09025574e-01,  1.00260890e+00, -4.16407764e-01,\n",
      "        -9.27499473e-01, -7.08057508e-02, -4.80063632e-02,\n",
      "        -5.75387716e-01,  4.52242285e-01,  6.90539002e-01,\n",
      "         3.25889051e-01],\n",
      "       [-7.37760067e-01,  1.11055183e+00, -5.74173927e-01,\n",
      "        -6.05745852e-01, -2.41876259e-01, -2.34890014e-01,\n",
      "        -5.51764011e-01,  8.70746076e-01, -4.90404218e-01,\n",
      "         2.64870465e-01],\n",
      "       [ 1.52367532e+00, -9.91409481e-01, -5.89742661e-01,\n",
      "        -1.20162416e+00,  7.16191471e-01, -2.29865849e-01,\n",
      "         1.10601461e+00, -1.37092561e-01, -7.91008055e-01,\n",
      "         7.54999638e-01],\n",
      "       [-9.39375833e-02, -9.36243594e-01,  1.15662038e+00,\n",
      "        -9.62578058e-01,  4.07130539e-01, -5.37452996e-01,\n",
      "         6.90013528e-01, -2.88277101e-02,  3.97554308e-01,\n",
      "        -1.23316057e-01],\n",
      "       [-9.90684927e-02,  3.93233150e-02, -4.08026904e-01,\n",
      "         4.92310733e-01, -4.73013930e-02,  5.57216331e-02,\n",
      "         2.30948403e-01, -1.73627734e-01, -1.69603527e-01,\n",
      "         3.87503803e-01],\n",
      "       [ 2.33359322e-01, -4.04752791e-01,  5.79451323e-01,\n",
      "        -8.50301385e-01,  6.20109081e-01, -7.37231299e-02,\n",
      "         3.43675941e-01, -1.29415166e+00,  2.50765830e-01,\n",
      "        -8.89587700e-01],\n",
      "       [-2.41231233e-01, -2.43622050e-01,  3.50811929e-01,\n",
      "        -1.20551392e-01,  1.36294410e-01, -3.08457673e-01,\n",
      "         4.61470217e-01, -1.16000503e-01,  5.29006779e-01,\n",
      "        -1.57457307e-01],\n",
      "       [-7.28531957e-01,  1.30106354e+00,  8.05784881e-01,\n",
      "         7.41943181e-01, -1.07053113e+00, -8.24611545e-01,\n",
      "        -1.62847507e+00,  8.21296349e-02,  7.68307507e-01,\n",
      "        -4.56831962e-01],\n",
      "       [-1.06218207e+00,  4.98118818e-01,  1.12834675e-02,\n",
      "         8.09984267e-01, -9.69440401e-01, -3.10662776e-01,\n",
      "         5.75234592e-01,  5.07300973e-01, -4.61260468e-01,\n",
      "        -2.81955093e-01]], dtype=float32)]\n",
      "Biases:\n",
      " [array([[ 3.42454277e-02, -5.97536564e-02,  5.72330430e-02,\n",
      "        -4.24214415e-02, -1.14384107e-01, -3.89425084e-02,\n",
      "         3.93754281e-02,  5.13672568e-02, -1.79946665e-02,\n",
      "         3.03938109e-02, -4.87077907e-02,  1.50789963e-02,\n",
      "        -8.53966326e-02,  5.74673228e-02, -7.24824294e-02,\n",
      "        -1.51690943e-02,  1.46480454e-02, -9.08525959e-02,\n",
      "        -8.89078379e-02,  5.36589650e-03,  3.17238271e-02,\n",
      "        -8.52057934e-02,  9.52714384e-02, -1.34401187e-01,\n",
      "        -9.55010206e-02, -3.66289057e-02, -1.30098704e-02,\n",
      "        -1.07075743e-01,  9.57189593e-03, -4.97165543e-04,\n",
      "         7.99939688e-03,  1.05996430e-01,  2.38171741e-02,\n",
      "        -3.38059552e-02, -8.36738944e-02, -1.18216403e-01,\n",
      "        -2.96966955e-02,  4.90012690e-02,  5.58546297e-02,\n",
      "        -3.35103832e-02,  2.66241655e-03, -5.12611754e-02,\n",
      "         4.22659470e-03, -1.15609141e-02, -1.83177814e-02,\n",
      "         3.90713029e-02, -6.53471053e-02, -1.06453195e-01,\n",
      "         2.13454235e-02,  7.00191641e-03,  7.61969611e-02,\n",
      "        -1.30111501e-01, -2.33377144e-02, -5.32268025e-02,\n",
      "        -4.95203100e-02,  7.24866092e-02, -4.46273908e-02,\n",
      "         7.46080503e-02,  8.39457437e-02, -8.38240758e-02,\n",
      "         7.90739898e-03,  2.23806761e-02,  1.20845497e-01,\n",
      "        -7.16720596e-02, -3.54884788e-02, -1.13441929e-01,\n",
      "        -6.70017302e-02,  5.74857518e-02, -5.03070429e-02,\n",
      "        -1.96789969e-02, -2.75506619e-02,  5.47152339e-03,\n",
      "         6.32523149e-02, -1.20142540e-05,  4.84268963e-02,\n",
      "         7.83842430e-02,  5.14056385e-02, -7.00636879e-02,\n",
      "         2.72788703e-02, -3.13638225e-02,  5.66673912e-02,\n",
      "         9.62790772e-02,  1.76626276e-02,  5.93034811e-02,\n",
      "         1.11808360e-01,  8.01139325e-02,  1.40731083e-02,\n",
      "        -2.45712139e-02, -5.98560311e-02,  1.37005402e-02,\n",
      "         3.72506380e-02,  8.20040032e-02,  1.95888057e-02,\n",
      "         9.16928500e-02,  9.09088477e-02,  5.09427674e-02,\n",
      "         1.88024957e-02, -2.39951462e-02, -1.21216208e-01,\n",
      "        -2.17078701e-02,  6.48626406e-03,  1.65849645e-02,\n",
      "         3.39413136e-02, -3.46321873e-02, -2.79827099e-02,\n",
      "        -3.00292000e-02,  3.72484587e-02,  5.65555878e-03,\n",
      "         9.55802053e-02,  5.96324168e-03, -6.22397996e-02,\n",
      "        -9.16547552e-02,  3.12763732e-03,  8.97577628e-02,\n",
      "         6.51626959e-02,  6.17769593e-03, -7.55939027e-03,\n",
      "        -2.89000906e-02, -1.09459735e-01,  4.61198762e-03,\n",
      "        -4.85264137e-02, -3.95697057e-02,  3.60540748e-02,\n",
      "         3.20582767e-03,  4.51770462e-02, -2.20606700e-02,\n",
      "        -9.80584398e-02,  1.29677774e-02]], dtype=float32), array([[ 0.13520297, -0.12238141, -0.03979922,  0.03742795, -0.07406916,\n",
      "         0.18054552, -0.02448441, -0.050209  , -0.15027075, -0.1688942 ,\n",
      "        -0.03186073, -0.12831023,  0.13511902, -0.05009673,  0.09260855,\n",
      "         0.08766462,  0.06528986, -0.05544792,  0.07415257,  0.09308293,\n",
      "        -0.1219343 , -0.06462195,  0.22874278, -0.0458066 , -0.00801299,\n",
      "        -0.1070691 ,  0.03760988, -0.0224979 , -0.07893223, -0.1349353 ,\n",
      "         0.05392313, -0.16886795,  0.03566331,  0.14330477,  0.07622212,\n",
      "        -0.0558866 ,  0.06248896,  0.08629891, -0.15463634, -0.06609275,\n",
      "         0.12628022,  0.06661818,  0.17154846,  0.10325362, -0.09314487,\n",
      "         0.03711262, -0.15090013,  0.08250367,  0.07503471, -0.07665719,\n",
      "         0.1598088 , -0.01178694,  0.08449589,  0.13600054, -0.08423971,\n",
      "        -0.13896102, -0.02033662,  0.06505229,  0.12194206, -0.06990432,\n",
      "         0.10625695, -0.02860423,  0.10480437, -0.11441052]],\n",
      "      dtype=float32), array([[-0.14598553,  0.0074638 ,  0.32385632,  0.20827502,  0.06897124,\n",
      "        -0.0817749 ,  0.25350085, -0.05902896,  0.14196827, -0.06459201,\n",
      "         0.21649975,  0.11278933, -0.03113156,  0.3671364 ,  0.09165811,\n",
      "         0.01302627, -0.09739551, -0.4155502 , -0.12061913, -0.17573443,\n",
      "         0.13357125, -0.03055713, -0.20159033,  0.10994052,  0.11531255,\n",
      "         0.04219579,  0.05800896,  0.24148902, -0.2728511 ,  0.3251244 ,\n",
      "         0.2036195 , -0.09997626]], dtype=float32), array([[-0.05929651, -0.25808936, -0.28033063, -0.30328494,  0.05458525,\n",
      "         0.5637992 , -0.11181162,  0.27753788,  0.1274044 , -0.4808451 ]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[2.04359225e-04 1.56837539e-03 2.09420267e-02 ... 4.86798817e-04\n",
      "  9.24772143e-01 2.61786161e-03]\n",
      " [7.30145664e-04 4.98258800e-04 2.88851472e-04 ... 1.34542193e-02\n",
      "  5.25641721e-03 3.73889148e-01]\n",
      " [7.74720162e-02 2.61832378e-04 6.80546788e-03 ... 4.34043258e-03\n",
      "  1.45390898e-01 7.09537044e-02]\n",
      " ...\n",
      " [4.01022262e-04 6.68769255e-02 7.67346501e-01 ... 6.33730087e-04\n",
      "  1.33176178e-01 6.08055503e-04]\n",
      " [7.42298143e-04 2.24412489e-03 2.30516962e-05 ... 8.58935058e-01\n",
      "  1.11903122e-03 1.28960237e-01]\n",
      " [3.86116881e-06 9.53963697e-01 8.57550185e-03 ... 2.03541443e-02\n",
      "  5.64049976e-03 3.90635943e-03]]\n",
      "Loss:\n",
      " [2.250437092471742, 2.0608039473837243, 1.7394582724930427, 1.3818273957116076, 1.0994431443115305, 0.9121667672100506, 0.7857923223062528, 0.6910743290015124, 0.6156802841557569, 0.5553292414661593, 0.5069023901496489, 0.46755334194852555, 0.4351448296691387, 0.40813183091367544, 0.38536025265251067]\n",
      "Accuracy:\n",
      " 0.8972142857142857\n",
      "\n",
      "Testing weight configuration: he_uniform\n",
      "[From Scratch FFNNClassifier]\n",
      "Weights:\n",
      " [array([[-0.03564897,  0.05407558, -0.02620035, ...,  0.0304185 ,\n",
      "        -0.08007096, -0.02949842],\n",
      "       [-0.01145362,  0.06800726, -0.01210968, ...,  0.07932521,\n",
      "         0.03553534,  0.04395818],\n",
      "       [-0.05284502, -0.0841887 , -0.0159593 , ...,  0.03445728,\n",
      "        -0.08295864, -0.03409827],\n",
      "       ...,\n",
      "       [ 0.01432097,  0.03387446, -0.01296032, ...,  0.03441519,\n",
      "        -0.06876738, -0.05527762],\n",
      "       [-0.08081977,  0.02993746, -0.08260595, ..., -0.07391525,\n",
      "        -0.0597079 , -0.07169901],\n",
      "       [ 0.04445016, -0.07577889, -0.07235124, ..., -0.06353316,\n",
      "        -0.01397525, -0.04290636]], shape=(784, 128), dtype=float32), array([[-0.20008859,  0.13011402, -0.11728435, ..., -0.14728734,\n",
      "        -0.20785442,  0.05075847],\n",
      "       [-0.10342662, -0.0788284 ,  0.20636277, ..., -0.0700444 ,\n",
      "         0.21543738,  0.06670509],\n",
      "       [ 0.15744741, -0.03600521, -0.02347739, ..., -0.19545963,\n",
      "        -0.23513258,  0.00287105],\n",
      "       ...,\n",
      "       [ 0.22702378,  0.27237293,  0.06941767, ...,  0.16183504,\n",
      "        -0.04936318, -0.04759612],\n",
      "       [-0.08875653, -0.23243795, -0.13283406, ...,  0.06531017,\n",
      "        -0.22717437,  0.1609179 ],\n",
      "       [-0.11679858,  0.36165404, -0.14856507, ..., -0.08986662,\n",
      "        -0.01600382, -0.18109158]], shape=(128, 64), dtype=float32), array([[-0.3963969 , -0.01325413, -0.3289105 , ..., -0.2384834 ,\n",
      "         0.4880394 , -0.08388603],\n",
      "       [ 0.29993182,  0.08545864,  0.22590663, ...,  0.15274401,\n",
      "        -0.05520472,  0.15873595],\n",
      "       [ 0.22797255, -0.08375859,  0.07888176, ..., -0.10961115,\n",
      "         0.33013833, -0.33701143],\n",
      "       ...,\n",
      "       [ 0.10091014, -0.0731288 , -0.21001942, ..., -0.23054586,\n",
      "        -0.02512578, -0.35904726],\n",
      "       [ 0.07491776,  0.49082085,  0.31291535, ...,  0.27058306,\n",
      "        -0.17055458,  0.45242473],\n",
      "       [ 0.08465689,  0.21525197, -0.01504941, ...,  0.2012172 ,\n",
      "         0.4456138 ,  0.2999094 ]], shape=(64, 32), dtype=float32), array([[-1.26677   ,  0.72819734, -0.05655456,  0.3725622 ,  0.46247348,\n",
      "         0.00266773, -0.40675616, -0.4610743 ,  1.0290042 ,  0.07985142],\n",
      "       [-1.3511021 ,  1.1277906 , -0.00942601,  0.81182843, -0.9531715 ,\n",
      "         0.31562912, -0.38830227, -0.3705964 ,  0.42287657, -0.74874395],\n",
      "       [-0.5308329 ,  1.0129352 , -0.20476197,  0.59666264, -0.11052008,\n",
      "        -0.09239797, -0.54292196, -0.2375492 ,  0.48719114,  0.6224066 ],\n",
      "       [-0.09491615, -0.97668475, -0.58695   ,  0.66551363,  0.3550114 ,\n",
      "         0.57560474,  0.4049006 , -0.2026094 , -0.45162654,  0.80165005],\n",
      "       [ 0.43371007,  0.04571708,  0.7748459 ,  0.26773003, -0.8562126 ,\n",
      "         0.7037356 , -0.5700172 , -0.8425096 ,  1.2468073 , -0.718436  ],\n",
      "       [-0.6943579 ,  0.98651606,  0.11355183, -0.5298692 ,  0.6375935 ,\n",
      "        -0.7275883 ,  1.1549094 , -0.9866162 , -0.61046946, -0.05237174],\n",
      "       [-1.1657616 ,  0.7080437 , -0.63290817, -0.58875346,  0.9322817 ,\n",
      "        -0.04617983, -0.43891528,  0.52616155,  0.9789639 ,  0.883414  ],\n",
      "       [ 0.44657394,  0.6078403 , -0.18931915,  0.31676412, -0.61730677,\n",
      "        -0.14393136,  0.6759599 , -0.22566856, -0.62408197, -0.17997707],\n",
      "       [ 0.55837727, -0.5856212 , -0.6435722 , -0.59793687, -0.5078991 ,\n",
      "         0.17356509,  0.08505344,  0.06062115, -0.63306314, -0.3400554 ],\n",
      "       [-0.304177  ,  1.2916847 ,  0.02118995,  0.983819  , -0.11376529,\n",
      "        -0.24785684, -0.5286072 ,  1.1081121 , -0.6377006 ,  0.85815316],\n",
      "       [ 0.41896737, -0.8416266 , -0.43423128, -1.3533128 ,  1.427061  ,\n",
      "         0.08354644,  1.2671266 , -0.5214125 , -0.31611222, -0.1048199 ],\n",
      "       [-0.7000857 ,  0.9770475 ,  0.6109511 , -0.44642225,  0.20175749,\n",
      "        -0.8875217 ,  0.74933934, -0.6378103 ,  0.11019444, -0.27379894],\n",
      "       [ 0.37856808, -1.1330504 , -0.8980127 , -0.73391896, -0.16321093,\n",
      "         1.1461029 ,  0.31841454, -0.28793463,  0.6775181 ,  0.60270756],\n",
      "       [ 0.878508  , -0.6551549 ,  0.3269612 ,  0.33239368, -0.09941258,\n",
      "        -0.6235321 ,  0.60903615,  0.6794079 , -0.08152404, -0.98847604],\n",
      "       [-0.95009583,  0.4759524 ,  0.04572422, -0.39077398,  0.48548618,\n",
      "        -0.21584894, -0.48956215,  0.9735666 , -0.1567712 ,  0.7300992 ],\n",
      "       [ 0.18648338, -0.15993984, -0.16691244, -0.8624421 ,  0.6110217 ,\n",
      "         0.14909695,  1.190708  , -0.864281  , -0.5061414 , -0.00796155],\n",
      "       [ 0.61616373, -0.79355717,  0.9667988 ,  0.31163815, -0.32508832,\n",
      "         0.71820015,  0.68874973, -0.7405019 , -0.3667607 , -0.39660972],\n",
      "       [ 0.7940731 , -0.8537039 ,  0.54156625,  0.761607  , -0.8847281 ,\n",
      "        -0.05805277,  0.61659724, -0.2872174 , -0.61892694, -0.72019106],\n",
      "       [-0.3840139 , -0.38051417,  0.44763032,  0.24777573,  0.01972524,\n",
      "        -1.1321224 ,  0.38852173,  1.1495441 , -1.1935891 ,  0.4396458 ],\n",
      "       [ 0.97726256, -1.3073189 , -0.44572532,  0.30751297, -0.48875144,\n",
      "         0.54685295, -0.8327998 ,  0.5872058 , -0.36733913,  0.49711516],\n",
      "       [ 0.9347961 , -0.468485  , -0.9017289 ,  0.50119424, -0.23169732,\n",
      "         0.3835829 , -0.7537039 ,  0.5802481 , -0.09429843,  0.54304606],\n",
      "       [-0.05396807, -0.03862916, -0.26177424,  0.6809653 , -0.8495823 ,\n",
      "         0.3952282 , -0.65970665,  0.65111804, -0.7852452 ,  0.7351042 ],\n",
      "       [-1.4309819 ,  0.65036696,  0.55804   ,  0.03477632,  0.55819625,\n",
      "         0.4771004 ,  0.06009682, -1.1222037 ,  0.91797566, -0.6131328 ],\n",
      "       [ 0.8939652 , -0.2838459 , -1.1419209 , -0.9392506 ,  0.5737918 ,\n",
      "         0.8205587 , -0.7726152 ,  0.2810361 ,  0.04893785,  0.4731362 ],\n",
      "       [ 0.99189067, -0.9225691 ,  0.6255429 ,  0.90056133, -1.0711893 ,\n",
      "         0.63890713, -0.36471504,  0.25536644, -0.15927476, -1.0850843 ],\n",
      "       [ 0.17545447, -1.0561562 , -0.18099064, -0.17184411,  0.95034033,\n",
      "        -0.28875995, -0.6016822 ,  0.60862076, -0.02090786,  0.9724648 ],\n",
      "       [ 0.02468507,  0.1085787 ,  0.8747189 , -0.49685225,  0.7199576 ,\n",
      "        -0.9824636 , -0.48265913,  0.3263457 , -0.4976703 ,  0.35629514],\n",
      "       [-0.1708855 , -0.39344984,  0.16882974, -0.5945607 ,  0.49886188,\n",
      "        -0.44236535,  0.2975722 , -0.5745999 , -0.17783302,  0.6409639 ],\n",
      "       [-0.8709502 , -0.16448447, -1.4563543 , -0.06822092,  0.4390441 ,\n",
      "         0.46772072, -0.7914104 ,  0.70107037,  0.9556413 ,  0.5705435 ],\n",
      "       [ 0.14097404, -0.2394455 , -0.14011896,  1.0664458 , -0.10605103,\n",
      "         0.04101354, -0.47726947,  0.02521437,  0.12248861,  0.14907713],\n",
      "       [ 0.37503132,  0.02132508,  0.81154114, -0.02925656, -0.73595834,\n",
      "        -0.01022225,  0.24442255, -1.3201804 ,  0.8885161 , -0.7296688 ],\n",
      "       [-0.3680224 ,  0.84013724,  1.179749  ,  0.18129647, -0.7957762 ,\n",
      "        -0.0747612 , -0.9168054 ,  0.50357586,  0.3684878 , -0.71531147]],\n",
      "      dtype=float32)]\n",
      "Biases:\n",
      " [array([[-2.7596641e-02,  6.6338368e-02,  6.3635074e-02,  1.0590991e-01,\n",
      "        -2.1130648e-02, -8.4263653e-02, -3.6006100e-02,  5.7073245e-03,\n",
      "         9.5588025e-03,  8.1967972e-03, -1.0107550e-02, -6.0586382e-02,\n",
      "        -3.2398973e-02, -6.9881447e-02, -1.7888622e-02, -1.1499479e-01,\n",
      "        -1.7801000e-02, -1.0770319e-02,  3.1833045e-02,  4.8471615e-02,\n",
      "         1.9769017e-02,  7.5916246e-02,  6.6228434e-02,  3.2670729e-02,\n",
      "        -5.8269098e-02, -8.0054156e-02,  6.6070907e-02,  5.5642381e-02,\n",
      "        -1.9446401e-02, -7.9746649e-02, -3.9279568e-03, -9.5753185e-02,\n",
      "         2.9233960e-02,  3.4666255e-02,  5.9972487e-02,  8.4723055e-02,\n",
      "        -5.7556897e-02,  1.4854876e-02, -1.6360909e-04, -8.8192999e-02,\n",
      "         7.1368650e-02, -7.1732596e-02,  4.7189992e-02, -1.7075710e-02,\n",
      "        -2.0069821e-02, -7.8328289e-02,  2.5249729e-02, -4.3981664e-02,\n",
      "        -8.2327954e-02, -6.4515084e-02,  5.8321752e-02, -2.9975247e-02,\n",
      "         9.7033523e-02, -1.1742140e-02,  1.0093905e-01, -8.6890228e-02,\n",
      "        -6.9443278e-02,  5.5491459e-02, -4.6092030e-02,  3.6897264e-02,\n",
      "         3.6791019e-02, -5.5358700e-02, -8.3939455e-02,  2.9193815e-02,\n",
      "        -8.6209014e-02,  4.0536337e-02, -5.1335100e-02,  1.4807300e-02,\n",
      "         6.9623508e-02,  5.2103277e-02,  7.3845550e-02, -7.7276900e-02,\n",
      "        -5.8395907e-02, -8.7583512e-03,  1.2877088e-02,  1.2098866e-03,\n",
      "         1.6413774e-01,  4.1165151e-02,  1.5200131e-02, -4.3165375e-02,\n",
      "         7.1172066e-02, -5.1267575e-02,  7.3574118e-02,  4.8853189e-02,\n",
      "         4.3087147e-02,  2.7689779e-02, -1.0363104e-02,  2.3518203e-02,\n",
      "        -8.2782976e-02,  4.5504645e-02, -9.8686993e-02,  5.1670581e-02,\n",
      "        -3.2852061e-02,  3.1278098e-03,  3.1439412e-02,  7.5990386e-02,\n",
      "        -9.0581346e-03,  7.0967581e-03,  3.0118613e-02,  7.1969867e-02,\n",
      "         2.4849821e-02, -4.3934081e-02, -1.0622848e-01, -1.9423937e-02,\n",
      "         4.7129218e-02,  4.0179372e-02, -9.7638041e-02, -4.0552258e-02,\n",
      "        -1.1873432e-02,  3.6739025e-02,  4.8290163e-02,  4.2242795e-02,\n",
      "        -2.0589875e-02, -5.4330789e-02, -1.8393669e-02, -6.1676525e-02,\n",
      "        -1.6072184e-02, -1.4640314e-02, -3.9561514e-02, -1.8311812e-02,\n",
      "         8.1608757e-02, -1.4160766e-02,  4.4056077e-02, -1.0161145e-01,\n",
      "        -3.2612722e-02,  5.2178772e-03,  2.1172548e-02,  6.1744936e-02]],\n",
      "      dtype=float32), array([[ 0.03184358,  0.13835244,  0.09666717, -0.07825515,  0.24058476,\n",
      "         0.22006552, -0.05391501, -0.04569014,  0.14818405,  0.1444709 ,\n",
      "         0.16575408,  0.1653445 , -0.15816452,  0.1443003 , -0.08080017,\n",
      "         0.0573125 ,  0.13825195, -0.09445249,  0.02747704,  0.07140771,\n",
      "         0.1535639 ,  0.00999415,  0.04068543, -0.19300584, -0.00994122,\n",
      "        -0.12287235,  0.18708004, -0.20622335,  0.0067202 ,  0.09365762,\n",
      "         0.13000502,  0.03894598, -0.1424567 ,  0.06342229, -0.08841245,\n",
      "        -0.12219972,  0.17610545,  0.18895313,  0.082449  ,  0.08338568,\n",
      "        -0.08345573,  0.18230075, -0.10445078,  0.08078563,  0.05816346,\n",
      "        -0.14475274,  0.04764352,  0.0593669 , -0.16753013, -0.12263821,\n",
      "         0.01912297, -0.03864149, -0.062626  , -0.17337851,  0.08184145,\n",
      "        -0.02606374,  0.18070787,  0.1933811 ,  0.00144473, -0.2247481 ,\n",
      "        -0.15915824,  0.06859478, -0.05287386,  0.00823364]],\n",
      "      dtype=float32), array([[ 0.30154952, -0.22861744,  0.02678606, -0.22027667, -0.20508823,\n",
      "        -0.10000192,  0.08686181,  0.22732627, -0.08767506,  0.3655702 ,\n",
      "        -0.0265281 , -0.05114393,  0.23607597, -0.06239821, -0.18636945,\n",
      "        -0.33211407,  0.15883633,  0.00791816,  0.08251154,  0.20104036,\n",
      "        -0.15169457, -0.0804579 , -0.13603118,  0.20730227,  0.06133066,\n",
      "        -0.09939873,  0.00976353, -0.21403654,  0.22368436, -0.19394201,\n",
      "        -0.12210818,  0.15913802]], dtype=float32), array([[-0.1601947 ,  0.0965821 ,  0.3121175 , -0.39440617,  0.03223838,\n",
      "        -0.07443672,  0.29692733,  0.36489436,  0.38382027, -0.5042493 ]],\n",
      "      dtype=float32)]\n",
      "Prediction:\n",
      " [8 4 5 ... 2 7 1]\n",
      "Prediction Probability:\n",
      " [[1.34231042e-04 4.96332999e-03 2.08526826e-03 ... 3.44050874e-04\n",
      "  9.08314347e-01 1.28524844e-03]\n",
      " [5.93005316e-05 1.06932304e-03 8.59137508e-05 ... 6.47913991e-03\n",
      "  4.96978499e-03 3.49327087e-01]\n",
      " [5.80216013e-03 1.33684429e-03 2.54567270e-03 ... 5.53915044e-04\n",
      "  3.22201729e-01 1.50454864e-02]\n",
      " ...\n",
      " [2.49081728e-04 1.41246617e-01 6.66776061e-01 ... 2.56367406e-04\n",
      "  1.36888444e-01 1.54563560e-04]\n",
      " [2.13770871e-03 9.43284031e-05 7.62082855e-05 ... 8.01931024e-01\n",
      "  5.71943761e-04 1.82158530e-01]\n",
      " [1.24906410e-06 9.63102877e-01 8.93784035e-03 ... 2.52025481e-03\n",
      "  1.26938885e-02 3.43459588e-03]]\n",
      "Loss:\n",
      " [2.259171961453605, 2.0785247006260703, 1.7292653897007084, 1.3614442371695663, 1.0874166410639097, 0.8859898593887915, 0.7445089091349468, 0.6489110846104604, 0.5828727476055247, 0.5344164881836917, 0.49661908365583707, 0.4657482624075912, 0.43973214070074945, 0.41734022153403066, 0.3977716241008228]\n",
      "Accuracy:\n",
      " 0.8917857142857143\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pengaruh Regularisasi",
   "id": "1b7734b1a1eb82bc"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-29T06:25:36.211991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scikit-learn MLP\n",
    "sk_mlp = MLPLIB(\n",
    "    max_iter=max_iter,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    activation=activation_mlplib,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Custom MLP\n",
    "custom_mlp = FFNNClassifier(\n",
    "    max_epoch=max_iter,\n",
    "    learning_rate=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    loss_func=\"categorical_cross_entropy\",\n",
    "    activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    ")\n",
    "\n",
    "\n",
    "model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "2f1679aeb669fd7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLearn MLPClassifier]\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T05:59:48.412373Z",
     "start_time": "2025-03-29T05:58:26.446727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scikit-learn MLP\n",
    "sk_mlp = MLPLIB(\n",
    "    max_iter=max_iter,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    activation=activation_mlplib,\n",
    "    verbose=False,\n",
    "    alpha_l1=l1\n",
    ")\n",
    "\n",
    "# Custom MLP\n",
    "custom_mlp = FFNNClassifier(\n",
    "    max_epoch=max_iter,\n",
    "    learning_rate=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    loss_func=\"categorical_cross_entropy\",\n",
    "    activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    l1 = l1\n",
    ")\n",
    "\n",
    "\n",
    "model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "816dc319367ceb2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLearn MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8455\n",
      "\n",
      "[From Scratch FFNNClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:104: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.8455\n",
      "\n",
      "[Comparison Result]\n",
      "[[ 1.25334943e-02 -2.04976459e-06 -1.27172225e-05 ... -2.26038901e-06\n",
      "   5.20470560e-01 -1.36140570e-05]\n",
      " [ 1.02603912e-01  1.83600187e-05 -3.02603439e-07 ... -1.41504988e-05\n",
      "   1.37276784e-05 -4.60157186e-01]\n",
      " [ 1.54448335e-05  5.31605838e-06 -4.93295789e-01 ... -1.91982090e-05\n",
      "  -1.57920301e-01 -5.13424675e-06]\n",
      " ...\n",
      " [-2.97288984e-01 -1.08179813e-02 -1.83952561e-05 ... -1.45242214e-01\n",
      "   2.75011917e-06 -3.18426100e-06]\n",
      " [ 1.77501559e-01 -3.56105864e-01  1.37034640e-05 ...  9.33108330e-02\n",
      "   5.98134138e-02  2.83952613e-06]\n",
      " [ 8.59687134e-07 -4.67437712e-06 -3.39252919e-01 ... -8.46586823e-02\n",
      "  -1.31968245e-05  4.98523514e-06]] != [[ 1.25334943e-02 -2.04976459e-06 -1.27172225e-05 ... -2.26038901e-06\n",
      "   5.20470560e-01 -1.36140570e-05]\n",
      " [ 1.02603912e-01  1.83600187e-05 -3.02603439e-07 ... -1.41504988e-05\n",
      "   1.37276784e-05 -4.60157186e-01]\n",
      " [ 1.54448335e-05  5.31605838e-06 -4.93295789e-01 ... -1.91982090e-05\n",
      "  -1.57920301e-01 -5.13424675e-06]\n",
      " ...\n",
      " [-2.97288984e-01 -1.08179813e-02 -1.83952561e-05 ... -1.45242214e-01\n",
      "   2.75011917e-06 -3.18426100e-06]\n",
      " [ 1.77501559e-01 -3.56105864e-01  1.37034640e-05 ...  9.33108330e-02\n",
      "   5.98134138e-02  2.83952613e-06]\n",
      " [ 8.59687134e-07 -4.67437712e-06 -3.39252919e-01 ... -8.46586823e-02\n",
      "  -1.31968245e-05  4.98523514e-06]]\n",
      "❌ Weight is not equal\n",
      "✅ Bias is equal\n",
      "✅ Prediction is equal\n",
      "✅ Prediction Probability is equal\n",
      "✅ Loss is equal\n",
      "✅ Accuracy is equal\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Scikit-learn MLP\n",
    "sk_mlp = MLPLIB(\n",
    "    max_iter=max_iter,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    activation=activation_mlplib,\n",
    "    verbose=False,\n",
    "    alpha=l2\n",
    ")\n",
    "\n",
    "# Custom MLP\n",
    "custom_mlp = FFNNClassifier(\n",
    "    max_epoch=max_iter,\n",
    "    learning_rate=learning_rate_init,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    init_method=init_method,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    loss_func=\"categorical_cross_entropy\",\n",
    "    activation_func=[activation_ffnn] * len(hidden_layer_sizes) + ['softmax'],\n",
    "    l2 = l2\n",
    ")\n",
    "\n",
    "\n",
    "model_comparison(sk_mlp, custom_mlp, X_train_scaled, y_train, y_train_one_hot, X_test_scaled, y_test, y_test_one_hot, is_only_show_accuracy=True)"
   ],
   "id": "36d5d02615bd9b40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
