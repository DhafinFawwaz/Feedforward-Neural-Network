{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T10:22:55.669809Z",
     "start_time": "2025-03-26T10:22:54.448653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.lib.FFNNClassifier import FFNNClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n"
   ],
   "id": "96667713e99492d3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T10:22:59.912681Z",
     "start_time": "2025-03-26T10:22:55.677043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_encode(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    More robust one-hot encoding using NumPy\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): Input labels\n",
    "    num_classes (int): Number of classes to encode\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: One-hot encoded array\n",
    "    \"\"\"\n",
    "    # Ensure y is a NumPy array of integers\n",
    "    y = np.asarray(y, dtype=int)\n",
    "\n",
    "    # Create one-hot encoded array\n",
    "    one_hot = np.zeros((len(y), num_classes))\n",
    "    one_hot[np.arange(len(y)), y] = 1\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# Type conversion\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "y_test_one_hot = one_hot_encode(y_test)"
   ],
   "id": "4cee682bc13fa484",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_and_evaluate_mlp(hidden_layer_sizes, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train MLP and return model, accuracy, and training loss\n",
    "    \"\"\"\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        max_iter=50,  # Increased iterations for better convergence\n",
    "        solver='adam',\n",
    "        random_state=42,\n",
    "        early_stopping=True,  # Use validation set for early stopping\n",
    "        validation_fraction=0.1,  # 10% of training data for validation\n",
    "        n_iter_no_change=5  # Stop if no improvement for 5 iterations\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return mlp, accuracy, mlp.loss_curve_"
   ],
   "id": "bd5b809b10bcb4ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T11:46:53.847328Z",
     "start_time": "2025-03-26T11:46:53.841998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model_comparison(sk_mlp: MLPClassifier, custom_mlp: FFNNClassifier, is_weight: bool = False):\n",
    "\n",
    "    if not is_weight:\n",
    "        sk_mlp.fit(X_train_scaled, y_train)\n",
    "    sk_pred = sk_mlp.predict(X_test_scaled)\n",
    "    sk_accuracy = accuracy_score(y_test, sk_pred)\n",
    "    print(\"[SKLEARN] Prediction: \",sk_pred)\n",
    "    print(\"[SKLEARN] Accuracy: \", sk_accuracy)\n",
    "    # print(\"[SKLEARN] Weights: \", sk_mlp.coefs_)\n",
    "    # print(\"[SKLEARN] Bias: \", sk_mlp.intercepts_)\n",
    "    print()\n",
    "\n",
    "    if not is_weight:\n",
    "        custom_mlp.fit(X_train_scaled, y_train_one_hot)\n",
    "    custom_pred = custom_mlp.predict(X_test_scaled)\n",
    "    y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "    custom_accuracy = accuracy_score(y_test_labels, custom_pred)\n",
    "    print(\"[CUSTOM] Prediction: \",custom_pred)\n",
    "    print(\"[CUSTOM] Accuracy: \", custom_accuracy)\n",
    "    # print(\"[SKLEARN] Weights: \", custom_mlp.weights_history)\n",
    "    # print(\"[SKLEARN] Bias: \", custom_mlp.biases_history[-1])\n",
    "    print()\n"
   ],
   "id": "690823e3c6017152",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T10:44:31.541202Z",
     "start_time": "2025-03-26T10:42:44.659494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"\n",
    "Pengaruh depth (banyak layer) dan width (banyak neuron per layer)\n",
    "\"\"\"\n",
    "\n",
    "# Configuration for depth variation (keeping width constant)\n",
    "depth_configs = [\n",
    "    (10, 10),  # 2 layers\n",
    "    (10, 10, 10),  # 3 layers\n",
    "    (10, 10, 10, 10)  # 4 layers\n",
    "]\n",
    "\n",
    "# Configuration for width variation (keeping depth constant)\n",
    "width_configs = [\n",
    "    (5,),  # narrow layer\n",
    "    (15,),  # medium layer\n",
    "    (30,)  # wide layer\n",
    "]\n",
    "\n",
    "results = {\n",
    "    'depth_variations': [],\n",
    "    'width_variations': []\n",
    "}\n",
    "\n",
    "# Experiment for depth variations (keeping width fixed)\n",
    "print(\"Depth Variations Experiment:\")\n",
    "for depth_config in depth_configs:\n",
    "    print(f\"\\nTesting depth configuration: {depth_config}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        max_iter=20,\n",
    "        random_state=42,\n",
    "        learning_rate_init=0.01\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=20,\n",
    "        learning_rate=0.01,\n",
    "        hidden_layer_sizes=depth_config,\n",
    "        init_method=\"normal\",\n",
    "        mean=5.39294405e-05,\n",
    "        std=.44,\n",
    "        seed=69\n",
    "\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp)\n",
    "\n",
    "print(\"Width Variations Experiment:\")\n",
    "for width_configs in width_configs:\n",
    "    print(f\"\\nTesting width configuration: {width_configs}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=width_configs,\n",
    "        max_iter=20,\n",
    "        random_state=42,\n",
    "        learning_rate_init=0.01\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=20,\n",
    "        learning_rate=0.01,\n",
    "        hidden_layer_sizes=width_configs,\n",
    "        init_method=\"normal\",\n",
    "        mean=5.39294405e-05,\n",
    "        std=.44,\n",
    "        seed=69\n",
    "\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp)\n"
   ],
   "id": "59dfa7da3d6601c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth Variations Experiment:\n",
      "\n",
      "Testing depth configuration: (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9295\n",
      "\n",
      "[CUSTOM] Prediction:  [5 6 5 ... 6 6 5]\n",
      "[CUSTOM] Accuracy:  0.121\n",
      "\n",
      "\n",
      "Testing depth configuration: (10, 10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 6 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9293571428571429\n",
      "\n",
      "[CUSTOM] Prediction:  [6 6 6 ... 6 6 6]\n",
      "[CUSTOM] Accuracy:  0.09414285714285714\n",
      "\n",
      "\n",
      "Testing depth configuration: (10, 10, 10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9362142857142857\n",
      "\n",
      "[CUSTOM] Prediction:  [6 6 6 ... 6 6 6]\n",
      "[CUSTOM] Accuracy:  0.09971428571428571\n",
      "\n",
      "Width Variations Experiment:\n",
      "\n",
      "Testing width configuration: (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.8880714285714286\n",
      "\n",
      "[CUSTOM] Prediction:  [7 5 5 ... 3 5 5]\n",
      "[CUSTOM] Accuracy:  0.07342857142857143\n",
      "\n",
      "\n",
      "Testing width configuration: (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 5 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9401428571428572\n",
      "\n",
      "[CUSTOM] Prediction:  [8 9 9 ... 9 3 6]\n",
      "[CUSTOM] Accuracy:  0.0995\n",
      "\n",
      "\n",
      "Testing width configuration: (30,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9547142857142857\n",
      "\n",
      "[CUSTOM] Prediction:  [9 9 9 ... 9 9 9]\n",
      "[CUSTOM] Accuracy:  0.10278571428571429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:84: RuntimeWarning: overflow encountered in exp\n",
      "  elif func == 'sigmoid': return 1.0/(1.0 + np.exp(-x))\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T10:57:28.074983Z",
     "start_time": "2025-03-26T10:55:19.493488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activation_configs = [\n",
    "    ('linear','identity'),\n",
    "    ('relu','relu'),\n",
    "    ('sigmoid','logistic'),\n",
    "    ('tanh','tanh')\n",
    "]\n",
    "\n",
    "print(\"Width Variations Experiment:\")\n",
    "for act_custom, act_sklearn in activation_configs:\n",
    "    print(f\"\\nTesting activation configuration: {act_custom}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=[10],\n",
    "        activation= act_sklearn,\n",
    "        max_iter=20,\n",
    "        random_state=42,\n",
    "        learning_rate_init=0.01\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=20,\n",
    "        learning_rate=0.01,\n",
    "        activation_func=[act_custom,act_custom],\n",
    "        hidden_layer_sizes=[10],\n",
    "        init_method=\"normal\",\n",
    "        mean=5.39294405e-05,\n",
    "        std=.44,\n",
    "        seed=69\n",
    "\n",
    "    )\n",
    "    model_comparison(sk_mlp, custom_mlp)"
   ],
   "id": "e7a0630da20efc9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing activation configuration: linear\n",
      "[SKLEARN] Prediction:  [8 4 5 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.8994285714285715\n",
      "\n",
      "[CUSTOM] Prediction:  [0 0 0 ... 0 0 0]\n",
      "[CUSTOM] Accuracy:  0.09592857142857143\n",
      "\n",
      "\n",
      "Testing activation configuration: relu\n",
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9259285714285714\n",
      "\n",
      "[CUSTOM] Prediction:  [0 0 0 ... 0 0 0]\n",
      "[CUSTOM] Accuracy:  0.09585714285714286\n",
      "\n",
      "\n",
      "Testing activation configuration: sigmoid\n",
      "[SKLEARN] Prediction:  [8 4 5 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9023571428571429\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 39\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m# Custom MLP\u001B[39;00m\n\u001B[32m     29\u001B[39m custom_mlp = FFNNClassifier(\n\u001B[32m     30\u001B[39m     learning_rate=\u001B[32m0.01\u001B[39m,\n\u001B[32m     31\u001B[39m     activation_func=[act_custom,act_custom],\n\u001B[32m   (...)\u001B[39m\u001B[32m     37\u001B[39m \n\u001B[32m     38\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m custom_loss = \u001B[43mcustom_mlp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_one_hot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m custom_pred = custom_mlp.predict(X_test_scaled)\n\u001B[32m     41\u001B[39m y_test_labels = np.argmax(y_test_one_hot, axis=\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Feedforward-Neural-Network\\src\\lib\\FFNNClassifier.py:279\u001B[39m, in \u001B[36mFFNNClassifier.fit\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m    275\u001B[39m w = \u001B[38;5;28mself\u001B[39m.weights_history[k]\n\u001B[32m    277\u001B[39m delta = np.dot(delta, w.T) * FFNNClassifier._activation_derived_function(nodes[k], \u001B[38;5;28mself\u001B[39m.activation_func[k-\u001B[32m1\u001B[39m])\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m weight_gradiens[k-\u001B[32m1\u001B[39m] = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes_active\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[43mdelta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[38;5;66;03m# bias_gradiens[k-1] = -delta\u001B[39;00m\n\u001B[32m    281\u001B[39m bias_gradiens[k-\u001B[32m1\u001B[39m] = -np.mean(delta, axis=\u001B[32m0\u001B[39m, keepdims=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T11:00:10.657980Z",
     "start_time": "2025-03-26T10:59:10.060844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "print(\"Width Variations Experiment:\")\n",
    "for rate in learning_rates:\n",
    "    print(f\"\\nTesting activation configuration: {rate}\")\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=[10],\n",
    "        max_iter=20,\n",
    "        random_state=42,\n",
    "        learning_rate_init=rate\n",
    "    )\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=20,\n",
    "        learning_rate=rate,\n",
    "        hidden_layer_sizes=[10],\n",
    "        init_method=\"normal\",\n",
    "        mean=5.39294405e-05,\n",
    "        std=.44,\n",
    "        seed=69\n",
    "\n",
    "    )\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp)"
   ],
   "id": "b21ff3b736552045",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing activation configuration: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [2 4 2 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.5694285714285714\n",
      "\n",
      "[CUSTOM] Prediction:  [6 9 5 ... 5 9 9]\n",
      "[CUSTOM] Accuracy:  0.09585714285714286\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9294285714285714\n",
      "\n",
      "[CUSTOM] Prediction:  [2 5 5 ... 5 9 9]\n",
      "[CUSTOM] Accuracy:  0.09235714285714286\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9322857142857143\n",
      "\n",
      "[CUSTOM] Prediction:  [2 5 5 ... 5 9 9]\n",
      "[CUSTOM] Accuracy:  0.091\n",
      "\n",
      "\n",
      "Testing activation configuration: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [8 4 8 ... 2 7 1]\n",
      "[SKLEARN] Accuracy:  0.9120714285714285\n",
      "\n",
      "[CUSTOM] Prediction:  [5 5 5 ... 5 9 9]\n",
      "[CUSTOM] Accuracy:  0.093\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T11:47:39.128009Z",
     "start_time": "2025-03-26T11:47:00.587040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "weight_configs =  ['normal', 'zero', 'uniform']\n",
    "\n",
    "print(\"Width Variations Experiment:\")\n",
    "for weight_config in weight_configs:\n",
    "    print(f\"\\nTesting weight configuration: {weight_config}\")\n",
    "\n",
    "    lower_bound=5.39294405e-05\n",
    "    upper_bound=1\n",
    "    mean=5.39294405e-05\n",
    "    std=.44\n",
    "    seed=69\n",
    "\n",
    "    # Scikit-learn MLP\n",
    "    sk_mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=[10],\n",
    "        max_iter=20,\n",
    "        random_state=42,\n",
    "        learning_rate_init=0.01\n",
    "    )\n",
    "    sk_mlp.fit(X_train_scaled, y_train)\n",
    "    if weight_config == 'normal':\n",
    "        for i in range(len(sk_mlp.coefs_)):\n",
    "            sk_mlp.coefs_[i] = np.random.normal(mean, std, sk_mlp.coefs_[i].shape)\n",
    "            sk_mlp.intercepts_[i] = np.random.normal(mean, std, sk_mlp.intercepts_[i].shape)\n",
    "    elif weight_config == 'zero':\n",
    "        for i in range(len(sk_mlp.coefs_)):\n",
    "            sk_mlp.coefs_[i] = np.zeros(sk_mlp.coefs_[i].shape)\n",
    "            sk_mlp.intercepts_[i] = np.zeros(sk_mlp.intercepts_[i].shape)\n",
    "    elif weight_config == 'uniform':\n",
    "        for i in range(len(sk_mlp.coefs_)):\n",
    "            sk_mlp.coefs_[i] = np.random.uniform(lower_bound, upper_bound, sk_mlp.coefs_[i].shape)\n",
    "            sk_mlp.intercepts_[i] = np.random.uniform(lower_bound, upper_bound, sk_mlp.intercepts_[i].shape)\n",
    "    else:\n",
    "        raise ValueError('Unknown weight configuration')\n",
    "\n",
    "\n",
    "\n",
    "    # Custom MLP\n",
    "    custom_mlp = FFNNClassifier(\n",
    "        max_epoch=20,\n",
    "        learning_rate=0.01,\n",
    "        hidden_layer_sizes=[10],\n",
    "        init_method=\"normal\",\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        seed=seed\n",
    "    )\n",
    "    custom_mlp.fit(X_train_scaled, y_train_one_hot)\n",
    "\n",
    "\n",
    "    model_comparison(sk_mlp, custom_mlp, True)"
   ],
   "id": "d5c0d65e76b4a222",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width Variations Experiment:\n",
      "\n",
      "Testing weight configuration: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [1 0 2 ... 7 9 1]\n",
      "[SKLEARN] Accuracy:  0.112\n",
      "\n",
      "[CUSTOM] Prediction:  [2 5 5 ... 5 9 9]\n",
      "[CUSTOM] Accuracy:  0.09235714285714286\n",
      "\n",
      "\n",
      "Testing weight configuration: zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [0 0 0 ... 0 0 0]\n",
      "[SKLEARN] Accuracy:  0.09592857142857143\n",
      "\n",
      "[CUSTOM] Prediction:  [2 5 5 ... 5 9 9]\n",
      "[CUSTOM] Accuracy:  0.09235714285714286\n",
      "\n",
      "\n",
      "Testing weight configuration: uniform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\GitHub\\Feedforward-Neural-Network\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKLEARN] Prediction:  [5 8 6 ... 3 3 3]\n",
      "[SKLEARN] Accuracy:  0.08135714285714286\n",
      "\n",
      "[CUSTOM] Prediction:  [2 5 5 ... 5 9 9]\n",
      "[CUSTOM] Accuracy:  0.09235714285714286\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
